From: <Saved by Blink>
Snapshot-Content-Location: https://slickgpt.com/t/5
Subject: =?utf-8?Q?Training=20a=20Custom=20Korean=20ASR=20Model=20with=20Python=20?=
 =?utf-8?Q?-=20Machine=20Learning=20=E2=80=A2=20SlickGPT?=
Date: Thu, 23 May 2024 23:48:39 -0400
MIME-Version: 1.0
Content-Type: multipart/related;
	type="text/html";
	boundary="----MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----"


------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: text/html
Content-ID: <frame-8A8CBC7723F82B09FB33403DB8B3DDD7@mhtml.blink>
Content-Transfer-Encoding: quoted-printable
Content-Location: https://slickgpt.com/t/5

<!DOCTYPE html><html lang=3D"en" translate=3D"no" style=3D"--vh: 9.53px;"><=
head><meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3DUTF-=
8"><link rel=3D"stylesheet" type=3D"text/css" href=3D"cid:css-482fdfc1-8f4a=
-493f-8577-bad422bc9e2c@mhtml.blink" />
   =20
    <link rel=3D"preconnect" href=3D"https://magicproxy-dnfo3dcduq-ew.a.run=
.app/">
    <link rel=3D"preconnect" href=3D"https://slickgpt-web-pe7fohytbq-uc.a.r=
un.app/">
    <link rel=3D"preconnect" href=3D"https://slickgpt-web-pe7fohytbq-ew.a.r=
un.app/">
    <link rel=3D"preconnect" href=3D"https://slickgpt-web-pe7fohytbq-zf.a.r=
un.app/">
    <link rel=3D"preconnect" href=3D"https://slickgpt-web-pe7fohytbq-de.a.r=
un.app/">
   =20
    <meta http-equiv=3D"X-UA-Compatible" content=3D"IE=3Dedge">

    <meta name=3D"viewport" content=3D"width=3Ddevice-width,initial-scale=
=3D1.0">
    <meta name=3D"referrer" content=3D"origin">

    <title>Training a Custom Korean ASR Model with Python - Machine Learnin=
g =E2=80=A2 SlickGPT</title>
    <meta name=3D"description" content=3D"Training a Custom Korean ASR Mode=
l with Python - Machine Learning">
    <meta name=3D"keywords" content=3D"SlickGPT, ChatGPT, AI assistant, no-=
code, marketing, creativity, productivity, personal assistant">
    <meta property=3D"og:title" content=3D"Training a Custom Korean ASR Mod=
el with Python - Machine Learning">
    <meta property=3D"og:description" content=3D"Training a Custom Korean A=
SR Model with Python - Machine Learning">
    <meta property=3D"og:image" content=3D"https://slickgpt.com/img/social.=
jpg">
    <meta property=3D"og:url" content=3D"https://slickgpt.com">
    <meta property=3D"og:type" content=3D"website">
    <meta property=3D"og:site_name" content=3D"SlickGPT">
    <meta name=3D"twitter:card" content=3D"summary_large_image">
    <meta name=3D"twitter:title" content=3D"Training a Custom Korean ASR Mo=
del with Python - Machine Learning">
    <meta name=3D"twitter:description" content=3D"Training a Custom Korean =
ASR Model with Python - Machine Learning">
    <meta name=3D"twitter:image" content=3D"https://slickgpt.com/img/social=
.jpg">
    <meta name=3D"twitter:site" content=3D"@SlickGPT">
    <meta name=3D"twitter:creator" content=3D"@SlickGPT">

    <meta name=3D"apple-mobile-web-app-capable" content=3D"yes">
    <meta name=3D"format-detection" content=3D"telephone=3Dno">
    <meta name=3D"google" content=3D"notranslate">

    <meta name=3D"apple-mobile-web-app-title" content=3D"SlickGPT">
    <meta name=3D"application-name" content=3D"SlickGPT">
    <link rel=3D"apple-touch-icon" sizes=3D"180x180" href=3D"https://slickg=
pt.com/apple-touch-icon.png">
    <link rel=3D"icon" type=3D"image/png" sizes=3D"32x32" href=3D"https://s=
lickgpt.com/favicon-32x32.png">
    <link rel=3D"icon" type=3D"image/png" sizes=3D"16x16" href=3D"https://s=
lickgpt.com/favicon-16x16.png">
    <link rel=3D"manifest" href=3D"https://slickgpt.com/site.webmanifest">
    <link rel=3D"mask-icon" href=3D"https://slickgpt.com/safari-pinned-tab.=
svg" color=3D"#511446">
    <meta name=3D"msapplication-TileColor" content=3D"#511446">
    <meta name=3D"theme-color" content=3D"#080b16">

    <meta property=3D"og:locale" content=3D"en">
    <meta http-equiv=3D"Content-Language" content=3D"en">
   =20
    <link rel=3D"modulepreload" crossorigin=3D"" href=3D"https://slickgpt.c=
om/assets/vendor-2643db22.js">
    <link rel=3D"stylesheet" href=3D"https://slickgpt.com/assets/index-0587=
c55e.css">
  <link rel=3D"modulepreload" as=3D"script" crossorigin=3D"" href=3D"https:=
//slickgpt.com/assets/thread-id-bc4e7372.js"><link rel=3D"modulepreload" as=
=3D"script" crossorigin=3D"" href=3D"https://slickgpt.com/assets/useHead-43=
c28b06.js"><link rel=3D"modulepreload" as=3D"script" crossorigin=3D"" href=
=3D"https://slickgpt.com/assets/ThreadPage.vue_vue_type_script_setup_true_l=
ang-c15e9b98.js"><link rel=3D"modulepreload" as=3D"script" crossorigin=3D""=
 href=3D"https://slickgpt.com/assets/PageHeader-9edcc061.js"><link rel=3D"m=
odulepreload" as=3D"script" crossorigin=3D"" href=3D"https://slickgpt.com/a=
ssets/UserAvatar.vue_vue_type_script_setup_true_lang-42a6e52b.js"><link rel=
=3D"modulepreload" as=3D"script" crossorigin=3D"" href=3D"https://slickgpt.=
com/assets/ChannelInput.vue_vue_type_script_setup_true_lang-5a387590.js"><l=
ink rel=3D"modulepreload" as=3D"script" crossorigin=3D"" href=3D"https://sl=
ickgpt.com/assets/new-55d33ec1.js"><link rel=3D"modulepreload" as=3D"script=
" crossorigin=3D"" href=3D"https://slickgpt.com/assets/models-05589cc3.js">=
</head>
  <body class=3D"dark">
   =20
    <div id=3D"app" data-v-app=3D""><!----><div class=3D"min-h-screen page =
flex flex-col sm:flex-row relative transition"><nav class=3D"fixed sm:stick=
y z-[100] top-0 left-0 h-screen max-h-screen border-r text-white bg-[#090b1=
6] transition-all select-none w-[256px] -translate-x-[256px] sm:translate-x=
-0 overflow-hidden sm:overflow-visible sm:w-[68px] border-slate-800/50"><di=
v class=3D"flex flex-col h-full"><div class=3D"group flex relative items-ce=
nter justify-end px-6 h-16 hover:bg-[#172B51]/50 transition cursor-pointer"=
><span class=3D"text-lg absolute left-0 ml-5 font-black text-center flex it=
ems-center"><svg class=3D"h-5 w-5 ml-1 transition" xmlns=3D"http://www.w3.o=
rg/2000/svg" viewBox=3D"0 0 64 64"><path fill=3D"#50c18e" d=3D"M15 57c-2-10=
 6-22 16-24 5 9 3 33-9 31-3-1-6-3-7-7Z"></path><path fill=3D"#50c18e" d=3D"=
M1 42c0 9 14 9 13 0 1-9-13-9-13 0Z" opacity=3D".8"></path><path fill=3D"#f9=
bb49" d=3D"M7 15c10-2 22 6 24 16-9 5-33 3-31-9 1-3 3-6 7-7Z"></path><path f=
ill=3D"#f9bb49" d=3D"M22 1c-9 0-9 14 0 13 9 1 9-13 0-13Z" opacity=3D".8"></=
path><path fill=3D"#e92e42" d=3D"M49 7c2 10-6 22-16 24-5-9-3-33 9-31 3 1 6 =
3 7 7Z"></path><path fill=3D"#e92e42" d=3D"M63 22c0-9-14-9-13 0-1 9 13 9 13=
 0Z" opacity=3D".8"></path><path fill=3D"#58caf7" d=3D"M57 49c-10 2-22-6-24=
-16 9-5 33-3 31 9-1 3-3 6-7 7Z"></path><path fill=3D"#58caf7" d=3D"M42 63c9=
 0 9-14 0-13-9-1-9 13 0 13Z" opacity=3D".8"></path></svg><!----></span><!--=
--></div><a class=3D"border rounded-full flex items-center ml-4 mr-4 mt-1 c=
ursor-pointer group ring-2 ring-transparent transition duration-300 border-=
slate-800 ring-slate-800 bg-slate-900 p-2 justify-center hover:border-blue-=
500 hover:ring-blue-500" href=3D"https://slickgpt.com/new"><div class=3D"te=
xt-sm font-bold text-slate-100 dark:text-slate-400 truncate"><svg class=3D"=
w-3 h-3 my-1" xmlns=3D"http://www.w3.org/2000/svg" viewBox=3D"0 0 13.41 13.=
41"><path fill=3D"currentColor" d=3D"M0 6.7c0 .65.53 1.18 1.18 1.18h4.34v4.=
34a1.18 1.18 0 0 0 2.37 0V7.88h4.34a1.18 1.18 0 0 0 0-2.37H7.89V1.18a1.18 1=
.18 0 0 0-2.37 0v4.33H1.18A1.2 1.2 0 0 0 0 6.7Z"></path></svg></div><!---->=
</a><div class=3D"my-3"></div><div class=3D"flex-1 overflow-auto microScrol=
lbar w-full flex flex-col"><a class=3D"px-2 group transition text-[15px] bl=
ock" href=3D"https://slickgpt.com/settings"><div class=3D"px-4 py-1 rounded=
-md transition flex items-center justify-between border text-[#c0d0f1] hove=
r:text-white group-hover:bg-[#172B51]/50 border-transparent"><svg class=3D"=
h-4 w-4 min-w-[16px]" xmlns=3D"http://www.w3.org/2000/svg" fill=3D"none" vi=
ewBox=3D"0 0 24 24" stroke-width=3D"1.5" stroke=3D"currentColor"><path stro=
ke-linecap=3D"round" stroke-linejoin=3D"round" d=3D"M9.594 3.94c.09-.542.56=
-.94 1.11-.94h2.593c.55 0 1.02.398 1.11.94l.213 1.281c.063.374.313.686.645.=
87.074.04.147.083.22.127.324.196.72.257 1.075.124l1.217-.456a1.125 1.125 0 =
011.37.49l1.296 2.247a1.125 1.125 0 01-.26 1.431l-1.003.827c-.293.24-.438.6=
13-.431.992a6.759 6.759 0 010 .255c-.007.378.138.75.43.99l1.005.828c.424.35=
.534.954.26 1.43l-1.298 2.247a1.125 1.125 0 01-1.369.491l-1.217-.456c-.355-=
.133-.75-.072-1.076.124a6.57 6.57 0 01-.22.128c-.331.183-.581.495-.644.869l=
-.213 1.28c-.09.543-.56.941-1.11.941h-2.594c-.55 0-1.02-.398-1.11-.94l-.213=
-1.281c-.062-.374-.312-.686-.644-.87a6.52 6.52 0 01-.22-.127c-.325-.196-.72=
-.257-1.076-.124l-1.217.456a1.125 1.125 0 01-1.369-.49l-1.297-2.247a1.125 1=
.125 0 01.26-1.431l1.004-.827c.292-.24.437-.613.43-.992a6.932 6.932 0 010-.=
255c.007-.378-.138-.75-.43-.99l-1.004-.828a1.125 1.125 0 01-.26-1.43l1.297-=
2.247a1.125 1.125 0 011.37-.491l1.216.456c.356.133.751.072 1.076-.124.072-.=
044.146-.087.22-.128.332-.183.582-.495.644-.869l.214-1.281z"></path><path s=
troke-linecap=3D"round" stroke-linejoin=3D"round" d=3D"M15 12a3 3 0 11-6 0 =
3 3 0 016 0z"></path></svg><span class=3D"ml-2 truncate leading-none transi=
tion flex-1">Settings</span><!----><!----><!----></div></a><a class=3D"px-2=
 group transition text-[15px] block" href=3D"https://slickgpt.com/search"><=
div class=3D"px-4 py-1 rounded-md transition flex items-center justify-betw=
een border text-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 bord=
er-transparent"><svg class=3D"h-4 w-4 min-w-[16px]" xmlns=3D"http://www.w3.=
org/2000/svg" fill=3D"none" viewBox=3D"0 0 24 24" stroke-width=3D"1.5" stro=
ke=3D"currentColor"><path stroke-linecap=3D"round" stroke-linejoin=3D"round=
" d=3D"M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 1=
0.607z"></path></svg><span class=3D"ml-2 truncate leading-none transition f=
lex-1">Search</span><!----><!----><!----></div></a><a class=3D"px-2 group t=
ransition text-[15px] block" href=3D"https://slickgpt.com/archive"><div cla=
ss=3D"px-4 py-1 rounded-md transition flex items-center justify-between bor=
der text-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-tran=
sparent"><svg class=3D"h-4 w-4 min-w-[16px]" xmlns=3D"http://www.w3.org/200=
0/svg" fill=3D"none" viewBox=3D"0 0 24 24" stroke-width=3D"1.5" stroke=3D"c=
urrentColor"><path stroke-linecap=3D"round" stroke-linejoin=3D"round" d=3D"=
M20.25 7.5l-.625 10.632a2.25 2.25 0 01-2.247 2.118H6.622a2.25 2.25 0 01-2.2=
47-2.118L3.75 7.5M10 11.25h4M3.375 7.5h17.25c.621 0 1.125-.504 1.125-1.125v=
-1.5c0-.621-.504-1.125-1.125-1.125H3.375c-.621 0-1.125.504-1.125 1.125v1.5c=
0 .621.504 1.125 1.125 1.125z"></path></svg><span class=3D"ml-2 truncate le=
ading-none transition flex-1">Archived</span><!----><!----><!----></div></a=
><a href=3D"https://magicspace.agency/contact" target=3D"_blank" class=3D"p=
x-2 group transition text-[15px] block"><div class=3D"px-4 py-1 rounded-md =
transition flex items-center justify-between border text-[#c0d0f1] hover:te=
xt-white group-hover:bg-[#172B51]/50 border-transparent"><svg class=3D"w-4 =
h-4 min-w-[16px] group-hover:text-[#7289da] transition" xmlns=3D"http://www=
.w3.org/2000/svg" viewBox=3D"0 0 640 512"><path fill=3D"currentColor" d=3D"=
M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1=
.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0=
,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A=
483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.=
651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.66=
6,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,43=
0.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1=
.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1=
,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2=
.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.=
407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.01=
4,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.88=
2,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM22=
2.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,21=
9.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.=
491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,41=
7.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337=
.58,417.871,337.58Z"></path></svg><span class=3D"ml-2 truncate leading-none=
 transition flex-1">Contact</span></div></a><a class=3D"px-2 group transiti=
on text-[15px] block" href=3D"https://slickgpt.com/changelog"><div class=3D=
"px-4 py-1 rounded-md transition flex items-center justify-between border t=
ext-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transpare=
nt"><svg class=3D"w-3.5 min-w-[14px] mx-px" xmlns=3D"http://www.w3.org/2000=
/svg" viewBox=3D"0 0 18.65 18.37"><path fill=3D"currentColor" d=3D"M14.3 9.=
3c-.7 0-1.29-.57-1.29-1.27s.59-1.3 1.29-1.29c.71.01 1.28.59 1.28 1.29s-.57 =
1.26-1.28 1.27Zm0 3.53c-.7 0-1.29-.59-1.29-1.29s.59-1.28 1.29-1.28a1.28 1.2=
8 0 0 1 0 2.57ZM7.44 7.78a.65.65 0 0 1-.64-.65.63.63 0 1 1 1.26 0c0 .34-.28=
.65-.62.65Zm1.86.54c-.34 0-.61-.29-.61-.64s.27-.64.61-.64c.37 0 .64.29.64.6=
4s-.28.64-.64.64Zm1.41 1.36a.62.62 0 0 1-.62-.62c0-.37.28-.66.62-.66s.64.29=
.64.66c0 .35-.29.62-.64.62Zm.48 1.81c-.35 0-.63-.28-.63-.63s.28-.63.63-.63.=
62.28.62.63-.28.63-.62.63Zm-.48 1.83c-.34 0-.62-.29-.62-.65s.28-.63.62-.63.=
64.28.64.63-.29.65-.64.65ZM9.3 14.71c-.34 0-.61-.29-.61-.64s.28-.64.61-.64c=
.36 0 .64.3.64.64s-.28.64-.64.64Zm-1.86.56c-.35 0-.64-.29-.64-.63s.29-.65.6=
4-.65.62.29.62.65-.28.63-.62.63Zm-1.88-.56c-.36 0-.63-.29-.63-.64s.28-.64.6=
3-.64.61.3.61.64-.27.64-.61.64Zm-1.41-1.39c-.35 0-.64-.3-.64-.65s.3-.63.64-=
.63.61.28.61.63-.27.65-.61.65Zm-.48-1.83c-.34 0-.62-.28-.62-.63s.28-.63.62-=
.63.63.28.63.63-.29.63-.63.63Zm.48-1.81a.63.63 0 0 1-.64-.62c0-.37.3-.66.64=
-.66s.61.29.61.66a.6.6 0 0 1-.61.62Zm1.41-1.36c-.36 0-.63-.29-.63-.64s.27-.=
64.63-.64.61.29.61.64-.27.64-.61.64Zm1.88 1.39c-.35 0-.64-.28-.64-.63s.29-.=
65.64-.65.62.29.62.65-.28.63-.62.63Zm1.72.77c-.34 0-.64-.3-.64-.64s.29-.64.=
64-.64.62.29.62.64-.28.64-.62.64Zm0 2.11c-.35 0-.64-.29-.64-.64s.29-.64.64-=
.64.62.29.62.64-.27.64-.62.64Zm-1.72.77c-.35 0-.64-.3-.64-.65s.29-.63.64-.6=
3.62.28.62.63-.28.65-.62.65Zm-1.73-.77c-.35 0-.63-.29-.63-.64s.28-.64.63-.6=
4.64.29.64.64-.3.64-.64.64Zm0-2.11c-.34 0-.63-.29-.63-.64s.29-.64.63-.64.64=
.3.64.64-.3.64-.64.64Zm1.73 1.04c-.35 0-.64-.28-.64-.63s.29-.63.64-.63.62.2=
8.62.63-.28.63-.62.63Zm7.59-6.25.53-1.66L4.6.04a.87.87 0 0 0-.55 1.66l10.98=
 3.56ZM2.76 18.37h13.13c1.79 0 2.76-.97 2.76-2.74V6.17c0-1.77-.97-2.74-2.76=
-2.74H2.76C.98 3.43 0 4.4 0 6.17v9.46c0 1.77.98 2.74 2.76 2.74Z"></path></s=
vg><span class=3D"ml-2 truncate leading-none transition flex-1">Changelog</=
span><!----><!----><!----></div></a><div class=3D"my-3"></div><div class=3D=
"space-y-2"><div id=3D"header-General" class=3D"flex flex-col transition-al=
l"><div class=3D"h-7 px-2 group transition text-[15px]"><div class=3D"flex =
items-center"><div class=3D"ml-3 my-0.5 h-6 w-6 flex items-center justify-c=
enter text-[#c0d0f1] hover:text-white hover:bg-[#172B51]/50 rounded-md tran=
sition cursor-pointer"><svg class=3D"w-2" xmlns=3D"http://www.w3.org/2000/s=
vg" viewBox=3D"0 0 21 20"><path fill=3D"currentColor" d=3D"M18 0H3C1 0 0 2 =
0 3v2l8 13 3 2 3-2 7-13V3c0-1-1-3-3-3Z"></path></svg></div><!----><!----></=
div></div><a class=3D"px-2 group transition text-[15px] block" href=3D"http=
s://slickgpt.com/t/0"><div class=3D"px-4 py-1 rounded-md transition flex it=
ems-center justify-between border text-[#c0d0f1] hover:text-white group-hov=
er:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] =
flex items-center justify-center font-bold">#</span><span class=3D"ml-2 tru=
ncate leading-none transition flex-1">New Thread</span><!----><!----><!----=
></div></a><a class=3D"px-2 group transition text-[15px] block" href=3D"htt=
ps://slickgpt.com/t/2"><div class=3D"px-4 py-1 rounded-md transition flex i=
tems-center justify-between border text-[#c0d0f1] hover:text-white group-ho=
ver:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px]=
 flex items-center justify-center font-bold">#</span><span class=3D"ml-2 tr=
uncate leading-none transition flex-1">New Thread</span><!----><!----><!---=
-></div></a><a class=3D"px-2 group transition text-[15px] block" href=3D"ht=
tps://slickgpt.com/t/3"><div class=3D"px-4 py-1 rounded-md transition flex =
items-center justify-between border text-[#c0d0f1] hover:text-white group-h=
over:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px=
] flex items-center justify-center font-bold">=F0=9F=A4=96</span><span clas=
s=3D"ml-2 truncate leading-none transition flex-1">Best Korean LLM Models</=
span><!----><!----><!----></div></a><a class=3D"px-2 group transition text-=
[15px] block" href=3D"https://slickgpt.com/t/4"><div class=3D"px-4 py-1 rou=
nded-md transition flex items-center justify-between border text-[#c0d0f1] =
hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><span clas=
s=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font-bold">=F0=
=9F=94=A7</span><span class=3D"ml-2 truncate leading-none transition flex-1=
">Obtaining WSL Update x64 MSI Installer URLs</span><!----><!----><!----></=
div></a><a class=3D"px-2 group transition text-[15px] block" href=3D"https:=
//slickgpt.com/t/13"><div class=3D"px-4 py-1 rounded-md transition flex ite=
ms-center justify-between border text-[#c0d0f1] hover:text-white group-hove=
r:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] f=
lex items-center justify-center font-bold">=F0=9F=94=8D</span><span class=
=3D"ml-2 truncate leading-none transition flex-1">Remove Duplicate Files in=
 Directory Using Python</span><!----><!----><!----></div></a></div><div id=
=3D"header-Machine Learning" class=3D"flex flex-col transition-all"><div cl=
ass=3D"h-7 px-2 group transition text-[15px]"><div class=3D"flex items-cent=
er"><div class=3D"ml-3 my-0.5 h-6 w-6 flex items-center justify-center text=
-[#c0d0f1] hover:text-white hover:bg-[#172B51]/50 rounded-md transition cur=
sor-pointer"><svg class=3D"w-2" xmlns=3D"http://www.w3.org/2000/svg" viewBo=
x=3D"0 0 21 20"><path fill=3D"currentColor" d=3D"M18 0H3C1 0 0 2 0 3v2l8 13=
 3 2 3-2 7-13V3c0-1-1-3-3-3Z"></path></svg></div><!----><!----></div></div>=
<a class=3D"px-2 group transition text-[15px] block" href=3D"https://slickg=
pt.com/t/5"><div class=3D"px-4 py-1 rounded-md transition flex items-center=
 justify-between border text-white bg-gradient-to-br from-[#172B51] to-[#1d=
3259] border-white/5"><span class=3D"h-4 w-4 min-w-[16px] flex items-center=
 justify-center font-bold">=F0=9F=A4=96</span><span class=3D"ml-2 truncate =
leading-none transition flex-1">Training a Custom Korean ASR Model with Pyt=
hon</span><!----><!----><!----></div></a><a class=3D"px-2 group transition =
text-[15px] block" href=3D"https://slickgpt.com/t/6"><div class=3D"px-4 py-=
1 rounded-md transition flex items-center justify-between border text-[#c0d=
0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><span=
 class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font-bold">=
=F0=9F=94=8A</span><span class=3D"ml-2 truncate leading-none transition fle=
x-1">Training Facebook's Denoiser on Custom Korean Speech Dataset with Vari=
ous Noises</span><!----><!----><!----></div></a><a class=3D"px-2 group tran=
sition text-[15px] block" href=3D"https://slickgpt.com/t/7"><div class=3D"p=
x-4 py-1 rounded-md transition flex items-center justify-between border tex=
t-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transparent=
"><span class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font=
-bold">=F0=9F=A4=96</span><span class=3D"ml-2 truncate leading-none transit=
ion flex-1">Training a Korean Language Model with Python</span><!----><!---=
-><!----></div></a><a class=3D"px-2 group transition text-[15px] block" hre=
f=3D"https://slickgpt.com/t/8"><div class=3D"px-4 py-1 rounded-md transitio=
n flex items-center justify-between border text-[#c0d0f1] hover:text-white =
group-hover:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-=
w-[16px] flex items-center justify-center font-bold">=F0=9F=94=8A</span><sp=
an class=3D"ml-2 truncate leading-none transition flex-1">Language-Free Spe=
aker Verification Model Training on Mobile</span><!----><!----><!----></div=
></a><a class=3D"px-2 group transition text-[15px] block" href=3D"https://s=
lickgpt.com/t/9"><div class=3D"px-4 py-1 rounded-md transition flex items-c=
enter justify-between border text-[#c0d0f1] hover:text-white group-hover:bg=
-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] flex =
items-center justify-center font-bold">=F0=9F=94=8A</span><span class=3D"ml=
-2 truncate leading-none transition flex-1">Language-Free Speaker Diarizati=
on Model for Mobile Devices</span><!----><!----><!----></div></a><a class=
=3D"px-2 group transition text-[15px] block" href=3D"https://slickgpt.com/t=
/10"><div class=3D"px-4 py-1 rounded-md transition flex items-center justif=
y-between border text-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/5=
0 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] flex items-center=
 justify-center font-bold">=F0=9F=8E=99=EF=B8=8F</span><span class=3D"ml-2 =
truncate leading-none transition flex-1">Multilingual ASR Pretrained Model =
Evaluation for Commercial Use</span><!----><!----><!----></div></a><a class=
=3D"px-2 group transition text-[15px] block" href=3D"https://slickgpt.com/t=
/11"><div class=3D"px-4 py-1 rounded-md transition flex items-center justif=
y-between border text-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/5=
0 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] flex items-center=
 justify-center font-bold">#</span><span class=3D"ml-2 truncate leading-non=
e transition flex-1">Building a Windows Application with Pretrained Models =
using PyTorch</span><!----><!----><!----></div></a><a class=3D"px-2 group t=
ransition text-[15px] block" href=3D"https://slickgpt.com/t/12"><div class=
=3D"px-4 py-1 rounded-md transition flex items-center justify-between borde=
r text-[#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transp=
arent"><span class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center=
 font-bold">=F0=9F=94=8D</span><span class=3D"ml-2 truncate leading-none tr=
ansition flex-1">Developer Guide for Training Object Detection Model with Y=
OLO-v9</span><!----><!----><!----></div></a><a class=3D"px-2 group transiti=
on text-[15px] block" href=3D"https://slickgpt.com/t/14"><div class=3D"px-4=
 py-1 rounded-md transition flex items-center justify-between border text-[=
#c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><=
span class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font-bo=
ld">=F0=9F=94=81</span><span class=3D"ml-2 truncate leading-none transition=
 flex-1">Converting a MeloTTS Model to ONNX Format</span><!----><!----><!--=
--></div></a><a class=3D"px-2 group transition text-[15px] block" href=3D"h=
ttps://slickgpt.com/t/15"><div class=3D"px-4 py-1 rounded-md transition fle=
x items-center justify-between border text-[#c0d0f1] hover:text-white group=
-hover:bg-[#172B51]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16=
px] flex items-center justify-center font-bold">=F0=9F=A7=A0</span><span cl=
ass=3D"ml-2 truncate leading-none transition flex-1">Memory Mechanism in Ch=
atGPT</span><!----><!----><!----></div></a><a class=3D"px-2 group transitio=
n text-[15px] block" href=3D"https://slickgpt.com/t/16"><div class=3D"px-4 =
py-1 rounded-md transition flex items-center justify-between border text-[#=
c0d0f1] hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><s=
pan class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font-bol=
d">=F0=9F=93=B1</span><span class=3D"ml-2 truncate leading-none transition =
flex-1">Choosing the Best Framework for On-Device Machine Learning</span><!=
----><!----><!----></div></a><a class=3D"px-2 group transition text-[15px] =
block" href=3D"https://slickgpt.com/t/17"><div class=3D"px-4 py-1 rounded-m=
d transition flex items-center justify-between border text-[#c0d0f1] hover:=
text-white group-hover:bg-[#172B51]/50 border-transparent"><span class=3D"h=
-4 w-4 min-w-[16px] flex items-center justify-center font-bold">=F0=9F=94=
=8A</span><span class=3D"ml-2 truncate leading-none transition flex-1">Spea=
ker Verification Dataset Overview</span><!----><!----><!----></div></a><a c=
lass=3D"px-2 group transition text-[15px] block" href=3D"https://slickgpt.c=
om/t/18"><div class=3D"px-4 py-1 rounded-md transition flex items-center ju=
stify-between border text-[#c0d0f1] hover:text-white group-hover:bg-[#172B5=
1]/50 border-transparent"><span class=3D"h-4 w-4 min-w-[16px] flex items-ce=
nter justify-center font-bold">=F0=9F=94=8D</span><span class=3D"ml-2 trunc=
ate leading-none transition flex-1">Training a Model for Image Search Engin=
e</span><!----><!----><!----></div></a><a class=3D"px-2 group transition te=
xt-[15px] block" href=3D"https://slickgpt.com/t/19"><div class=3D"px-4 py-1=
 rounded-md transition flex items-center justify-between border text-[#c0d0=
f1] hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><span =
class=3D"h-4 w-4 min-w-[16px] flex items-center justify-center font-bold">=
=F0=9F=9B=8D=EF=B8=8F</span><span class=3D"ml-2 truncate leading-none trans=
ition flex-1">Extracting Product Cards from Amazon Website Screenshot using=
 Python</span><!----><!----><!----></div></a></div><!----></div></div><div =
class=3D"h-0 w-full border-b border-slate-800/50"></div><div data-headlessu=
i-state=3D"" class=3D"p-1"><button id=3D"headlessui-menu-button-1" type=3D"=
button" aria-haspopup=3D"menu" aria-expanded=3D"false" data-headlessui-stat=
e=3D"" class=3D"hover:bg-uiBlue-600/80 ui-open:bg-white/10 ui-open:text-whi=
te ui-not-open:hover:bg-white/[0.08] ui-not-open:dark:hover:text-white/80 a=
ctive:bg-slate-800 active:ring-uiBlue-600 select-none py-2 px-4 text-base f=
ont-medium text-white group bg-opacity-80 focus:outline-none active:ring-2 =
shadow-sm w-full rounded-lg focus:ring-1 focus:ring-blue-500"><div class=3D=
"flex items-center"><div class=3D"font-extrabold font-num text-center flex =
items-center justify-center text-white overflow-hidden text-[8px] bg-black =
rounded h-5 w-5 min-w-[20px] transition" style=3D"background-color: rgb(178=
, 183, 187);">CW</div><!----></div></button><!----></div></div></nav><div c=
lass=3D"flex flex-col page-fade-in flex-1"><div class=3D"sticky text-xs fle=
x items-center justify-between z-20 top-0 left-0 w-full h-10 border-b borde=
r-slate-700/50 text-white bg-darkBlue-500/75 backdrop-blur select-none"><di=
v class=3D"sm:hidden px-6"><svg class=3D"w-5 h-5" xmlns=3D"http://www.w3.or=
g/2000/svg" fill=3D"none" viewBox=3D"0 0 24 24" stroke-width=3D"1.5" stroke=
=3D"currentColor"><path stroke-linecap=3D"round" stroke-linejoin=3D"round" =
d=3D"M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div><div =
class=3D"flex-1 h-10 group cursor-pointer py-1 rounded-md flex items-center=
 font-black tracking-tight transition text-[#c0d0f1] group-hover:text-white=
 group-hover:bg-[#172B51]/50 border-transparent px-1 sm:px-4"><span class=
=3D"font-bold mr-1">=F0=9F=A4=96</span><span class=3D"whitespace-nowrap tra=
nsition">Machine Learning</span></div><div class=3D"flex-1 px-1 h-10 hidden=
 sm:flex items-center group cursor-pointer truncate sm:px-3 py-1 rounded-md=
 font-semibold transition text-[#c0d0f1]/50 group-hover:text-white group-ho=
ver:bg-[#172B51]/50 border-transparent">Training a Custom Korean ASR Model =
with Python</div><div class=3D"h-10 group cursor-pointer px-3 py-1 rounded-=
md flex items-center font-black tracking-tight transition text-[#c0d0f1] gr=
oup-hover:text-white group-hover:bg-[#172B51]/50 border-transparent"><span>=
4</span></div><div data-headlessui-state=3D"" class=3D"p-1 mr-2"><button id=
=3D"headlessui-menu-button-19" type=3D"button" aria-haspopup=3D"menu" aria-=
expanded=3D"false" data-headlessui-state=3D"" class=3D"relative hover:bg-ui=
Blue-600/80 ui-open:bg-white/10 ui-open:text-white ui-not-open:hover:bg-whi=
te/[0.08] ui-not-open:dark:hover:text-white/80 active:bg-slate-800 active:r=
ing-uiBlue-600 select-none p-1 text-base font-medium text-white group bg-op=
acity-80 focus:outline-none active:ring-2 shadow-sm w-full rounded-lg focus=
:ring-1 focus:ring-blue-500" aria-label=3D"Account"><div class=3D"overflow-=
hidden bg-black rounded-lg h-6 w-6 transition group-hover:scale-110"><img r=
eferrerpolicy=3D"no-referrer" src=3D"https://lh3.googleusercontent.com/a/AC=
g8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G9E0cdWXQ=3Ds96-c" alt=3D"" load=
ing=3D"lazy" class=3D"transition h-full w-full opacity-100"></div></button>=
<!----></div></div><div class=3D"flex-1 flex flex-col justify-between items=
-end"><div class=3D"flex flex-col justify-end h-full w-full"><div class=3D"=
p-6"><h2 class=3D"flex items-center text-lg lg:text-2xl"><span class=3D"fon=
t-bold mr-1">=F0=9F=A4=96</span><span class=3D"font-black">Machine Learning=
</span></h2><p class=3D"text-sm lg:text-base">Training a Custom Korean ASR =
Model with Python</p></div><div class=3D"pb-6 px-3 flex items-center"><div =
class=3D"px-3"><div class=3D"text-[10px] text-slate-400 font-bold tracking-=
wide"> Model </div><div class=3D"text-sm font-black tracking-tight transiti=
on hover:text-[#f9bb49]">gpt-4o-2024-05-13</div></div><div class=3D"px-3"><=
div class=3D"text-[10px] text-slate-400 font-bold tracking-wide"> Agent </d=
iv><div class=3D"text-sm font-black tracking-tight transition hover:text-[#=
f9bb49]">Assistant</div></div></div><div class=3D"chat-base px-6 group rela=
tive hover:bg-slate-800/50"><div class=3D"flex items-start py-3"><div class=
=3D"h-8 w-8 mr-3 rounded flex items-center justify-center bg-slate-500/20 t=
ext-slate-100/50 transition cursor-pointer hover:bg-slate-500/50 hover:text=
-slate-100"><svg xmlns=3D"http://www.w3.org/2000/svg" viewBox=3D"0 0 17.08 =
17.07" width=3D"16" height=3D"16"><path fill=3D"currentColor" d=3D"M7.83 17=
.07h1.42c.56 0 1-.34 1.12-.89l.37-1.56c.21-.07.41-.15.58-.23l1.36.84c.46.29=
 1.02.23 1.41-.15l1-.99c.39-.39.44-.98.14-1.44l-.83-1.35c.09-.18.16-.37.22-=
.56l1.57-.38c.54-.12.88-.55.88-1.12V7.85c0-.55-.34-.99-.88-1.11l-1.55-.37a4=
.5 4.5 0 0 0-.23-.57l.84-1.38A1.1 1.1 0 0 0 15.1 3l-1.02-1a1.13 1.13 0 0 0-=
1.36-.16l-1.4.87a3.89 3.89 0 0 0-.58-.24L10.36.89A1.1 1.1 0 0 0 9.24 0H7.82=
c-.56 0-1 .35-1.12.89l-.38 1.56c-.21.07-.41.15-.59.25l-1.39-.86c-.47-.25-.9=
7-.2-1.37.17l-1.01 1c-.4.38-.45.95-.14 1.42l.83 1.38c-.07.16-.16.36-.22.57l=
-1.55.37a1.1 1.1 0 0 0-.89 1.11v1.39c0 .56.34 1 .89 1.12l1.57.38c.06.19.14.=
38.22.56l-.82 1.35c-.31.46-.25 1.05.14 1.44l.99.99c.39.38.95.44 1.42.15l1.3=
6-.84.58.23.38 1.56c.12.54.55.89 1.12.89Zm.71-5.84a2.69 2.69 0 1 1 0-5.38 2=
.69 2.69 0 0 1 0 5.38Z"></path></svg></div><!----><!----><div class=3D"flex=
 flex-col flex-1"><div class=3D"flex items-center"><div class=3D"text-sm le=
ading-none font-bold text-white mr-2"><span>System</span><!----><!----></di=
v><div class=3D"text-xs leading-none text-slate-400 hover:underline" title=
=3D"Thursday, May 16, 2024 at 3:55 PM">3:55 PM</div></div><div class=3D"fle=
x-1 chat-content break-words" agent=3D"Assistant"><p>You are SlickGPT, a la=
rge language model on <a href=3D"http://slickgpt.com/">SlickGPT.com</a>, an=
swer as concisely as possible.<br>
Current date: 2024-05-16</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-black=
 rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https://l=
h3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G9E=
0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-full=
 opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 3:=
55 PM">3:55 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>I am gonna get my own Korean ASR model on my own datas=
et. Recommend the best model for me and walk me through training with pytho=
n code</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 3:55 PM">3:55 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>For building a Korean Automatic Speech Recognition (ASR) model, a strong s=
tarting point is to use a pre-trained model like Wav2Vec 2.0 from Facebook =
AI, which can be fine-tuned on your specific dataset. Here=E2=80=99s a conc=
ise guide to get you started:</p>
<h3 id=3D"step-1-install-necessary-libraries" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-necessary-lib=
raries" aria-hidden=3D"true">#</a> Step 1: Install Necessary Libraries</h3>
<p>Ensure you have the necessary libraries installed. You can use Hugging F=
ace=E2=80=99s <code>transformers</code> and <code>datasets</code> libraries=
.</p>
<pre><code class=3D"hljs language-bash">pip install transformers datasets t=
orch soundfile
</code></pre>
<h3 id=3D"step-2-load-pre-trained-wav2vec-2-0-model-and-tokenizer" tabindex=
=3D"-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-=
load-pre-trained-wav2vec-2-0-model-and-tokenizer" aria-hidden=3D"true">#</a=
> Step 2: Load Pre-trained Wav2Vec 2.0 Model and Tokenizer</h3>
<p>Import the necessary modules and load the pre-trained model and tokenize=
r.</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> Wav2Vec2For=
CTC, Wav2Vec2Processor
<span class=3D"hljs-keyword">import</span> torch
<span class=3D"hljs-keyword">import</span> torchaudio

<span class=3D"hljs-comment"># Load pre-trained model and tokenizer</span>
model_name =3D <span class=3D"hljs-string">"facebook/wav2vec2-large-xlsr-53=
"</span>
processor =3D Wav2Vec2Processor.from_pretrained(model_name)
model =3D Wav2Vec2ForCTC.from_pretrained(model_name)
</code></pre>
<h3 id=3D"step-3-prepare-your-dataset" tabindex=3D"-1"><a class=3D"header-a=
nchor" href=3D"https://slickgpt.com/t/5#step-3-prepare-your-dataset" aria-h=
idden=3D"true">#</a> Step 3: Prepare Your Dataset</h3>
<p>Your dataset should contain audio files and corresponding transcripts. L=
oad and preprocess your dataset.</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> datasets <span class=3D"hljs-keyword">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load your dataset</span>
dataset =3D load_dataset(<span class=3D"hljs-string">"path_to_your_dataset"=
</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">speech_file_to_array_fn</span>(<span class=3D"hljs-params">batch</span>):
    speech_array, _ =3D sf.read(batch[<span class=3D"hljs-string">"file"</s=
pan>])
    batch[<span class=3D"hljs-string">"speech"</span>] =3D speech_array
    <span class=3D"hljs-keyword">return</span> batch

<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">prepare_dataset</span>(<span class=3D"hljs-params">batch</span>):
    batch[<span class=3D"hljs-string">"input_values"</span>] =3D processor(=
batch[<span class=3D"hljs-string">"speech"</span>], sampling_rate=3D<span c=
lass=3D"hljs-number">16_000</span>).input_values[<span class=3D"hljs-number=
">0</span>]
    <span class=3D"hljs-keyword">with</span> processor.as_target_processor(=
):
        batch[<span class=3D"hljs-string">"labels"</span>] =3D processor(ba=
tch[<span class=3D"hljs-string">"transcript"</span>]).input_ids
    <span class=3D"hljs-keyword">return</span> batch

dataset =3D dataset.<span class=3D"hljs-built_in">map</span>(speech_file_to=
_array_fn)
dataset =3D dataset.<span class=3D"hljs-built_in">map</span>(prepare_datase=
t, remove_columns=3Ddataset.column_names)
</code></pre>
<h3 id=3D"step-4-fine-tune-the-model" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-4-fine-tune-the-model" aria-hid=
den=3D"true">#</a> Step 4: Fine-Tune the Model</h3>
<p>Set up training arguments and fine-tune the model.</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> TrainingArg=
uments, Trainer

<span class=3D"hljs-comment"># Define training arguments</span>
training_args =3D TrainingArguments(
    output_dir=3D<span class=3D"hljs-string">"./wav2vec2-korean"</span>,
    group_by_length=3D<span class=3D"hljs-literal">True</span>,
    per_device_train_batch_size=3D<span class=3D"hljs-number">16</span>,
    gradient_accumulation_steps=3D<span class=3D"hljs-number">2</span>,
    evaluation_strategy=3D<span class=3D"hljs-string">"steps"</span>,
    num_train_epochs=3D<span class=3D"hljs-number">3</span>,
    save_steps=3D<span class=3D"hljs-number">400</span>,
    eval_steps=3D<span class=3D"hljs-number">400</span>,
    logging_steps=3D<span class=3D"hljs-number">400</span>,
    learning_rate=3D<span class=3D"hljs-number">3e-4</span>,
    warmup_steps=3D<span class=3D"hljs-number">500</span>,
    save_total_limit=3D<span class=3D"hljs-number">2</span>,
)

<span class=3D"hljs-comment"># Define the data collator</span>
<span class=3D"hljs-keyword">from</span> dataclasses <span class=3D"hljs-ke=
yword">import</span> dataclass
<span class=3D"hljs-keyword">from</span> typing <span class=3D"hljs-keyword=
">import</span> <span class=3D"hljs-type">Dict</span>, <span class=3D"hljs-=
type">List</span>, <span class=3D"hljs-type">Union</span>
<span class=3D"hljs-keyword">import</span> torch

<span class=3D"hljs-meta">@dataclass</span>
<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>DataCollatorCTCWithPadding</span>:
    processor: Wav2Vec2Processor
    padding: <span class=3D"hljs-type">Union</span>[<span class=3D"hljs-bui=
lt_in">bool</span>, <span class=3D"hljs-built_in">str</span>] =3D <span cla=
ss=3D"hljs-literal">True</span>

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__call__</span>(<span class=3D"hljs-params">self, features: <span cla=
ss=3D"hljs-type">List</span>[<span class=3D"hljs-type">Dict</span>[<span cl=
ass=3D"hljs-built_in">str</span>, <span class=3D"hljs-type">Union</span>[<s=
pan class=3D"hljs-type">List</span>[<span class=3D"hljs-built_in">int</span=
>], torch.Tensor]]]</span>) -&gt; <span class=3D"hljs-type">Dict</span>[<sp=
an class=3D"hljs-built_in">str</span>, torch.Tensor]:
        input_features =3D [{<span class=3D"hljs-string">"input_values"</sp=
an>: feature[<span class=3D"hljs-string">"input_values"</span>]} <span clas=
s=3D"hljs-keyword">for</span> feature <span class=3D"hljs-keyword">in</span=
> features]
        label_features =3D [{<span class=3D"hljs-string">"input_ids"</span>=
: feature[<span class=3D"hljs-string">"labels"</span>]} <span class=3D"hljs=
-keyword">for</span> feature <span class=3D"hljs-keyword">in</span> feature=
s]

        batch =3D self.processor.pad(
            input_features,
            padding=3Dself.padding,
            return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
        )
        <span class=3D"hljs-keyword">with</span> self.processor.as_target_p=
rocessor():
            labels_batch =3D self.processor.pad(
                label_features,
                padding=3Dself.padding,
                return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
            )

        batch[<span class=3D"hljs-string">"labels"</span>] =3D labels_batch=
[<span class=3D"hljs-string">"input_ids"</span>].masked_fill(labels_batch.a=
ttention_mask.ne(<span class=3D"hljs-number">1</span>), -<span class=3D"hlj=
s-number">100</span>)

        <span class=3D"hljs-keyword">return</span> batch

data_collator =3D DataCollatorCTCWithPadding(processor=3Dprocessor)

<span class=3D"hljs-comment"># Initialize Trainer</span>
trainer =3D Trainer(
    model=3Dmodel,
    data_collator=3Ddata_collator,
    args=3Dtraining_args,
    train_dataset=3Ddataset[<span class=3D"hljs-string">"train"</span>],
    eval_dataset=3Ddataset[<span class=3D"hljs-string">"test"</span>],
    tokenizer=3Dprocessor.feature_extractor,
)

<span class=3D"hljs-comment"># Train the model</span>
trainer.train()
</code></pre>
<h3 id=3D"step-5-evaluate-the-model" tabindex=3D"-1"><a class=3D"header-anc=
hor" href=3D"https://slickgpt.com/t/5#step-5-evaluate-the-model" aria-hidde=
n=3D"true">#</a> Step 5: Evaluate the Model</h3>
<p>Evaluate your fine-tuned model on the test dataset.</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Ev=
aluate the model</span>
results =3D trainer.evaluate()
<span class=3D"hljs-built_in">print</span>(results)
</code></pre>
<p>This guide provides a foundation for training a Korean ASR model using W=
av2Vec 2.0. Adjust the dataset path, training parameters, and other specifi=
cs as needed for your application.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 3:=
59 PM">3:59 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>I use the model on device like mobile phones. The mode=
l size should be small. Recommend small and good one</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 3:59 PM">3:59 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>For deploying an ASR model on mobile devices, you=E2=80=99ll need a smalle=
r, more efficient model. One suitable option is the <code>Wav2Vec2.0-base</=
code> model or its distilled versions. Another lightweight alternative is t=
he <code>DeepSpeech</code> model.</p>
<h3 id=3D"step-by-step-guide-for-training-a-small-asr-model" tabindex=3D"-1=
"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-by-step-=
guide-for-training-a-small-asr-model" aria-hidden=3D"true">#</a> Step-by-St=
ep Guide for Training a Small ASR Model</h3>
<h4 id=3D"step-1-install-necessary-libraries" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-necessary-lib=
raries" aria-hidden=3D"true">#</a> Step 1: Install Necessary Libraries</h4>
<p>Make sure you have the required libraries installed:</p>
<pre><code class=3D"hljs language-bash">pip install transformers datasets t=
orch soundfile
</code></pre>
<h4 id=3D"step-2-load-a-smaller-pre-trained-model-and-tokenizer" tabindex=
=3D"-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-=
load-a-smaller-pre-trained-model-and-tokenizer" aria-hidden=3D"true">#</a> =
Step 2: Load a Smaller Pre-trained Model and Tokenizer</h4>
<p>Use a smaller variant of the Wav2Vec2.0 model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> Wav2Vec2For=
CTC, Wav2Vec2Processor

<span class=3D"hljs-comment"># Load a smaller pre-trained model</span>
model_name =3D <span class=3D"hljs-string">"facebook/wav2vec2-base"</span>
processor =3D Wav2Vec2Processor.from_pretrained(model_name)
model =3D Wav2Vec2ForCTC.from_pretrained(model_name)
</code></pre>
<h4 id=3D"step-3-prepare-your-dataset" tabindex=3D"-1"><a class=3D"header-a=
nchor" href=3D"https://slickgpt.com/t/5#step-3-prepare-your-dataset" aria-h=
idden=3D"true">#</a> Step 3: Prepare Your Dataset</h4>
<p>Ensure your dataset has audio files and corresponding transcripts. Load =
and preprocess the dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> datasets <span class=3D"hljs-keyword">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load your dataset</span>
dataset =3D load_dataset(<span class=3D"hljs-string">"path_to_your_dataset"=
</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">speech_file_to_array_fn</span>(<span class=3D"hljs-params">batch</span>):
    speech_array, _ =3D sf.read(batch[<span class=3D"hljs-string">"file"</s=
pan>])
    batch[<span class=3D"hljs-string">"speech"</span>] =3D speech_array
    <span class=3D"hljs-keyword">return</span> batch

<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">prepare_dataset</span>(<span class=3D"hljs-params">batch</span>):
    batch[<span class=3D"hljs-string">"input_values"</span>] =3D processor(=
batch[<span class=3D"hljs-string">"speech"</span>], sampling_rate=3D<span c=
lass=3D"hljs-number">16_000</span>).input_values[<span class=3D"hljs-number=
">0</span>]
    <span class=3D"hljs-keyword">with</span> processor.as_target_processor(=
):
        batch[<span class=3D"hljs-string">"labels"</span>] =3D processor(ba=
tch[<span class=3D"hljs-string">"transcript"</span>]).input_ids
    <span class=3D"hljs-keyword">return</span> batch

dataset =3D dataset.<span class=3D"hljs-built_in">map</span>(speech_file_to=
_array_fn)
dataset =3D dataset.<span class=3D"hljs-built_in">map</span>(prepare_datase=
t, remove_columns=3Ddataset.column_names)
</code></pre>
<h4 id=3D"step-4-fine-tune-the-model" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-4-fine-tune-the-model" aria-hid=
den=3D"true">#</a> Step 4: Fine-Tune the Model</h4>
<p>Set up the training arguments and fine-tune the smaller model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> TrainingArg=
uments, Trainer

<span class=3D"hljs-comment"># Define training arguments</span>
training_args =3D TrainingArguments(
    output_dir=3D<span class=3D"hljs-string">"./wav2vec2-small-korean"</spa=
n>,
    group_by_length=3D<span class=3D"hljs-literal">True</span>,
    per_device_train_batch_size=3D<span class=3D"hljs-number">16</span>,
    gradient_accumulation_steps=3D<span class=3D"hljs-number">2</span>,
    evaluation_strategy=3D<span class=3D"hljs-string">"steps"</span>,
    num_train_epochs=3D<span class=3D"hljs-number">3</span>,
    save_steps=3D<span class=3D"hljs-number">400</span>,
    eval_steps=3D<span class=3D"hljs-number">400</span>,
    logging_steps=3D<span class=3D"hljs-number">400</span>,
    learning_rate=3D<span class=3D"hljs-number">3e-4</span>,
    warmup_steps=3D<span class=3D"hljs-number">500</span>,
    save_total_limit=3D<span class=3D"hljs-number">2</span>,
)

<span class=3D"hljs-comment"># Define the data collator</span>
<span class=3D"hljs-keyword">from</span> dataclasses <span class=3D"hljs-ke=
yword">import</span> dataclass
<span class=3D"hljs-keyword">from</span> typing <span class=3D"hljs-keyword=
">import</span> <span class=3D"hljs-type">Dict</span>, <span class=3D"hljs-=
type">List</span>, <span class=3D"hljs-type">Union</span>
<span class=3D"hljs-keyword">import</span> torch

<span class=3D"hljs-meta">@dataclass</span>
<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>DataCollatorCTCWithPadding</span>:
    processor: Wav2Vec2Processor
    padding: <span class=3D"hljs-type">Union</span>[<span class=3D"hljs-bui=
lt_in">bool</span>, <span class=3D"hljs-built_in">str</span>] =3D <span cla=
ss=3D"hljs-literal">True</span>

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__call__</span>(<span class=3D"hljs-params">self, features: <span cla=
ss=3D"hljs-type">List</span>[<span class=3D"hljs-type">Dict</span>[<span cl=
ass=3D"hljs-built_in">str</span>, <span class=3D"hljs-type">Union</span>[<s=
pan class=3D"hljs-type">List</span>[<span class=3D"hljs-built_in">int</span=
>], torch.Tensor]]]</span>) -&gt; <span class=3D"hljs-type">Dict</span>[<sp=
an class=3D"hljs-built_in">str</span>, torch.Tensor]:
        input_features =3D [{<span class=3D"hljs-string">"input_values"</sp=
an>: feature[<span class=3D"hljs-string">"input_values"</span>]} <span clas=
s=3D"hljs-keyword">for</span> feature <span class=3D"hljs-keyword">in</span=
> features]
        label_features =3D [{<span class=3D"hljs-string">"input_ids"</span>=
: feature[<span class=3D"hljs-string">"labels"</span>]} <span class=3D"hljs=
-keyword">for</span> feature <span class=3D"hljs-keyword">in</span> feature=
s]

        batch =3D self.processor.pad(
            input_features,
            padding=3Dself.padding,
            return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
        )
        <span class=3D"hljs-keyword">with</span> self.processor.as_target_p=
rocessor():
            labels_batch =3D self.processor.pad(
                label_features,
                padding=3Dself.padding,
                return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
            )

        batch[<span class=3D"hljs-string">"labels"</span>] =3D labels_batch=
[<span class=3D"hljs-string">"input_ids"</span>].masked_fill(labels_batch.a=
ttention_mask.ne(<span class=3D"hljs-number">1</span>), -<span class=3D"hlj=
s-number">100</span>)

        <span class=3D"hljs-keyword">return</span> batch

data_collator =3D DataCollatorCTCWithPadding(processor=3Dprocessor)

<span class=3D"hljs-comment"># Initialize Trainer</span>
trainer =3D Trainer(
    model=3Dmodel,
    data_collator=3Ddata_collator,
    args=3Dtraining_args,
    train_dataset=3Ddataset[<span class=3D"hljs-string">"train"</span>],
    eval_dataset=3Ddataset[<span class=3D"hljs-string">"test"</span>],
    tokenizer=3Dprocessor.feature_extractor,
)

<span class=3D"hljs-comment"># Train the model</span>
trainer.train()
</code></pre>
<h4 id=3D"step-5-evaluate-the-model" tabindex=3D"-1"><a class=3D"header-anc=
hor" href=3D"https://slickgpt.com/t/5#step-5-evaluate-the-model" aria-hidde=
n=3D"true">#</a> Step 5: Evaluate the Model</h4>
<p>Evaluate your fine-tuned model on the test dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Ev=
aluate the model</span>
results =3D trainer.evaluate()
<span class=3D"hljs-built_in">print</span>(results)
</code></pre>
<h3 id=3D"model-optimization-for-mobile" tabindex=3D"-1"><a class=3D"header=
-anchor" href=3D"https://slickgpt.com/t/5#model-optimization-for-mobile" ar=
ia-hidden=3D"true">#</a> Model Optimization for Mobile</h3>
<p>To further optimize for mobile deployment, consider converting the model=
 to ONNX format or using TensorFlow Lite:</p>
<h4 id=3D"convert-to-onnx" tabindex=3D"-1"><a class=3D"header-anchor" href=
=3D"https://slickgpt.com/t/5#convert-to-onnx" aria-hidden=3D"true">#</a> Co=
nvert to ONNX</h4>
<pre><code class=3D"hljs language-bash">pip install onnx onnxruntime
</code></pre>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">from</span> transformers <span class=3D"hljs-k=
eyword">import</span> Wav2Vec2ForCTC

<span class=3D"hljs-comment"># Load the fine-tuned model</span>
model =3D Wav2Vec2ForCTC.from_pretrained(<span class=3D"hljs-string">"./wav=
2vec2-small-korean"</span>)

<span class=3D"hljs-comment"># Export the model to ONNX</span>
dummy_input =3D torch.zeros(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">16000</span>)  <span class=3D"hljs-comment"># Example in=
put tensor</span>
torch.onnx.export(model, dummy_input, <span class=3D"hljs-string">"wav2vec2=
-small-korean.onnx"</span>)
</code></pre>
<p>This approach will help you create a smaller and efficient ASR model sui=
table for mobile devices. Adjust the parameters and dataset paths as needed=
 for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 4:=
25 PM">4:25 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>Use online dataset free available instead of custom da=
taset.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 4:25 PM">4:25 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Sure, you can use a publicly available dataset like the Common Voice datas=
et by Mozilla, which has Korean speech data. Below is a step-by-step guide =
to fine-tune a smaller Wav2Vec2.0 model using the Common Voice dataset.</p>
<h3 id=3D"step-1-install-necessary-libraries" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-necessary-lib=
raries" aria-hidden=3D"true">#</a> Step 1: Install Necessary Libraries</h3>
<p>Make sure you have the required libraries installed:</p>
<pre><code class=3D"hljs language-bash">pip install transformers datasets t=
orch soundfile
</code></pre>
<h3 id=3D"step-2-load-a-smaller-pre-trained-model-and-tokenizer" tabindex=
=3D"-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-=
load-a-smaller-pre-trained-model-and-tokenizer" aria-hidden=3D"true">#</a> =
Step 2: Load a Smaller Pre-trained Model and Tokenizer</h3>
<p>Use a smaller variant of the Wav2Vec2.0 model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> Wav2Vec2For=
CTC, Wav2Vec2Processor

<span class=3D"hljs-comment"># Load a smaller pre-trained model</span>
model_name =3D <span class=3D"hljs-string">"facebook/wav2vec2-base"</span>
processor =3D Wav2Vec2Processor.from_pretrained(model_name)
model =3D Wav2Vec2ForCTC.from_pretrained(model_name)
</code></pre>
<h3 id=3D"step-3-load-and-prepare-the-common-voice-dataset" tabindex=3D"-1"=
><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-3-load-an=
d-prepare-the-common-voice-dataset" aria-hidden=3D"true">#</a> Step 3: Load=
 and Prepare the Common Voice Dataset</h3>
<p>Use the <code>datasets</code> library to load and preprocess the Common =
Voice dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> datasets <span class=3D"hljs-keyword">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice =3D load_dataset(<span class=3D"hljs-string">"mozilla-foundati=
on/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, split=
=3D<span class=3D"hljs-string">"train+validation"</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">speech_file_to_array_fn</span>(<span class=3D"hljs-params">batch</span>):
    speech_array, _ =3D sf.read(batch[<span class=3D"hljs-string">"path"</s=
pan>])
    batch[<span class=3D"hljs-string">"speech"</span>] =3D speech_array
    <span class=3D"hljs-keyword">return</span> batch

<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">prepare_dataset</span>(<span class=3D"hljs-params">batch</span>):
    batch[<span class=3D"hljs-string">"input_values"</span>] =3D processor(=
batch[<span class=3D"hljs-string">"speech"</span>], sampling_rate=3D<span c=
lass=3D"hljs-number">16_000</span>).input_values[<span class=3D"hljs-number=
">0</span>]
    <span class=3D"hljs-keyword">with</span> processor.as_target_processor(=
):
        batch[<span class=3D"hljs-string">"labels"</span>] =3D processor(ba=
tch[<span class=3D"hljs-string">"sentence"</span>]).input_ids
    <span class=3D"hljs-keyword">return</span> batch

common_voice =3D common_voice.<span class=3D"hljs-built_in">map</span>(spee=
ch_file_to_array_fn)
common_voice =3D common_voice.<span class=3D"hljs-built_in">map</span>(prep=
are_dataset, remove_columns=3Dcommon_voice.column_names)
</code></pre>
<h3 id=3D"step-4-fine-tune-the-model" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-4-fine-tune-the-model" aria-hid=
den=3D"true">#</a> Step 4: Fine-Tune the Model</h3>
<p>Set up the training arguments and fine-tune the smaller model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> TrainingArg=
uments, Trainer

<span class=3D"hljs-comment"># Define training arguments</span>
training_args =3D TrainingArguments(
    output_dir=3D<span class=3D"hljs-string">"./wav2vec2-small-korean"</spa=
n>,
    group_by_length=3D<span class=3D"hljs-literal">True</span>,
    per_device_train_batch_size=3D<span class=3D"hljs-number">16</span>,
    gradient_accumulation_steps=3D<span class=3D"hljs-number">2</span>,
    evaluation_strategy=3D<span class=3D"hljs-string">"steps"</span>,
    num_train_epochs=3D<span class=3D"hljs-number">3</span>,
    save_steps=3D<span class=3D"hljs-number">400</span>,
    eval_steps=3D<span class=3D"hljs-number">400</span>,
    logging_steps=3D<span class=3D"hljs-number">400</span>,
    learning_rate=3D<span class=3D"hljs-number">3e-4</span>,
    warmup_steps=3D<span class=3D"hljs-number">500</span>,
    save_total_limit=3D<span class=3D"hljs-number">2</span>,
)

<span class=3D"hljs-comment"># Define the data collator</span>
<span class=3D"hljs-keyword">from</span> dataclasses <span class=3D"hljs-ke=
yword">import</span> dataclass
<span class=3D"hljs-keyword">from</span> typing <span class=3D"hljs-keyword=
">import</span> <span class=3D"hljs-type">Dict</span>, <span class=3D"hljs-=
type">List</span>, <span class=3D"hljs-type">Union</span>
<span class=3D"hljs-keyword">import</span> torch

<span class=3D"hljs-meta">@dataclass</span>
<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>DataCollatorCTCWithPadding</span>:
    processor: Wav2Vec2Processor
    padding: <span class=3D"hljs-type">Union</span>[<span class=3D"hljs-bui=
lt_in">bool</span>, <span class=3D"hljs-built_in">str</span>] =3D <span cla=
ss=3D"hljs-literal">True</span>

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__call__</span>(<span class=3D"hljs-params">self, features: <span cla=
ss=3D"hljs-type">List</span>[<span class=3D"hljs-type">Dict</span>[<span cl=
ass=3D"hljs-built_in">str</span>, <span class=3D"hljs-type">Union</span>[<s=
pan class=3D"hljs-type">List</span>[<span class=3D"hljs-built_in">int</span=
>], torch.Tensor]]]</span>) -&gt; <span class=3D"hljs-type">Dict</span>[<sp=
an class=3D"hljs-built_in">str</span>, torch.Tensor]:
        input_features =3D [{<span class=3D"hljs-string">"input_values"</sp=
an>: feature[<span class=3D"hljs-string">"input_values"</span>]} <span clas=
s=3D"hljs-keyword">for</span> feature <span class=3D"hljs-keyword">in</span=
> features]
        label_features =3D [{<span class=3D"hljs-string">"input_ids"</span>=
: feature[<span class=3D"hljs-string">"labels"</span>]} <span class=3D"hljs=
-keyword">for</span> feature <span class=3D"hljs-keyword">in</span> feature=
s]

        batch =3D self.processor.pad(
            input_features,
            padding=3Dself.padding,
            return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
        )
        <span class=3D"hljs-keyword">with</span> processor.as_target_proces=
sor():
            labels_batch =3D self.processor.pad(
                label_features,
                padding=3Dself.padding,
                return_tensors=3D<span class=3D"hljs-string">"pt"</span>,
            )

        batch[<span class=3D"hljs-string">"labels"</span>] =3D labels_batch=
[<span class=3D"hljs-string">"input_ids"</span>].masked_fill(labels_batch.a=
ttention_mask.ne(<span class=3D"hljs-number">1</span>), -<span class=3D"hlj=
s-number">100</span>)

        <span class=3D"hljs-keyword">return</span> batch

data_collator =3D DataCollatorCTCWithPadding(processor=3Dprocessor)

<span class=3D"hljs-comment"># Initialize Trainer</span>
trainer =3D Trainer(
    model=3Dmodel,
    data_collator=3Ddata_collator,
    args=3Dtraining_args,
    train_dataset=3Dcommon_voice,
    eval_dataset=3Dcommon_voice,
    tokenizer=3Dprocessor.feature_extractor,
)

<span class=3D"hljs-comment"># Train the model</span>
trainer.train()
</code></pre>
<h3 id=3D"step-5-evaluate-the-model" tabindex=3D"-1"><a class=3D"header-anc=
hor" href=3D"https://slickgpt.com/t/5#step-5-evaluate-the-model" aria-hidde=
n=3D"true">#</a> Step 5: Evaluate the Model</h3>
<p>Evaluate your fine-tuned model on the dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Ev=
aluate the model</span>
results =3D trainer.evaluate()
<span class=3D"hljs-built_in">print</span>(results)
</code></pre>
<h3 id=3D"model-optimization-for-mobile" tabindex=3D"-1"><a class=3D"header=
-anchor" href=3D"https://slickgpt.com/t/5#model-optimization-for-mobile" ar=
ia-hidden=3D"true">#</a> Model Optimization for Mobile</h3>
<p>To further optimize for mobile deployment, consider converting the model=
 to ONNX format:</p>
<h4 id=3D"convert-to-onnx" tabindex=3D"-1"><a class=3D"header-anchor" href=
=3D"https://slickgpt.com/t/5#convert-to-onnx" aria-hidden=3D"true">#</a> Co=
nvert to ONNX</h4>
<pre><code class=3D"hljs language-bash">pip install onnx onnxruntime
</code></pre>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">from</span> transformers <span class=3D"hljs-k=
eyword">import</span> Wav2Vec2ForCTC

<span class=3D"hljs-comment"># Load the fine-tuned model</span>
model =3D Wav2Vec2ForCTC.from_pretrained(<span class=3D"hljs-string">"./wav=
2vec2-small-korean"</span>)

<span class=3D"hljs-comment"># Export the model to ONNX</span>
dummy_input =3D torch.zeros(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">16000</span>)  <span class=3D"hljs-comment"># Example in=
put tensor</span>
torch.onnx.export(model, dummy_input, <span class=3D"hljs-string">"wav2vec2=
-small-korean.onnx"</span>)
</code></pre>
<p>This approach will help you create a smaller and efficient ASR model sui=
table for mobile devices using the Common Voice dataset. Adjust the paramet=
ers and dataset paths as needed for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 4:=
54 PM">4:54 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>Try speechbrain</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 4:54 PM">4:54 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Certainly! SpeechBrain is an open-source toolkit for speech processing, wh=
ich includes ASR. It provides flexibility and is suitable for creating ligh=
tweight models. Here=E2=80=99s how you can train a small ASR model using Sp=
eechBrain with the Common Voice dataset:</p>
<h3 id=3D"step-1-install-speechbrain-and-dependencies" tabindex=3D"-1"><a c=
lass=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-spee=
chbrain-and-dependencies" aria-hidden=3D"true">#</a> Step 1: Install Speech=
Brain and Dependencies</h3>
<p>First, install SpeechBrain and other necessary packages:</p>
<pre><code class=3D"hljs language-bash">pip install speechbrain
pip install torchaudio
pip install datasets
</code></pre>
<h3 id=3D"step-2-load-and-preprocess-the-common-voice-dataset" tabindex=3D"=
-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-load=
-and-preprocess-the-common-voice-dataset" aria-hidden=3D"true">#</a> Step 2=
: Load and Preprocess the Common Voice Dataset</h3>
<p>Use the <code>datasets</code> library to load the Common Voice dataset a=
nd prepare it for training:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torchaudio
<span class=3D"hljs-keyword">from</span> datasets <span class=3D"hljs-keywo=
rd">import</span> load_dataset, load_metric
<span class=3D"hljs-keyword">import</span> speechbrain <span class=3D"hljs-=
keyword">as</span> sb
<span class=3D"hljs-keyword">from</span> speechbrain.dataio.dataio <span cl=
ass=3D"hljs-keyword">import</span> read_audio
<span class=3D"hljs-keyword">from</span> speechbrain.dataio.batch <span cla=
ss=3D"hljs-keyword">import</span> PaddedBatch

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Define data preparation functions</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">prepare_common_voice</span>(<span class=3D"hljs-params">batch</span>):
    batch[<span class=3D"hljs-string">"speech"</span>] =3D read_audio(batch=
[<span class=3D"hljs-string">"path"</span>])
    batch[<span class=3D"hljs-string">"target"</span>] =3D batch[<span clas=
s=3D"hljs-string">"sentence"</span>]
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(prepare_common_voice)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(prepare_common_voice)
</code></pre>
<h3 id=3D"step-3-define-the-asr-model" tabindex=3D"-1"><a class=3D"header-a=
nchor" href=3D"https://slickgpt.com/t/5#step-3-define-the-asr-model" aria-h=
idden=3D"true">#</a> Step 3: Define the ASR Model</h3>
<p>Define the model architecture using SpeechBrain=E2=80=99s Brain class:</=
p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> speechbrain <span class=3D"hljs-keyword">as</span> sb
<span class=3D"hljs-keyword">from</span> hyperpyyaml <span class=3D"hljs-ke=
yword">import</span> load_hyperpyyaml

<span class=3D"hljs-comment"># Define the model</span>
<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>ASR</span>(sb.Brain):
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">compute_forward</span>(<span class=3D"hljs-params">self, batch, stage=
</span>):
        batch =3D batch.to(self.device)
        wavs, wav_lens =3D batch.speech
        outputs =3D self.modules.wav2vec2(wavs)
        logits =3D self.modules.output(outputs)
        <span class=3D"hljs-keyword">return</span> logits, wav_lens

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">compute_objectives</span>(<span class=3D"hljs-params">self, predictio=
ns, batch, stage</span>):
        logits, wav_lens =3D predictions
        ids =3D batch.<span class=3D"hljs-built_in">id</span>
        targets, target_lens =3D batch.target_encoded
        loss =3D self.hparams.compute_cost(logits, targets, wav_lens, targe=
t_lens)
        <span class=3D"hljs-keyword">return</span> loss

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">fit_batch</span>(<span class=3D"hljs-params">self, batch</span>):
        predictions =3D self.compute_forward(batch, sb.Stage.TRAIN)
        loss =3D self.compute_objectives(predictions, batch, sb.Stage.TRAIN=
)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        <span class=3D"hljs-keyword">return</span> loss.detach()

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">evaluate_batch</span>(<span class=3D"hljs-params">self, batch, stage<=
/span>):
        predictions =3D self.compute_forward(batch, stage)
        loss =3D self.compute_objectives(predictions, batch, stage)
        <span class=3D"hljs-keyword">return</span> loss.detach()

<span class=3D"hljs-comment"># Load the hyperparameters file</span>
<span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">open=
</span>(<span class=3D"hljs-string">'hyperparams.yaml'</span>) <span class=
=3D"hljs-keyword">as</span> fin:
    hparams =3D load_hyperpyyaml(fin)
</code></pre>
<h3 id=3D"step-4-define-data-pipelines" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-4-define-data-pipelines" aria=
-hidden=3D"true">#</a> Step 4: Define Data Pipelines</h3>
<p>Set up data pipelines for loading and tokenizing the dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># De=
fine the data pipeline</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">dataio_prep</span>(<span class=3D"hljs-params">hparams</span>):
    <span class=3D"hljs-comment"># Define audio pipeline</span>
<span class=3D"hljs-meta">    @sb.utils.data_pipeline.takes(<span class=3D"=
hljs-params"><span class=3D"hljs-string">"path"</span></span>)</span>
<span class=3D"hljs-meta">    @sb.utils.data_pipeline.provides(<span class=
=3D"hljs-params"><span class=3D"hljs-string">"speech"</span></span>)</span>
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">audio_pipeline</span>(<span class=3D"hljs-params">path</span>):
        sig =3D read_audio(path)
        <span class=3D"hljs-keyword">yield</span> sig

    <span class=3D"hljs-comment"># Define text pipeline</span>
<span class=3D"hljs-meta">    @sb.utils.data_pipeline.takes(<span class=3D"=
hljs-params"><span class=3D"hljs-string">"sentence"</span></span>)</span>
<span class=3D"hljs-meta">    @sb.utils.data_pipeline.provides(<span class=
=3D"hljs-params"><span class=3D"hljs-string">"target"</span></span>)</span>
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">text_pipeline</span>(<span class=3D"hljs-params">sentence</span>):
        <span class=3D"hljs-keyword">yield</span> sentence

    data_pipeline =3D {
        <span class=3D"hljs-string">"audio"</span>: audio_pipeline,
        <span class=3D"hljs-string">"text"</span>: text_pipeline,
    }

    datasets =3D {
        <span class=3D"hljs-string">"train"</span>: sb.dataio.dataset.Dynam=
icItemDataset.from_dataset(common_voice_train),
        <span class=3D"hljs-string">"test"</span>: sb.dataio.dataset.Dynami=
cItemDataset.from_dataset(common_voice_test),
    }

    sb.dataio.dataset.add_dynamic_item(datasets.values(), data_pipeline)
    sb.dataio.dataset.set_output_keys(
        datasets.values(), [<span class=3D"hljs-string">"id"</span>, <span =
class=3D"hljs-string">"speech"</span>, <span class=3D"hljs-string">"target"=
</span>]
    )

    <span class=3D"hljs-keyword">return</span> datasets
</code></pre>
<h3 id=3D"step-5-training-configuration" tabindex=3D"-1"><a class=3D"header=
-anchor" href=3D"https://slickgpt.com/t/5#step-5-training-configuration" ar=
ia-hidden=3D"true">#</a> Step 5: Training Configuration</h3>
<p>Configure the training process in a <code>hyperparams.yaml</code> file:<=
/p>
<pre><code class=3D"hljs language-yaml"><span class=3D"hljs-comment"># hype=
rparams.yaml</span>
<span class=3D"hljs-attr">output_folder:</span> <span class=3D"hljs-type">!=
ref</span> <span class=3D"hljs-string">./results/</span>

<span class=3D"hljs-comment"># Training parameters</span>
<span class=3D"hljs-attr">lr:</span> <span class=3D"hljs-number">1e-4</span=
>
<span class=3D"hljs-attr">batch_size:</span> <span class=3D"hljs-number">16=
</span>
<span class=3D"hljs-attr">epochs:</span> <span class=3D"hljs-number">10</sp=
an>

<span class=3D"hljs-comment"># Define the model</span>
<span class=3D"hljs-attr">modules:</span>
  <span class=3D"hljs-attr">wav2vec2:</span> <span class=3D"hljs-type">!new=
:</span> <span class=3D"hljs-string">speechbrain.lobes.models.huggingface_w=
av2vec2.Wav2Vec2ASR</span>
    <span class=3D"hljs-attr">source:</span> <span class=3D"hljs-string">fa=
cebook/wav2vec2-base</span>
  <span class=3D"hljs-attr">output:</span> <span class=3D"hljs-type">!new:<=
/span> <span class=3D"hljs-string">torch.nn.Linear</span>
    <span class=3D"hljs-attr">in_features:</span> <span class=3D"hljs-numbe=
r">1024</span>
    <span class=3D"hljs-attr">out_features:</span> <span class=3D"hljs-numb=
er">35</span>

<span class=3D"hljs-comment"># Define the optimizer</span>
<span class=3D"hljs-attr">optimizer:</span> <span class=3D"hljs-type">!new:=
</span> <span class=3D"hljs-string">torch.optim.Adam</span>
  <span class=3D"hljs-attr">params:</span> <span class=3D"hljs-type">!ref</=
span> <span class=3D"hljs-string">&lt;modules.parameters&gt;</span>
  <span class=3D"hljs-attr">lr:</span> <span class=3D"hljs-type">!ref</span=
> <span class=3D"hljs-string">&lt;lr&gt;</span>

<span class=3D"hljs-comment"># Define the loss function</span>
<span class=3D"hljs-attr">compute_cost:</span> <span class=3D"hljs-type">!n=
ew:</span> <span class=3D"hljs-string">speechbrain.nnet.losses.ctc_loss</sp=
an>
    <span class=3D"hljs-attr">reduction:</span> <span class=3D"hljs-string"=
>mean</span>
</code></pre>
<h3 id=3D"step-6-train-the-model" tabindex=3D"-1"><a class=3D"header-anchor=
" href=3D"https://slickgpt.com/t/5#step-6-train-the-model" aria-hidden=3D"t=
rue">#</a> Step 6: Train the Model</h3>
<p>Finally, create a training script and start training:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Im=
port the necessary modules</span>
<span class=3D"hljs-keyword">import</span> os
<span class=3D"hljs-keyword">import</span> torch

<span class=3D"hljs-comment"># Load the hyperparameters</span>
<span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">open=
</span>(<span class=3D"hljs-string">"hyperparams.yaml"</span>) <span class=
=3D"hljs-keyword">as</span> fin:
    hparams =3D load_hyperpyyaml(fin)

<span class=3D"hljs-comment"># Create the datasets</span>
datasets =3D dataio_prep(hparams)

<span class=3D"hljs-comment"># Initialize the Brain object</span>
asr_brain =3D ASR(
    modules=3Dhparams[<span class=3D"hljs-string">"modules"</span>],
    opt_class=3Dhparams[<span class=3D"hljs-string">"optimizer"</span>],
    hparams=3Dhparams,
    run_opts=3D{<span class=3D"hljs-string">"device"</span>: <span class=3D=
"hljs-string">"cuda"</span> <span class=3D"hljs-keyword">if</span> torch.cu=
da.is_available() <span class=3D"hljs-keyword">else</span> <span class=3D"h=
ljs-string">"cpu"</span>},
    checkpointer=3Dsb.utils.checkpoints.Checkpointer(hparams[<span class=3D=
"hljs-string">"output_folder"</span>]),
)

<span class=3D"hljs-comment"># Train the model</span>
asr_brain.fit(
    epoch_counter=3Dsb.utils.epoch_loop.EpochCounter(max_epochs=3Dhparams[<=
span class=3D"hljs-string">"epochs"</span>]),
    train_set=3Ddatasets[<span class=3D"hljs-string">"train"</span>],
    valid_set=3Ddatasets[<span class=3D"hljs-string">"test"</span>],
    train_loader_kwargs=3D{<span class=3D"hljs-string">"batch_size"</span>:=
 hparams[<span class=3D"hljs-string">"batch_size"</span>]},
    valid_loader_kwargs=3D{<span class=3D"hljs-string">"batch_size"</span>:=
 hparams[<span class=3D"hljs-string">"batch_size"</span>]},
)
</code></pre>
<p>This guide provides a basic setup for training a smaller ASR model using=
 SpeechBrain and the Common Voice dataset. Adjust parameters, paths, and ot=
her configurations as needed for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 5:=
02 PM">5:02 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>Why are whisper and espnet on the list? any performanc=
e issue or mobility issue?</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 5:02 PM">5:02 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Whisper and ESPnet are both excellent frameworks for ASR, but there are so=
me considerations for their use, especially when targeting mobile deploymen=
t.</p>
<h3 id=3D"whisper" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https=
://slickgpt.com/t/5#whisper" aria-hidden=3D"true">#</a> Whisper</h3>
<p>Whisper is an ASR model developed by OpenAI, known for its high accuracy=
 and robustness against diverse audio conditions. However, it has some limi=
tations:</p>
<ol>
<li><strong>Model Size</strong>: Whisper models are generally large, which =
can be challenging for deployment on mobile devices with limited storage an=
d memory.</li>
<li><strong>Compute Requirements</strong>: Whisper models require substanti=
al computational resources, making them less suitable for real-time process=
ing on mobile devices without powerful hardware.</li>
<li><strong>Inference Latency</strong>: Due to the model size and complexit=
y, inference times can be longer, which might not meet the real-time requir=
ements on mobile devices.</li>
</ol>
<h3 id=3D"espnet" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https:=
//slickgpt.com/t/5#espnet" aria-hidden=3D"true">#</a> ESPnet</h3>
<p>ESPnet (End-to-End Speech Processing Toolkit) is another powerful and fl=
exible toolkit for speech recognition and other speech-related tasks. While=
 it is a robust tool, there are a few considerations:</p>
<ol>
<li><strong>Complexity</strong>: ESPnet is highly modular and flexible but =
can be complex to set up and fine-tune, especially for newcomers.</li>
<li><strong>Resource Intensive</strong>: Like Whisper, ESPnet models often =
require considerable computational resources, which can pose challenges for=
 deployment on mobile devices.</li>
<li><strong>Model Size</strong>: ESPnet models can also be large, making th=
em less ideal for mobile environments with limited storage and memory.</li>
</ol>
<h3 id=3D"comparison-with-smaller-models" tabindex=3D"-1"><a class=3D"heade=
r-anchor" href=3D"https://slickgpt.com/t/5#comparison-with-smaller-models" =
aria-hidden=3D"true">#</a> Comparison with Smaller Models</h3>
<p>Models like Wav2Vec 2.0 or distilled versions of it, and toolkits like S=
peechBrain, offer a more balanced trade-off between performance and resourc=
e requirements. These models are often more suitable for mobile deployment =
due to:</p>
<ol>
<li><strong>Smaller Model Size</strong>: They can be more easily compressed=
 and optimized for mobile environments.</li>
<li><strong>Lower Computational Requirements</strong>: They are designed to=
 run efficiently on devices with limited computational power.</li>
<li><strong>Flexibility and Simplicity</strong>: Toolkits like SpeechBrain =
provide straightforward APIs and are easier to set up and customize for spe=
cific use cases.</li>
</ol>
<h3 id=3D"summary" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https=
://slickgpt.com/t/5#summary" aria-hidden=3D"true">#</a> Summary</h3>
<p>While Whisper and ESPnet are both powerful and high-performing ASR frame=
works, their resource demands and model sizes make them less ideal for mobi=
le deployment. For mobile applications, using smaller, more efficient model=
s like those provided by Wav2Vec 2.0 or SpeechBrain is generally a better c=
hoice due to their balance of performance and resource efficiency.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 5:=
09 PM">5:09 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>Try whisper</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 5:09 PM">5:09 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Sure! Whisper by OpenAI is a robust ASR model known for its high accuracy.=
 Although it=E2=80=99s larger and more resource-intensive than some other m=
odels, you can still use it effectively, especially if you manage to optimi=
ze it for your specific use case. Here=E2=80=99s how you can fine-tune and =
use Whisper for Korean ASR using a publicly available dataset like Common V=
oice.</p>
<h3 id=3D"step-1-install-necessary-libraries" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-necessary-lib=
raries" aria-hidden=3D"true">#</a> Step 1: Install Necessary Libraries</h3>
<p>First, install the required libraries:</p>
<pre><code class=3D"hljs language-bash">pip install transformers datasets t=
orch soundfile
pip install git+https://github.com/openai/whisper.git
</code></pre>
<h3 id=3D"step-2-load-and-preprocess-the-common-voice-dataset" tabindex=3D"=
-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-load=
-and-preprocess-the-common-voice-dataset" aria-hidden=3D"true">#</a> Step 2=
: Load and Preprocess the Common Voice Dataset</h3>
<p>Use the <code>datasets</code> library to load and preprocess the Common =
Voice dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> datasets <span class=3D"hljs-keyword">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> whisper

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">preprocess</span>(<span class=3D"hljs-params">batch</span>):
    audio =3D whisper.load_audio(batch[<span class=3D"hljs-string">"path"</=
span>])
    batch[<span class=3D"hljs-string">"audio"</span>] =3D whisper.pad_or_tr=
im(audio)
    batch[<span class=3D"hljs-string">"text"</span>] =3D batch[<span class=
=3D"hljs-string">"sentence"</span>]
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(preprocess)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(preprocess)
</code></pre>
<h3 id=3D"step-3-define-the-model-and-tokenizer" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-3-define-the-model=
-and-tokenizer" aria-hidden=3D"true">#</a> Step 3: Define the Model and Tok=
enizer</h3>
<p>Load the Whisper model and processor:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> WhisperProc=
essor, WhisperForConditionalGeneration

<span class=3D"hljs-comment"># Load Whisper model and processor</span>
model_name =3D <span class=3D"hljs-string">"openai/whisper-base"</span>
processor =3D WhisperProcessor.from_pretrained(model_name)
model =3D WhisperForConditionalGeneration.from_pretrained(model_name)

<span class=3D"hljs-comment"># Adjust the model for fine-tuning</span>
model.config.forced_decoder_ids =3D processor.get_decoder_prompt_ids(langua=
ge=3D<span class=3D"hljs-string">"ko"</span>, task=3D<span class=3D"hljs-st=
ring">"transcribe"</span>)
</code></pre>
<h3 id=3D"step-4-prepare-data-loaders" tabindex=3D"-1"><a class=3D"header-a=
nchor" href=3D"https://slickgpt.com/t/5#step-4-prepare-data-loaders" aria-h=
idden=3D"true">#</a> Step 4: Prepare Data Loaders</h3>
<p>Convert the dataset into PyTorch data loaders for training:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> torch.utils.data <span class=3D"hljs-keyword">import</span> DataLoa=
der

<span class=3D"hljs-comment"># Define collate function</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">collate_fn</span>(<span class=3D"hljs-params">batch</span>):
    input_features =3D [processor(feature[<span class=3D"hljs-string">"audi=
o"</span>], sampling_rate=3D<span class=3D"hljs-number">16000</span>).input=
_features <span class=3D"hljs-keyword">for</span> feature <span class=3D"hl=
js-keyword">in</span> batch]
    labels =3D [processor(feature[<span class=3D"hljs-string">"text"</span>=
]).input_ids <span class=3D"hljs-keyword">for</span> feature <span class=3D=
"hljs-keyword">in</span> batch]
    input_features =3D torch.tensor(input_features)
    labels =3D torch.tensor(labels)
    <span class=3D"hljs-keyword">return</span> input_features, labels

<span class=3D"hljs-comment"># Create data loaders</span>
train_dataloader =3D DataLoader(common_voice_train, batch_size=3D<span clas=
s=3D"hljs-number">8</span>, shuffle=3D<span class=3D"hljs-literal">True</sp=
an>, collate_fn=3Dcollate_fn)
test_dataloader =3D DataLoader(common_voice_test, batch_size=3D<span class=
=3D"hljs-number">8</span>, shuffle=3D<span class=3D"hljs-literal">False</sp=
an>, collate_fn=3Dcollate_fn)
</code></pre>
<h3 id=3D"step-5-fine-tune-the-model" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-5-fine-tune-the-model" aria-hid=
den=3D"true">#</a> Step 5: Fine-Tune the Model</h3>
<p>Set up the training loop:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">from</span> torch.optim <span class=3D"hljs-ke=
yword">import</span> AdamW
<span class=3D"hljs-keyword">from</span> tqdm <span class=3D"hljs-keyword">=
import</span> tqdm

<span class=3D"hljs-comment"># Define optimizer</span>
optimizer =3D AdamW(model.parameters(), lr=3D<span class=3D"hljs-number">1e=
-5</span>)

<span class=3D"hljs-comment"># Move model to GPU if available</span>
device =3D torch.device(<span class=3D"hljs-string">"cuda"</span> <span cla=
ss=3D"hljs-keyword">if</span> torch.cuda.is_available() <span class=3D"hljs=
-keyword">else</span> <span class=3D"hljs-string">"cpu"</span>)
model.to(device)

<span class=3D"hljs-comment"># Training loop</span>
num_epochs =3D <span class=3D"hljs-number">3</span>
<span class=3D"hljs-keyword">for</span> epoch <span class=3D"hljs-keyword">=
in</span> <span class=3D"hljs-built_in">range</span>(num_epochs):
    model.train()
    train_loss =3D <span class=3D"hljs-number">0.0</span>
    <span class=3D"hljs-keyword">for</span> batch <span class=3D"hljs-keywo=
rd">in</span> tqdm(train_dataloader, desc=3D<span class=3D"hljs-string">f"T=
raining Epoch <span class=3D"hljs-subst">{epoch+<span class=3D"hljs-number"=
>1</span>}</span>/<span class=3D"hljs-subst">{num_epochs}</span>"</span>):
        input_features, labels =3D batch
        input_features =3D input_features.to(device)
        labels =3D labels.to(device)

        optimizer.zero_grad()
        outputs =3D model(input_features, labels=3Dlabels)
        loss =3D outputs.loss
        loss.backward()
        optimizer.step()
        train_loss +=3D loss.item()

    avg_train_loss =3D train_loss / <span class=3D"hljs-built_in">len</span=
>(train_dataloader)
    <span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">=
f"Epoch <span class=3D"hljs-subst">{epoch+<span class=3D"hljs-number">1</sp=
an>}</span> - Training Loss: <span class=3D"hljs-subst">{avg_train_loss:<sp=
an class=3D"hljs-number">.4</span>f}</span>"</span>)

    <span class=3D"hljs-comment"># Evaluation loop</span>
    model.<span class=3D"hljs-built_in">eval</span>()
    eval_loss =3D <span class=3D"hljs-number">0.0</span>
    <span class=3D"hljs-keyword">with</span> torch.no_grad():
        <span class=3D"hljs-keyword">for</span> batch <span class=3D"hljs-k=
eyword">in</span> tqdm(test_dataloader, desc=3D<span class=3D"hljs-string">=
f"Evaluating Epoch <span class=3D"hljs-subst">{epoch+<span class=3D"hljs-nu=
mber">1</span>}</span>/<span class=3D"hljs-subst">{num_epochs}</span>"</spa=
n>):
            input_features, labels =3D batch
            input_features =3D input_features.to(device)
            labels =3D labels.to(device)

            outputs =3D model(input_features, labels=3Dlabels)
            loss =3D outputs.loss
            eval_loss +=3D loss.item()

    avg_eval_loss =3D eval_loss / <span class=3D"hljs-built_in">len</span>(=
test_dataloader)
    <span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">=
f"Epoch <span class=3D"hljs-subst">{epoch+<span class=3D"hljs-number">1</sp=
an>}</span> - Evaluation Loss: <span class=3D"hljs-subst">{avg_eval_loss:<s=
pan class=3D"hljs-number">.4</span>f}</span>"</span>)
</code></pre>
<h3 id=3D"step-6-save-the-fine-tuned-model" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-6-save-the-fine-tuned-mod=
el" aria-hidden=3D"true">#</a> Step 6: Save the Fine-Tuned Model</h3>
<p>Save the model and processor for later use:</p>
<pre><code class=3D"hljs language-python">model.save_pretrained(<span class=
=3D"hljs-string">"whisper-korean-asr"</span>)
processor.save_pretrained(<span class=3D"hljs-string">"whisper-korean-asr"<=
/span>)
</code></pre>
<h3 id=3D"step-7-inference-with-the-fine-tuned-model" tabindex=3D"-1"><a cl=
ass=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-7-inference-wit=
h-the-fine-tuned-model" aria-hidden=3D"true">#</a> Step 7: Inference with t=
he Fine-Tuned Model</h3>
<p>Use the fine-tuned model for inference:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Lo=
ad the fine-tuned model and processor</span>
model =3D WhisperForConditionalGeneration.from_pretrained(<span class=3D"hl=
js-string">"whisper-korean-asr"</span>)
processor =3D WhisperProcessor.from_pretrained(<span class=3D"hljs-string">=
"whisper-korean-asr"</span>)

<span class=3D"hljs-comment"># Move model to GPU if available</span>
device =3D torch.device(<span class=3D"hljs-string">"cuda"</span> <span cla=
ss=3D"hljs-keyword">if</span> torch.cuda.is_available() <span class=3D"hljs=
-keyword">else</span> <span class=3D"hljs-string">"cpu"</span>)
model.to(device)

<span class=3D"hljs-comment"># Load an example audio file</span>
audio_path =3D <span class=3D"hljs-string">"path_to_audio_file.wav"</span>
audio =3D whisper.load_audio(audio_path)
audio =3D whisper.pad_or_trim(audio)

<span class=3D"hljs-comment"># Preprocess the audio</span>
input_features =3D processor(audio, sampling_rate=3D<span class=3D"hljs-num=
ber">16000</span>).input_features
input_features =3D torch.tensor(input_features).unsqueeze(<span class=3D"hl=
js-number">0</span>).to(device)

<span class=3D"hljs-comment"># Generate predictions</span>
<span class=3D"hljs-keyword">with</span> torch.no_grad():
    predicted_ids =3D model.generate(input_features)
    transcription =3D processor.batch_decode(predicted_ids, skip_special_to=
kens=3D<span class=3D"hljs-literal">True</span>)

<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"Tra=
nscription:"</span>, transcription[<span class=3D"hljs-number">0</span>])
</code></pre>
<p>This guide outlines the process of fine-tuning Whisper for Korean ASR us=
ing the Common Voice dataset. Adjust the parameters and paths as needed for=
 your specific use case and dataset. Whisper, though resource-intensive, ca=
n deliver high accuracy for ASR tasks.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 5:=
18 PM">5:18 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>How to convert this pretrained model into onnx model</=
p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 5:18 PM">5:18 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Converting a pre-trained Whisper model into ONNX format involves a few ste=
ps. ONNX (Open Neural Network Exchange) is a format designed to allow model=
s to be used across different frameworks and platforms, including mobile de=
vices. Here=E2=80=99s how you can convert a fine-tuned Whisper model into O=
NNX:</p>
<h3 id=3D"step-1-install-required-libraries" tabindex=3D"-1"><a class=3D"he=
ader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-required-libra=
ries" aria-hidden=3D"true">#</a> Step 1: Install Required Libraries</h3>
<p>Ensure you have the necessary libraries installed:</p>
<pre><code class=3D"hljs language-bash">pip install torch transformers onnx=
 onnxruntime
</code></pre>
<h3 id=3D"step-2-load-the-fine-tuned-model" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-2-load-the-fine-tuned-mod=
el" aria-hidden=3D"true">#</a> Step 2: Load the Fine-Tuned Model</h3>
<p>Load your fine-tuned Whisper model and processor:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> WhisperForC=
onditionalGeneration, WhisperProcessor

<span class=3D"hljs-comment"># Load the fine-tuned model and processor</spa=
n>
model =3D WhisperForConditionalGeneration.from_pretrained(<span class=3D"hl=
js-string">"whisper-korean-asr"</span>)
processor =3D WhisperProcessor.from_pretrained(<span class=3D"hljs-string">=
"whisper-korean-asr"</span>)
</code></pre>
<h3 id=3D"step-3-prepare-the-model-for-export" tabindex=3D"-1"><a class=3D"=
header-anchor" href=3D"https://slickgpt.com/t/5#step-3-prepare-the-model-fo=
r-export" aria-hidden=3D"true">#</a> Step 3: Prepare the Model for Export</=
h3>
<p>You need to define a helper function to handle the model=E2=80=99s forwa=
rd pass for the ONNX conversion.</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch

<span class=3D"hljs-comment"># Function to handle the model's forward pass<=
/span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">forward_pass</span>(<span class=3D"hljs-params">input_features</span>):
    <span class=3D"hljs-comment"># Move the input to the appropriate device=
</span>
    input_features =3D input_features.to(device)
   =20
    <span class=3D"hljs-comment"># Forward pass through the model</span>
    outputs =3D model(input_features)
   =20
    <span class=3D"hljs-keyword">return</span> outputs.logits

<span class=3D"hljs-comment"># Move model to GPU if available</span>
device =3D torch.device(<span class=3D"hljs-string">"cuda"</span> <span cla=
ss=3D"hljs-keyword">if</span> torch.cuda.is_available() <span class=3D"hljs=
-keyword">else</span> <span class=3D"hljs-string">"cpu"</span>)
model.to(device)
model.<span class=3D"hljs-built_in">eval</span>()
</code></pre>
<h3 id=3D"step-4-define-a-dummy-input" tabindex=3D"-1"><a class=3D"header-a=
nchor" href=3D"https://slickgpt.com/t/5#step-4-define-a-dummy-input" aria-h=
idden=3D"true">#</a> Step 4: Define a Dummy Input</h3>
<p>Create a dummy input that matches the input signature of the model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># De=
fine a dummy input in the same shape as your model expects</span>
dummy_input =3D torch.randn(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">80</span>, <span class=3D"hljs-number">3000</span>).to(d=
evice)  <span class=3D"hljs-comment"># Example input shape (batch_size, fea=
ture_dim, seq_length)</span>
</code></pre>
<h3 id=3D"step-5-export-the-model-to-onnx" tabindex=3D"-1"><a class=3D"head=
er-anchor" href=3D"https://slickgpt.com/t/5#step-5-export-the-model-to-onnx=
" aria-hidden=3D"true">#</a> Step 5: Export the Model to ONNX</h3>
<p>Use <code>torch.onnx.export</code> to convert the model:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> os

<span class=3D"hljs-comment"># Export the model to ONNX</span>
onnx_model_path =3D <span class=3D"hljs-string">"whisper_korean_asr.onnx"</=
span>
torch.onnx.export(
    model,
    dummy_input,
    onnx_model_path,
    input_names=3D[<span class=3D"hljs-string">"input_features"</span>],
    output_names=3D[<span class=3D"hljs-string">"logits"</span>],
    dynamic_axes=3D{
        <span class=3D"hljs-string">"input_features"</span>: {<span class=
=3D"hljs-number">0</span>: <span class=3D"hljs-string">"batch_size"</span>,=
 <span class=3D"hljs-number">2</span>: <span class=3D"hljs-string">"sequenc=
e_length"</span>},  <span class=3D"hljs-comment"># Variable length axes</sp=
an>
        <span class=3D"hljs-string">"logits"</span>: {<span class=3D"hljs-n=
umber">0</span>: <span class=3D"hljs-string">"batch_size"</span>, <span cla=
ss=3D"hljs-number">1</span>: <span class=3D"hljs-string">"sequence_length"<=
/span>}
    },
    opset_version=3D<span class=3D"hljs-number">11</span>,
)

<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">f"Mo=
del successfully exported to <span class=3D"hljs-subst">{onnx_model_path}</=
span>"</span>)
</code></pre>
<h3 id=3D"step-6-verify-the-onnx-model" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-6-verify-the-onnx-model" aria=
-hidden=3D"true">#</a> Step 6: Verify the ONNX Model</h3>
<p>Load the ONNX model and verify it using <code>onnxruntime</code>:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(onnx_model_path)

<span class=3D"hljs-comment"># Verify the model by running an inference</sp=
an>
onnx_inputs =3D {<span class=3D"hljs-string">"input_features"</span>: dummy=
_input.cpu().numpy()}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output shape:"</span>, onnx_outputs[<span class=3D"hljs-number">0</=
span>].shape)
</code></pre>
<p>This code converts your fine-tuned Whisper model into ONNX format and ve=
rifies the conversion by running an inference. This ONNX model can now be o=
ptimized further and used for deployment on various platforms, including mo=
bile devices.</p>
<h3 id=3D"notes" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https:/=
/slickgpt.com/t/5#notes" aria-hidden=3D"true">#</a> Notes:</h3>
<ol>
<li><strong>Dynamic Axes</strong>: The <code>dynamic_axes</code> parameter =
allows the ONNX model to accept variable-length inputs, which is crucial fo=
r inference on variable-length audio sequences.</li>
<li><strong>Optimization</strong>: After exporting to ONNX, consider using =
tools like ONNX Runtime or TensorRT to optimize the model for better perfor=
mance on your target deployment platform.</li>
</ol>
<p>By following these steps, you can convert your fine-tuned Whisper ASR mo=
del into an ONNX model, making it suitable for deployment on various platfo=
rms, including mobile devices.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 5:=
29 PM">5:29 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>Try espnet</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 5:29 PM">5:29 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Certainly! ESPnet (End-to-End Speech Processing Toolkit) is a powerful too=
lkit for ASR and other speech processing tasks. Below, I=E2=80=99ll guide y=
ou through the process of using ESPnet to train a Korean ASR model using th=
e Common Voice dataset and then converting that model to ONNX for deploymen=
t:</p>
<h3 id=3D"step-1-install-espnet-and-dependencies" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-espnet-a=
nd-dependencies" aria-hidden=3D"true">#</a> Step 1: Install ESPnet and Depe=
ndencies</h3>
<p>First, install ESPnet and its dependencies:</p>
<pre><code class=3D"hljs language-bash">git <span class=3D"hljs-built_in">c=
lone</span> https://github.com/espnet/espnet
<span class=3D"hljs-built_in">cd</span> espnet
pip install -e .
</code></pre>
<h3 id=3D"step-2-prepare-the-common-voice-dataset" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-prepare-the-comm=
on-voice-dataset" aria-hidden=3D"true">#</a> Step 2: Prepare the Common Voi=
ce Dataset</h3>
<p>ESPnet requires specific file formats and directories for datasets. Here=
=E2=80=99s how you can prepare the Common Voice dataset:</p>
<ol>
<li><strong>Download the Dataset</strong>: Use the <code>datasets</code> li=
brary to download the Common Voice dataset.</li>
<li><strong>Convert and Organize</strong>: Convert the dataset into a forma=
t that ESPnet can use.</li>
</ol>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> os
<span class=3D"hljs-keyword">from</span> datasets <span class=3D"hljs-keywo=
rd">import</span> load_dataset

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Define paths</span>
data_dir =3D <span class=3D"hljs-string">"data"</span>
os.makedirs(data_dir, exist_ok=3D<span class=3D"hljs-literal">True</span>)
train_dir =3D os.path.join(data_dir, <span class=3D"hljs-string">"train"</s=
pan>)
test_dir =3D os.path.join(data_dir, <span class=3D"hljs-string">"test"</spa=
n>)
os.makedirs(train_dir, exist_ok=3D<span class=3D"hljs-literal">True</span>)
os.makedirs(test_dir, exist_ok=3D<span class=3D"hljs-literal">True</span>)

<span class=3D"hljs-comment"># Save audio files and transcriptions</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">save_common_voice</span>(<span class=3D"hljs-params">dataset, save_dir</s=
pan>):
    <span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">=
open</span>(os.path.join(save_dir, <span class=3D"hljs-string">"wav.scp"</s=
pan>), <span class=3D"hljs-string">"w"</span>) <span class=3D"hljs-keyword"=
>as</span> wav_scp, \
         <span class=3D"hljs-built_in">open</span>(os.path.join(save_dir, <=
span class=3D"hljs-string">"text"</span>), <span class=3D"hljs-string">"w"<=
/span>) <span class=3D"hljs-keyword">as</span> text_f, \
         <span class=3D"hljs-built_in">open</span>(os.path.join(save_dir, <=
span class=3D"hljs-string">"utt2spk"</span>), <span class=3D"hljs-string">"=
w"</span>) <span class=3D"hljs-keyword">as</span> utt2spk:
        <span class=3D"hljs-keyword">for</span> i, sample <span class=3D"hl=
js-keyword">in</span> <span class=3D"hljs-built_in">enumerate</span>(datase=
t):
            audio_path =3D os.path.join(save_dir, <span class=3D"hljs-strin=
g">f"<span class=3D"hljs-subst">{i}</span>.wav"</span>)
            sample[<span class=3D"hljs-string">"audio"</span>][<span class=
=3D"hljs-string">"array"</span>].tofile(audio_path)
            wav_scp.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{i}</span> <span class=3D"hljs-subst">{audio_path}</span>\n"</span>=
)
            text_f.write(<span class=3D"hljs-string">f"<span class=3D"hljs-=
subst">{i}</span> <span class=3D"hljs-subst">{sample[<span class=3D"hljs-st=
ring">'sentence'</span>]}</span>\n"</span>)
            utt2spk.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{i}</span> <span class=3D"hljs-subst">{i}</span>\n"</span>)  <span =
class=3D"hljs-comment"># dummy utt2spk</span>

save_common_voice(common_voice_train, train_dir)
save_common_voice(common_voice_test, test_dir)
</code></pre>
<h3 id=3D"step-3-set-up-espnet-configuration" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-3-set-up-espnet-configu=
ration" aria-hidden=3D"true">#</a> Step 3: Set Up ESPnet Configuration</h3>
<p>Prepare the configuration files for training. ESPnet uses YAML configura=
tion files to define the training setup. Here=E2=80=99s an example configur=
ation:</p>
<p>Create a directory for your configuration and model files:</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-built_in">mkdir=
</span> -p exp/whisper_asr/config
</code></pre>
<p>Create a <code>config.yaml</code> file inside <code>exp/whisper_asr/conf=
ig</code>:</p>
<pre><code class=3D"hljs language-yaml"><span class=3D"hljs-comment"># conf=
ig.yaml</span>
<span class=3D"hljs-attr">dataset:</span>
  <span class=3D"hljs-attr">train:</span> <span class=3D"hljs-string">"data=
/train"</span>
  <span class=3D"hljs-attr">valid:</span> <span class=3D"hljs-string">"data=
/test"</span>

<span class=3D"hljs-attr">model:</span>
  <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"whisp=
er_asr"</span>
  <span class=3D"hljs-attr">frontend:</span>=20
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Log=
MelFilterBank"</span>
    <span class=3D"hljs-attr">fs:</span> <span class=3D"hljs-number">16000<=
/span>
    <span class=3D"hljs-attr">n_mels:</span> <span class=3D"hljs-number">80=
</span>
    <span class=3D"hljs-attr">n_fft:</span> <span class=3D"hljs-number">400=
</span>
    <span class=3D"hljs-attr">hop_length:</span> <span class=3D"hljs-number=
">160</span>
    <span class=3D"hljs-attr">fmin:</span> <span class=3D"hljs-number">0</s=
pan>
    <span class=3D"hljs-attr">fmax:</span> <span class=3D"hljs-number">8000=
</span>

  <span class=3D"hljs-attr">encoder:</span>
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Con=
former"</span>
    <span class=3D"hljs-attr">input_size:</span> <span class=3D"hljs-number=
">80</span>
    <span class=3D"hljs-attr">output_size:</span> <span class=3D"hljs-numbe=
r">256</span>
    <span class=3D"hljs-attr">attention_heads:</span> <span class=3D"hljs-n=
umber">4</span>
    <span class=3D"hljs-attr">linear_units:</span> <span class=3D"hljs-numb=
er">2048</span>
    <span class=3D"hljs-attr">num_blocks:</span> <span class=3D"hljs-number=
">12</span>

  <span class=3D"hljs-attr">decoder:</span>
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Tra=
nsformerDecoder"</span>
    <span class=3D"hljs-attr">vocab_size:</span> <span class=3D"hljs-number=
">5000</span>
    <span class=3D"hljs-attr">attention_heads:</span> <span class=3D"hljs-n=
umber">4</span>
    <span class=3D"hljs-attr">linear_units:</span> <span class=3D"hljs-numb=
er">2048</span>
    <span class=3D"hljs-attr">num_blocks:</span> <span class=3D"hljs-number=
">6</span>

<span class=3D"hljs-attr">training:</span>
  <span class=3D"hljs-attr">batch_size:</span> <span class=3D"hljs-number">=
16</span>
  <span class=3D"hljs-attr">max_epochs:</span> <span class=3D"hljs-number">=
50</span>
  <span class=3D"hljs-attr">learning_rate:</span> <span class=3D"hljs-numbe=
r">0.001</span>
  <span class=3D"hljs-attr">optimizer:</span> <span class=3D"hljs-string">"=
adam"</span>
</code></pre>
<h3 id=3D"step-4-train-the-model" tabindex=3D"-1"><a class=3D"header-anchor=
" href=3D"https://slickgpt.com/t/5#step-4-train-the-model" aria-hidden=3D"t=
rue">#</a> Step 4: Train the Model</h3>
<p>Run the training process using ESPnet=E2=80=99s training script:</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-built_in">cd</s=
pan> espnet/egs2/commonvoice/asr1
./run.sh --stage 1 --stop_stage 5 --ngpu 1 --train_config exp/whisper_asr/c=
onfig/config.yaml
</code></pre>
<h3 id=3D"step-5-convert-the-model-to-onnx" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-5-convert-the-model-to-on=
nx" aria-hidden=3D"true">#</a> Step 5: Convert the Model to ONNX</h3>
<p>After training, you can convert the model to ONNX format for deployment:=
</p>
<ol>
<li><strong>Export the Model</strong>: Use ESPnet=E2=80=99s tools to export=
 the trained model to ONNX.</li>
<li><strong>Verify the Export</strong>: Ensure the ONNX model runs correctl=
y.</li>
</ol>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-comment"># Navi=
gate to the directory with the trained model</span>
<span class=3D"hljs-built_in">cd</span> exp/whisper_asr/results

<span class=3D"hljs-comment"># Export the model to ONNX</span>
python -m espnet2.bin.export_asr_model \
    --asr_train_config exp/whisper_asr/config/config.yaml \
    --asr_model_file exp/whisper_asr/results/model.pth \
    --output_file whisper_asr.onnx \
    --export_format onnx
</code></pre>
<h3 id=3D"step-6-verify-the-onnx-model" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-6-verify-the-onnx-model" aria=
-hidden=3D"true">#</a> Step 6: Verify the ONNX Model</h3>
<p>Load the ONNX model and run inference to ensure it works correctly:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort
<span class=3D"hljs-keyword">import</span> numpy <span class=3D"hljs-keywor=
d">as</span> np
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(<span class=3D"hljs-string">"whisper_as=
r.onnx"</span>)

<span class=3D"hljs-comment"># Load an example audio file</span>
audio_path =3D <span class=3D"hljs-string">"path_to_audio_file.wav"</span>
audio, rate =3D sf.read(audio_path)
<span class=3D"hljs-keyword">assert</span> rate =3D=3D <span class=3D"hljs-=
number">16000</span>  <span class=3D"hljs-comment"># ensure the sample rate=
 is 16000 Hz</span>

<span class=3D"hljs-comment"># Preprocess the audio</span>
audio =3D np.expand_dims(audio, axis=3D<span class=3D"hljs-number">0</span>=
)  <span class=3D"hljs-comment"># add batch dimension</span>

<span class=3D"hljs-comment"># Run inference</span>
onnx_inputs =3D {<span class=3D"hljs-string">"input"</span>: audio}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-comment"># Decode the output if needed</span>
<span class=3D"hljs-comment"># This step depends on your model's output for=
mat</span>
<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output:"</span>, onnx_outputs)
</code></pre>
<p>This guide walks you through using ESPnet to train a Korean ASR model us=
ing the Common Voice dataset and converting it to ONNX for deployment. Adju=
st paths and parameters as needed for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 5:=
50 PM">5:50 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>what if I need to customize the model - add layers, re=
move layers, separate language model, use custom tokenizer something like t=
hat. give me instructions</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 5:50 PM">5:50 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Customizing an ASR model with ESPnet involves several steps, including mod=
ifying the model architecture, potentially separating the language model, a=
nd using a custom tokenizer. Here=E2=80=99s a comprehensive guide to help y=
ou achieve this:</p>
<h3 id=3D"step-1-install-espnet-and-dependencies" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-espnet-a=
nd-dependencies" aria-hidden=3D"true">#</a> Step 1: Install ESPnet and Depe=
ndencies</h3>
<p>Ensure you have ESPnet and other necessary dependencies installed:</p>
<pre><code class=3D"hljs language-bash">git <span class=3D"hljs-built_in">c=
lone</span> https://github.com/espnet/espnet.git
<span class=3D"hljs-built_in">cd</span> espnet
pip install -e .
pip install torch onnx onnxruntime soundfile
</code></pre>
<h3 id=3D"step-2-prepare-the-dataset" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-2-prepare-the-dataset" aria-hid=
den=3D"true">#</a> Step 2: Prepare the Dataset</h3>
<p>Prepare the Common Voice dataset as described earlier. Ensure you have t=
he dataset organized in a format that ESPnet can use.</p>
<h3 id=3D"step-3-customize-the-model-architecture" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-3-customize-the-mo=
del-architecture" aria-hidden=3D"true">#</a> Step 3: Customize the Model Ar=
chitecture</h3>
<p>To customize the model, you will need to modify the model configuration =
files and potentially the model scripts. Here=E2=80=99s how:</p>
<ol>
<li><strong>Modify the Configuration Files</strong>: Edit the <code>config.=
yaml</code> to define your custom model architecture.</li>
</ol>
<h4 id=3D"example-of-a-customized-config-yaml" tabindex=3D"-1"><a class=3D"=
header-anchor" href=3D"https://slickgpt.com/t/5#example-of-a-customized-con=
fig-yaml" aria-hidden=3D"true">#</a> Example of a Customized <code>config.y=
aml</code>:</h4>
<pre><code class=3D"hljs language-yaml"><span class=3D"hljs-comment"># conf=
ig.yaml</span>
<span class=3D"hljs-attr">dataset:</span>
  <span class=3D"hljs-attr">train:</span> <span class=3D"hljs-string">"data=
/train"</span>
  <span class=3D"hljs-attr">valid:</span> <span class=3D"hljs-string">"data=
/test"</span>

<span class=3D"hljs-attr">model:</span>
  <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"custo=
m_asr"</span>
  <span class=3D"hljs-attr">frontend:</span>=20
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Log=
MelFilterBank"</span>
    <span class=3D"hljs-attr">fs:</span> <span class=3D"hljs-number">16000<=
/span>
    <span class=3D"hljs-attr">n_mels:</span> <span class=3D"hljs-number">80=
</span>
    <span class=3D"hljs-attr">n_fft:</span> <span class=3D"hljs-number">400=
</span>
    <span class=3D"hljs-attr">hop_length:</span> <span class=3D"hljs-number=
">160</span>
    <span class=3D"hljs-attr">fmin:</span> <span class=3D"hljs-number">0</s=
pan>
    <span class=3D"hljs-attr">fmax:</span> <span class=3D"hljs-number">8000=
</span>

  <span class=3D"hljs-attr">encoder:</span>
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Con=
former"</span>
    <span class=3D"hljs-attr">input_size:</span> <span class=3D"hljs-number=
">80</span>
    <span class=3D"hljs-attr">output_size:</span> <span class=3D"hljs-numbe=
r">256</span>
    <span class=3D"hljs-attr">attention_heads:</span> <span class=3D"hljs-n=
umber">4</span>
    <span class=3D"hljs-attr">linear_units:</span> <span class=3D"hljs-numb=
er">2048</span>
    <span class=3D"hljs-attr">num_blocks:</span> <span class=3D"hljs-number=
">12</span>
    <span class=3D"hljs-attr">additional_layer:</span>  <span class=3D"hljs=
-comment"># Adding a custom layer</span>
      <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"L=
inear"</span>
      <span class=3D"hljs-attr">output_size:</span> <span class=3D"hljs-num=
ber">512</span>

  <span class=3D"hljs-attr">decoder:</span>
    <span class=3D"hljs-attr">name:</span> <span class=3D"hljs-string">"Tra=
nsformerDecoder"</span>
    <span class=3D"hljs-attr">vocab_size:</span> <span class=3D"hljs-number=
">5000</span>
    <span class=3D"hljs-attr">attention_heads:</span> <span class=3D"hljs-n=
umber">4</span>
    <span class=3D"hljs-attr">linear_units:</span> <span class=3D"hljs-numb=
er">2048</span>
    <span class=3D"hljs-attr">num_blocks:</span> <span class=3D"hljs-number=
">6</span>

  <span class=3D"hljs-attr">language_model:</span>  <span class=3D"hljs-com=
ment"># Separate language model configuration</span>
    <span class=3D"hljs-attr">lm_type:</span> <span class=3D"hljs-string">"=
RNNLM"</span>
    <span class=3D"hljs-attr">units:</span> <span class=3D"hljs-number">650=
</span>
    <span class=3D"hljs-attr">layers:</span> <span class=3D"hljs-number">2<=
/span>
    <span class=3D"hljs-attr">dropout_rate:</span> <span class=3D"hljs-numb=
er">0.5</span>

<span class=3D"hljs-attr">training:</span>
  <span class=3D"hljs-attr">batch_size:</span> <span class=3D"hljs-number">=
16</span>
  <span class=3D"hljs-attr">max_epochs:</span> <span class=3D"hljs-number">=
50</span>
  <span class=3D"hljs-attr">learning_rate:</span> <span class=3D"hljs-numbe=
r">0.001</span>
  <span class=3D"hljs-attr">optimizer:</span> <span class=3D"hljs-string">"=
adam"</span>
</code></pre>
<ol start=3D"2">
<li><strong>Modify Model Scripts</strong>: If you need more customization, =
you might need to modify the model scripts directly. ESPnet models are defi=
ned in <code>espnet/nets/pytorch_backend/e2e_asr_transformer.py</code> (for=
 transformer models) or similar files.</li>
</ol>
<h3 id=3D"step-4-customize-tokenizer" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-4-customize-tokenizer" aria-hid=
den=3D"true">#</a> Step 4: Customize Tokenizer</h3>
<p>To use a custom tokenizer, you need to define your own tokenizer and int=
egrate it into the ESPnet pipeline.</p>
<h4 id=3D"example-of-custom-tokenizer-integration" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#example-of-custom-token=
izer-integration" aria-hidden=3D"true">#</a> Example of Custom Tokenizer In=
tegration:</h4>
<ol>
<li><strong>Define Custom Tokenizer</strong>: Create your tokenizer script,=
 e.g., <code>custom_tokenizer.py</code>.</li>
</ol>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> AutoTokeniz=
er

<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomTokenizer</span>:
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__init__</span>(<span class=3D"hljs-params">self, model_name=3D<span =
class=3D"hljs-string">"bert-base-multilingual-cased"</span></span>):
        self.tokenizer =3D AutoTokenizer.from_pretrained(model_name)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">encode</span>(<span class=3D"hljs-params">self, text</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.encode(te=
xt, add_special_tokens=3D<span class=3D"hljs-literal">True</span>)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">decode</span>(<span class=3D"hljs-params">self, tokens</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.decode(to=
kens)
</code></pre>
<ol start=3D"2">
<li><strong>Integrate Custom Tokenizer</strong>: Modify the data preparatio=
n script to use your custom tokenizer.</li>
</ol>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># da=
ta_prep.py</span>
<span class=3D"hljs-keyword">from</span> custom_tokenizer <span class=3D"hl=
js-keyword">import</span> CustomTokenizer

tokenizer =3D CustomTokenizer()

<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">preprocess</span>(<span class=3D"hljs-params">batch</span>):
    audio =3D whisper.load_audio(batch[<span class=3D"hljs-string">"path"</=
span>])
    batch[<span class=3D"hljs-string">"audio"</span>] =3D whisper.pad_or_tr=
im(audio)
    batch[<span class=3D"hljs-string">"text"</span>] =3D batch[<span class=
=3D"hljs-string">"sentence"</span>]
    batch[<span class=3D"hljs-string">"text_encoded"</span>] =3D tokenizer.=
encode(batch[<span class=3D"hljs-string">"text"</span>])
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(preprocess)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(preprocess)
</code></pre>
<h3 id=3D"step-5-train-the-customized-model" tabindex=3D"-1"><a class=3D"he=
ader-anchor" href=3D"https://slickgpt.com/t/5#step-5-train-the-customized-m=
odel" aria-hidden=3D"true">#</a> Step 5: Train the Customized Model</h3>
<p>Run the training process using ESPnet=E2=80=99s training script, now con=
figured to use your customized model and tokenizer:</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-built_in">cd</s=
pan> espnet/egs2/commonvoice/asr1
./run.sh --stage 1 --stop_stage 5 --ngpu 1 --train_config exp/custom_asr/co=
nfig/config.yaml
</code></pre>
<h3 id=3D"step-6-convert-the-model-to-onnx" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-6-convert-the-model-to-on=
nx" aria-hidden=3D"true">#</a> Step 6: Convert the Model to ONNX</h3>
<p>After training, you can convert the customized model to ONNX format for =
deployment:</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-comment"># Navi=
gate to the directory with the trained model</span>
<span class=3D"hljs-built_in">cd</span> exp/custom_asr/results

<span class=3D"hljs-comment"># Export the model to ONNX</span>
python -m espnet2.bin.export_asr_model \
    --asr_train_config exp/custom_asr/config/config.yaml \
    --asr_model_file exp/custom_asr/results/model.pth \
    --output_file custom_asr.onnx \
    --export_format onnx
</code></pre>
<h3 id=3D"step-7-verify-the-onnx-model" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-7-verify-the-onnx-model" aria=
-hidden=3D"true">#</a> Step 7: Verify the ONNX Model</h3>
<p>Load the ONNX model and run inference to ensure it works correctly:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort
<span class=3D"hljs-keyword">import</span> numpy <span class=3D"hljs-keywor=
d">as</span> np
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(<span class=3D"hljs-string">"custom_asr=
.onnx"</span>)

<span class=3D"hljs-comment"># Load an example audio file</span>
audio_path =3D <span class=3D"hljs-string">"path_to_audio_file.wav"</span>
audio, rate =3D sf.read(audio_path)
<span class=3D"hljs-keyword">assert</span> rate =3D=3D <span class=3D"hljs-=
number">16000</span>  <span class=3D"hljs-comment"># ensure the sample rate=
 is 16000 Hz</span>

<span class=3D"hljs-comment"># Preprocess the audio</span>
audio =3D np.expand_dims(audio, axis=3D<span class=3D"hljs-number">0</span>=
)  <span class=3D"hljs-comment"># add batch dimension</span>

<span class=3D"hljs-comment"># Run inference</span>
onnx_inputs =3D {<span class=3D"hljs-string">"input"</span>: audio}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-comment"># Decode the output if needed</span>
<span class=3D"hljs-comment"># This step depends on your model's output for=
mat</span>
<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output:"</span>, onnx_outputs)
</code></pre>
<h3 id=3D"summary" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https=
://slickgpt.com/t/5#summary" aria-hidden=3D"true">#</a> Summary</h3>
<p>By following these steps, you can customize an ASR model using ESPnet, i=
ncluding adding/removing layers, integrating a separate language model, and=
 using a custom tokenizer. This comprehensive approach ensures that you can=
 tailor the model to your specific requirements and deploy it in an optimiz=
ed format using ONNX.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 6:=
46 PM">6:46 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>do the same thing with speechbrain</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 6:46 PM">6:46 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Certainly! Here=E2=80=99s how you can customize a SpeechBrain ASR model, i=
ncluding adding/removing layers, using a separate language model, and imple=
menting a custom tokenizer. Then, we=E2=80=99ll convert the model to ONNX f=
or deployment.</p>
<h3 id=3D"step-1-install-speechbrain-and-dependencies" tabindex=3D"-1"><a c=
lass=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-spee=
chbrain-and-dependencies" aria-hidden=3D"true">#</a> Step 1: Install Speech=
Brain and Dependencies</h3>
<p>First, install SpeechBrain and other necessary packages:</p>
<pre><code class=3D"hljs language-bash">pip install speechbrain torchaudio =
datasets onnx onnxruntime
</code></pre>
<h3 id=3D"step-2-prepare-the-common-voice-dataset" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-prepare-the-comm=
on-voice-dataset" aria-hidden=3D"true">#</a> Step 2: Prepare the Common Voi=
ce Dataset</h3>
<p>Use the <code>datasets</code> library to load and preprocess the Common =
Voice dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> os
<span class=3D"hljs-keyword">import</span> torchaudio
<span class=3D"hljs-keyword">from</span> datasets <span class=3D"hljs-keywo=
rd">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> speechbrain <span class=3D"hljs-=
keyword">as</span> sb
<span class=3D"hljs-keyword">from</span> speechbrain.dataio.dataio <span cl=
ass=3D"hljs-keyword">import</span> read_audio

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Define paths</span>
data_dir =3D <span class=3D"hljs-string">"data"</span>
os.makedirs(data_dir, exist_ok=3D<span class=3D"hljs-literal">True</span>)

<span class=3D"hljs-comment"># Save audio files and transcriptions</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">save_common_voice</span>(<span class=3D"hljs-params">dataset, save_dir</s=
pan>):
    os.makedirs(save_dir, exist_ok=3D<span class=3D"hljs-literal">True</spa=
n>)
    <span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">=
open</span>(os.path.join(save_dir, <span class=3D"hljs-string">"wav.scp"</s=
pan>), <span class=3D"hljs-string">"w"</span>) <span class=3D"hljs-keyword"=
>as</span> wav_scp, \
         <span class=3D"hljs-built_in">open</span>(os.path.join(save_dir, <=
span class=3D"hljs-string">"text"</span>), <span class=3D"hljs-string">"w"<=
/span>) <span class=3D"hljs-keyword">as</span> text_f, \
         <span class=3D"hljs-built_in">open</span>(os.path.join(save_dir, <=
span class=3D"hljs-string">"utt2spk"</span>), <span class=3D"hljs-string">"=
w"</span>) <span class=3D"hljs-keyword">as</span> utt2spk:
        <span class=3D"hljs-keyword">for</span> i, sample <span class=3D"hl=
js-keyword">in</span> <span class=3D"hljs-built_in">enumerate</span>(datase=
t):
            audio_path =3D os.path.join(save_dir, <span class=3D"hljs-strin=
g">f"<span class=3D"hljs-subst">{i}</span>.wav"</span>)
            torchaudio.save(audio_path, sample[<span class=3D"hljs-string">=
"audio"</span>][<span class=3D"hljs-string">"array"</span>].unsqueeze(<span=
 class=3D"hljs-number">0</span>), <span class=3D"hljs-number">16000</span>)
            wav_scp.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{i}</span> <span class=3D"hljs-subst">{audio_path}</span>\n"</span>=
)
            text_f.write(<span class=3D"hljs-string">f"<span class=3D"hljs-=
subst">{i}</span> <span class=3D"hljs-subst">{sample[<span class=3D"hljs-st=
ring">'sentence'</span>]}</span>\n"</span>)
            utt2spk.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{i}</span> <span class=3D"hljs-subst">{i}</span>\n"</span>)

save_common_voice(common_voice_train, os.path.join(data_dir, <span class=3D=
"hljs-string">"train"</span>))
save_common_voice(common_voice_test, os.path.join(data_dir, <span class=3D"=
hljs-string">"test"</span>))
</code></pre>
<h3 id=3D"step-3-define-custom-tokenizer" tabindex=3D"-1"><a class=3D"heade=
r-anchor" href=3D"https://slickgpt.com/t/5#step-3-define-custom-tokenizer" =
aria-hidden=3D"true">#</a> Step 3: Define Custom Tokenizer</h3>
<p>Create a custom tokenizer script, e.g., <code>custom_tokenizer.py</code>=
:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># cu=
stom_tokenizer.py</span>
<span class=3D"hljs-keyword">from</span> transformers <span class=3D"hljs-k=
eyword">import</span> AutoTokenizer

<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomTokenizer</span>:
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__init__</span>(<span class=3D"hljs-params">self, model_name=3D<span =
class=3D"hljs-string">"bert-base-multilingual-cased"</span></span>):
        self.tokenizer =3D AutoTokenizer.from_pretrained(model_name)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">encode</span>(<span class=3D"hljs-params">self, text</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.encode(te=
xt, add_special_tokens=3D<span class=3D"hljs-literal">True</span>)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">decode</span>(<span class=3D"hljs-params">self, tokens</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.decode(to=
kens)
</code></pre>
<h3 id=3D"step-4-data-preparation-with-custom-tokenizer" tabindex=3D"-1"><a=
 class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-4-data-prepa=
ration-with-custom-tokenizer" aria-hidden=3D"true">#</a> Step 4: Data Prepa=
ration with Custom Tokenizer</h3>
<p>Modify the data preparation script to use your custom tokenizer:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torchaudio
<span class=3D"hljs-keyword">from</span> datasets <span class=3D"hljs-keywo=
rd">import</span> load_dataset
<span class=3D"hljs-keyword">from</span> custom_tokenizer <span class=3D"hl=
js-keyword">import</span> CustomTokenizer

tokenizer =3D CustomTokenizer()

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">preprocess</span>(<span class=3D"hljs-params">batch</span>):
    audio =3D batch[<span class=3D"hljs-string">"audio"</span>][<span class=
=3D"hljs-string">"array"</span>]
    batch[<span class=3D"hljs-string">"audio"</span>] =3D audio
    batch[<span class=3D"hljs-string">"text"</span>] =3D batch[<span class=
=3D"hljs-string">"sentence"</span>]
    batch[<span class=3D"hljs-string">"text_encoded"</span>] =3D tokenizer.=
encode(batch[<span class=3D"hljs-string">"text"</span>])
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(preprocess)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(preprocess)
</code></pre>
<h3 id=3D"step-5-define-the-asr-model-with-custom-layers" tabindex=3D"-1"><=
a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-5-define-th=
e-asr-model-with-custom-layers" aria-hidden=3D"true">#</a> Step 5: Define t=
he ASR Model with Custom Layers</h3>
<p>Define your customized ASR model using SpeechBrain=E2=80=99s Brain class=
:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">import</span> torch.nn <span class=3D"hljs-key=
word">as</span> nn
<span class=3D"hljs-keyword">import</span> speechbrain <span class=3D"hljs-=
keyword">as</span> sb
<span class=3D"hljs-keyword">from</span> hyperpyyaml <span class=3D"hljs-ke=
yword">import</span> load_hyperpyyaml

<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomASR</span>(sb.Brain):
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">compute_forward</span>(<span class=3D"hljs-params">self, batch, stage=
</span>):
        batch =3D batch.to(self.device)
        wavs, wav_lens =3D batch.audio
        features =3D self.modules.wav2vec2(wavs)
        features =3D self.modules.additional_layer(features)
        logits =3D self.modules.output(features)
        <span class=3D"hljs-keyword">return</span> logits, wav_lens

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">compute_objectives</span>(<span class=3D"hljs-params">self, predictio=
ns, batch, stage</span>):
        logits, wav_lens =3D predictions
        ids =3D batch.<span class=3D"hljs-built_in">id</span>
        targets, target_lens =3D batch.text_encoded
        loss =3D self.hparams.compute_cost(logits, targets, wav_lens, targe=
t_lens)
        <span class=3D"hljs-keyword">return</span> loss

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">fit_batch</span>(<span class=3D"hljs-params">self, batch</span>):
        predictions =3D self.compute_forward(batch, sb.Stage.TRAIN)
        loss =3D self.compute_objectives(predictions, batch, sb.Stage.TRAIN=
)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        <span class=3D"hljs-keyword">return</span> loss.detach()

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">evaluate_batch</span>(<span class=3D"hljs-params">self, batch, stage<=
/span>):
        predictions =3D self.compute_forward(batch, stage)
        loss =3D self.compute_objectives(predictions, batch, stage)
        <span class=3D"hljs-keyword">return</span> loss.detach()
</code></pre>
<h3 id=3D"step-6-define-hyperparameters-and-model-configuration" tabindex=
=3D"-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-6-=
define-hyperparameters-and-model-configuration" aria-hidden=3D"true">#</a> =
Step 6: Define Hyperparameters and Model Configuration</h3>
<p>Create a <code>hyperparams.yaml</code> file with your model configuratio=
n:</p>
<pre><code class=3D"hljs language-yaml"><span class=3D"hljs-comment"># hype=
rparams.yaml</span>
<span class=3D"hljs-attr">output_folder:</span> <span class=3D"hljs-type">!=
ref</span> <span class=3D"hljs-string">./results/</span>

<span class=3D"hljs-comment"># Training parameters</span>
<span class=3D"hljs-attr">lr:</span> <span class=3D"hljs-number">1e-4</span=
>
<span class=3D"hljs-attr">batch_size:</span> <span class=3D"hljs-number">16=
</span>
<span class=3D"hljs-attr">epochs:</span> <span class=3D"hljs-number">10</sp=
an>

<span class=3D"hljs-comment"># Define the model</span>
<span class=3D"hljs-attr">modules:</span>
  <span class=3D"hljs-attr">wav2vec2:</span> <span class=3D"hljs-type">!new=
:</span> <span class=3D"hljs-string">speechbrain.lobes.models.huggingface_w=
av2vec2.Wav2Vec2ASR</span>
    <span class=3D"hljs-attr">source:</span> <span class=3D"hljs-string">fa=
cebook/wav2vec2-base</span>
  <span class=3D"hljs-attr">additional_layer:</span> <span class=3D"hljs-ty=
pe">!new:</span> <span class=3D"hljs-string">torch.nn.Linear</span>
    <span class=3D"hljs-attr">in_features:</span> <span class=3D"hljs-numbe=
r">1024</span>
    <span class=3D"hljs-attr">out_features:</span> <span class=3D"hljs-numb=
er">512</span>
  <span class=3D"hljs-attr">output:</span> <span class=3D"hljs-type">!new:<=
/span> <span class=3D"hljs-string">torch.nn.Linear</span>
    <span class=3D"hljs-attr">in_features:</span> <span class=3D"hljs-numbe=
r">512</span>
    <span class=3D"hljs-attr">out_features:</span> <span class=3D"hljs-numb=
er">5000</span>

<span class=3D"hljs-comment"># Define the optimizer</span>
<span class=3D"hljs-attr">optimizer:</span> <span class=3D"hljs-type">!new:=
</span> <span class=3D"hljs-string">torch.optim.Adam</span>
  <span class=3D"hljs-attr">params:</span> <span class=3D"hljs-type">!ref</=
span> <span class=3D"hljs-string">&lt;modules.parameters&gt;</span>
  <span class=3D"hljs-attr">lr:</span> <span class=3D"hljs-type">!ref</span=
> <span class=3D"hljs-string">&lt;lr&gt;</span>

<span class=3D"hljs-comment"># Define the loss function</span>
<span class=3D"hljs-attr">compute_cost:</span> <span class=3D"hljs-type">!n=
ew:</span> <span class=3D"hljs-string">speechbrain.nnet.losses.ctc_loss</sp=
an>
    <span class=3D"hljs-attr">reduction:</span> <span class=3D"hljs-string"=
>mean</span>
</code></pre>
<h3 id=3D"step-7-train-the-model" tabindex=3D"-1"><a class=3D"header-anchor=
" href=3D"https://slickgpt.com/t/5#step-7-train-the-model" aria-hidden=3D"t=
rue">#</a> Step 7: Train the Model</h3>
<p>Create a training script and start training:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># Im=
port the necessary modules</span>
<span class=3D"hljs-keyword">import</span> torch
<span class=3D"hljs-keyword">import</span> speechbrain <span class=3D"hljs-=
keyword">as</span> sb
<span class=3D"hljs-keyword">from</span> hyperpyyaml <span class=3D"hljs-ke=
yword">import</span> load_hyperpyyaml

<span class=3D"hljs-comment"># Load the hyperparameters</span>
<span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">open=
</span>(<span class=3D"hljs-string">"hyperparams.yaml"</span>) <span class=
=3D"hljs-keyword">as</span> fin:
    hparams =3D load_hyperpyyaml(fin)

<span class=3D"hljs-comment"># Data preparation</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">dataio_prepare</span>(<span class=3D"hljs-params">hparams</span>):
    data_pipeline =3D {
        <span class=3D"hljs-string">"audio"</span>: sb.dataio.dataset.Dynam=
icItemDataset.from_dataset(common_voice_train),
        <span class=3D"hljs-string">"text"</span>: sb.dataio.dataset.Dynami=
cItemDataset.from_dataset(common_voice_test),
    }
    sb.dataio.dataset.add_dynamic_item(data_pipeline.values(), <span class=
=3D"hljs-keyword">lambda</span> x: x)
    sb.dataio.dataset.set_output_keys(data_pipeline.values(), [<span class=
=3D"hljs-string">"id"</span>, <span class=3D"hljs-string">"audio"</span>, <=
span class=3D"hljs-string">"text"</span>, <span class=3D"hljs-string">"text=
_encoded"</span>])
    <span class=3D"hljs-keyword">return</span> data_pipeline

datasets =3D dataio_prepare(hparams)

<span class=3D"hljs-comment"># Initialize the Brain object</span>
asr_brain =3D CustomASR(
    modules=3Dhparams[<span class=3D"hljs-string">"modules"</span>],
    opt_class=3Dhparams[<span class=3D"hljs-string">"optimizer"</span>],
    hparams=3Dhparams,
    run_opts=3D{<span class=3D"hljs-string">"device"</span>: <span class=3D=
"hljs-string">"cuda"</span> <span class=3D"hljs-keyword">if</span> torch.cu=
da.is_available() <span class=3D"hljs-keyword">else</span> <span class=3D"h=
ljs-string">"cpu"</span>},
    checkpointer=3Dsb.utils.checkpoints.Checkpointer(hparams[<span class=3D=
"hljs-string">"output_folder"</span>]),
)

<span class=3D"hljs-comment"># Train the model</span>
asr_brain.fit(
    epoch_counter=3Dsb.utils.epoch_loop.EpochCounter(max_epochs=3Dhparams[<=
span class=3D"hljs-string">"epochs"</span>]),
    train_set=3Ddatasets[<span class=3D"hljs-string">"train"</span>],
    valid_set=3Ddatasets[<span class=3D"hljs-string">"test"</span>],
    train_loader_kwargs=3D{<span class=3D"hljs-string">"batch_size"</span>:=
 hparams[<span class=3D"hljs-string">"batch_size"</span>]},
    valid_loader_kwargs=3D{<span class=3D"hljs-string">"batch_size"</span>:=
 hparams[<span class=3D"hljs-string">"batch_size"</span>]},
)
</code></pre>
<h3 id=3D"step-8-convert-the-model-to-onnx" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-8-convert-the-model-to-on=
nx" aria-hidden=3D"true">#</a> Step 8: Convert the Model to ONNX</h3>
<p>After training, convert the model to ONNX format:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">from</span> speechbrain.utils.checkpoints <spa=
n class=3D"hljs-keyword">import</span> Checkpointer

<span class=3D"hljs-comment"># Load the trained model</span>
checkpointer =3D Checkpointer(hparams[<span class=3D"hljs-string">"output_f=
older"</span>])
checkpointer.recover_if_possible(asr_brain)

<span class=3D"hljs-comment"># Set the model to evaluation mode</span>
asr_brain.modules.<span class=3D"hljs-built_in">eval</span>()

<span class=3D"hljs-comment"># Define a dummy input for exporting</span>
dummy_input =3D torch.randn(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">16000</span>, device=3Dasr_brain.device)

<span class=3D"hljs-comment"># Export the model to ONNX</span>
torch.onnx.export(
    asr_brain.modules.wav2vec2,
    dummy_input,
    <span class=3D"hljs-string">"custom_asr.onnx"</span>,
    input_names=3D[<span class=3D"hljs-string">"input"</span>],
    output_names=3D[<span class=3D"hljs-string">"output"</span>],
    dynamic_axes=3D{<span class=3D"hljs-string">"input"</span>: {<span clas=
s=3D"hljs-number">0</span>: <span class=3D"hljs-string">"batch_size"</span>=
, <span class=3D"hljs-number">1</span>: <span class=3D"hljs-string">"sequen=
ce_length"</span>}, <span class=3D"hljs-string">"output"</span>: {<span cla=
ss=3D"hljs-number">0</span>: <span class=3D"hljs-string">"batch_size"</span=
>}},
    opset_version=3D<span class=3D"hljs-number">11</span>,
)
</code></pre>
<h3 id=3D"step-9-verify-the-onnx-model" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-9-verify-the-onnx-model" aria=
-hidden=3D"true">#</a> Step 9: Verify the ONNX Model</h3>
<p>Load the ONNX model and run inference to ensure it works correctly:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort
<span class=3D"hljs-keyword">import</span> numpy <span class=3D"hljs-keywor=
d">as</span> np
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf
<span class=3D"hljs-keyword">import</span> torch

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(<span class=3D"hljs-string">"custom_asr=
.onnx"</span>)

<span class=3D"hljs-comment"># Load an example audio file</span>
audio_path =3D <span class=3D"hljs-string">"path_to_audio_file.wav"</span>
audio, rate =3D sf.read(audio_path)
<span class=3D"hljs-keyword">assert</span> rate =3D=3D <span class=3D"hljs-=
number">16000</span>  <span class=3D"hljs-comment"># ensure the sample rate=
 is 16000 Hz</span>

<span class=3D"hljs-comment"># Preprocess the audio</span>
audio =3D np.expand_dims(audio, axis=3D<span class=3D"hljs-number">0</span>=
)  <span class=3D"hljs-comment"># add batch dimension</span>

<span class=3D"hljs-comment"># Run inference</span>
onnx_inputs =3D {<span class=3D"hljs-string">"input"</span>: audio}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-comment"># Decode the output if needed</span>
<span class=3D"hljs-comment"># This step depends on your model's output for=
mat</span>
<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output:"</span>, onnx_outputs)
</code></pre>
<p>This guide provides the steps to customize a SpeechBrain ASR model, incl=
uding adding/removing layers, using a separate language model, and implemen=
ting a custom tokenizer. It also includes the steps to convert the customiz=
ed model to ONNX for deployment. Adjust paths, parameters, and configuratio=
ns as needed for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 6:=
55 PM">6:55 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>do the same thing with transformers</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 6:55 PM">6:55 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Sure! Using the Transformers library from Hugging Face, you can customize =
an ASR model, including adding/removing layers and using a custom tokenizer=
. Below, I=E2=80=99ll guide you through the process of customizing a Wav2Ve=
c2.0 model, fine-tuning it on the Common Voice dataset, and converting it t=
o ONNX for deployment.</p>
<h3 id=3D"step-1-install-necessary-libraries" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-1-install-necessary-lib=
raries" aria-hidden=3D"true">#</a> Step 1: Install Necessary Libraries</h3>
<p>First, make sure you have the necessary libraries installed:</p>
<pre><code class=3D"hljs language-bash">pip install transformers datasets t=
orch soundfile onnx onnxruntime
</code></pre>
<h3 id=3D"step-2-load-and-preprocess-the-common-voice-dataset" tabindex=3D"=
-1"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-load=
-and-preprocess-the-common-voice-dataset" aria-hidden=3D"true">#</a> Step 2=
: Load and Preprocess the Common Voice Dataset</h3>
<p>Use the <code>datasets</code> library to load and preprocess the Common =
Voice dataset:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> datasets <span class=3D"hljs-keyword">import</span> load_dataset
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load the Common Voice dataset</span>
common_voice_train =3D load_dataset(<span class=3D"hljs-string">"mozilla-fo=
undation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>,=
 split=3D<span class=3D"hljs-string">"train"</span>)
common_voice_test =3D load_dataset(<span class=3D"hljs-string">"mozilla-fou=
ndation/common_voice_8_0"</span>, <span class=3D"hljs-string">"ko"</span>, =
split=3D<span class=3D"hljs-string">"test"</span>)

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">preprocess</span>(<span class=3D"hljs-params">batch</span>):
    audio, _ =3D sf.read(batch[<span class=3D"hljs-string">"path"</span>])
    batch[<span class=3D"hljs-string">"audio"</span>] =3D audio
    batch[<span class=3D"hljs-string">"text"</span>] =3D batch[<span class=
=3D"hljs-string">"sentence"</span>]
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(preprocess)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(preprocess)
</code></pre>
<h3 id=3D"step-3-define-a-custom-tokenizer" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-3-define-a-custom-tokeniz=
er" aria-hidden=3D"true">#</a> Step 3: Define a Custom Tokenizer</h3>
<p>Create a custom tokenizer script, e.g., <code>custom_tokenizer.py</code>=
:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># cu=
stom_tokenizer.py</span>
<span class=3D"hljs-keyword">from</span> transformers <span class=3D"hljs-k=
eyword">import</span> AutoTokenizer

<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomTokenizer</span>:
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__init__</span>(<span class=3D"hljs-params">self, model_name=3D<span =
class=3D"hljs-string">"bert-base-multilingual-cased"</span></span>):
        self.tokenizer =3D AutoTokenizer.from_pretrained(model_name)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">encode</span>(<span class=3D"hljs-params">self, text</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.encode(te=
xt, add_special_tokens=3D<span class=3D"hljs-literal">True</span>)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">decode</span>(<span class=3D"hljs-params">self, tokens</span>):
        <span class=3D"hljs-keyword">return</span> self.tokenizer.decode(to=
kens)
</code></pre>
<h3 id=3D"step-4-prepare-data-loaders-with-custom-tokenizer" tabindex=3D"-1=
"><a class=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-4-prepar=
e-data-loaders-with-custom-tokenizer" aria-hidden=3D"true">#</a> Step 4: Pr=
epare Data Loaders with Custom Tokenizer</h3>
<p>Modify the data preparation script to use your custom tokenizer:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> Wav2Vec2Pro=
cessor
<span class=3D"hljs-keyword">import</span> torch
<span class=3D"hljs-keyword">from</span> torch.utils.data <span class=3D"hl=
js-keyword">import</span> DataLoader

<span class=3D"hljs-comment"># Load the processor</span>
processor =3D Wav2Vec2Processor.from_pretrained(<span class=3D"hljs-string"=
>"facebook/wav2vec2-base"</span>)

<span class=3D"hljs-comment"># Initialize custom tokenizer</span>
<span class=3D"hljs-keyword">from</span> custom_tokenizer <span class=3D"hl=
js-keyword">import</span> CustomTokenizer
tokenizer =3D CustomTokenizer()

<span class=3D"hljs-comment"># Preprocess the dataset</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">preprocess</span>(<span class=3D"hljs-params">batch</span>):
    audio, _ =3D sf.read(batch[<span class=3D"hljs-string">"path"</span>])
    batch[<span class=3D"hljs-string">"input_values"</span>] =3D processor(=
audio, sampling_rate=3D<span class=3D"hljs-number">16000</span>).input_valu=
es[<span class=3D"hljs-number">0</span>]
    batch[<span class=3D"hljs-string">"labels"</span>] =3D tokenizer.encode=
(batch[<span class=3D"hljs-string">"sentence"</span>])
    <span class=3D"hljs-keyword">return</span> batch

common_voice_train =3D common_voice_train.<span class=3D"hljs-built_in">map=
</span>(preprocess)
common_voice_test =3D common_voice_test.<span class=3D"hljs-built_in">map</=
span>(preprocess)

<span class=3D"hljs-comment"># Define a collate function</span>
<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">collate_fn</span>(<span class=3D"hljs-params">batch</span>):
    input_features =3D [item[<span class=3D"hljs-string">"input_values"</sp=
an>] <span class=3D"hljs-keyword">for</span> item <span class=3D"hljs-keywo=
rd">in</span> batch]
    labels =3D [item[<span class=3D"hljs-string">"labels"</span>] <span cla=
ss=3D"hljs-keyword">for</span> item <span class=3D"hljs-keyword">in</span> =
batch]
    input_features =3D processor.pad(input_features, return_tensors=3D<span=
 class=3D"hljs-string">'pt'</span>).input_values
    labels =3D torch.nn.utils.rnn.pad_sequence([torch.tensor(label) <span c=
lass=3D"hljs-keyword">for</span> label <span class=3D"hljs-keyword">in</spa=
n> labels], batch_first=3D<span class=3D"hljs-literal">True</span>, padding=
_value=3Dprocessor.tokenizer.pad_token_id)
    <span class=3D"hljs-keyword">return</span> {<span class=3D"hljs-string"=
>"input_features"</span>: input_features, <span class=3D"hljs-string">"labe=
ls"</span>: labels}

<span class=3D"hljs-comment"># Create data loaders</span>
train_dataloader =3D DataLoader(common_voice_train, batch_size=3D<span clas=
s=3D"hljs-number">16</span>, shuffle=3D<span class=3D"hljs-literal">True</s=
pan>, collate_fn=3Dcollate_fn)
test_dataloader =3D DataLoader(common_voice_test, batch_size=3D<span class=
=3D"hljs-number">16</span>, shuffle=3D<span class=3D"hljs-literal">False</s=
pan>, collate_fn=3Dcollate_fn)
</code></pre>
<h3 id=3D"step-5-define-the-custom-asr-model" tabindex=3D"-1"><a class=3D"h=
eader-anchor" href=3D"https://slickgpt.com/t/5#step-5-define-the-custom-asr=
-model" aria-hidden=3D"true">#</a> Step 5: Define the Custom ASR Model</h3>
<p>Extend the Wav2Vec2 model to include additional layers or modifications:=
</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> Wav2Vec2For=
CTC
<span class=3D"hljs-keyword">import</span> torch.nn <span class=3D"hljs-key=
word">as</span> nn

<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomWav2Vec2ForCTC</span>(<span class=3D"hljs-title class_ inherited__">=
Wav2Vec2ForCTC</span>):
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__init__</span>(<span class=3D"hljs-params">self, config</span>):
        <span class=3D"hljs-built_in">super</span>().__init__(config)
        self.additional_layer =3D nn.Linear(config.hidden_size, config.hidd=
en_size // <span class=3D"hljs-number">2</span>)
        self.output_layer =3D nn.Linear(config.hidden_size // <span class=
=3D"hljs-number">2</span>, config.vocab_size)

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">forward</span>(<span class=3D"hljs-params">self, input_features, labe=
ls=3D<span class=3D"hljs-literal">None</span></span>):
        hidden_states =3D self.wav2vec2(input_features).last_hidden_state
        hidden_states =3D self.additional_layer(hidden_states)
        logits =3D self.output_layer(hidden_states)
        loss =3D <span class=3D"hljs-literal">None</span>
        <span class=3D"hljs-keyword">if</span> labels <span class=3D"hljs-k=
eyword">is</span> <span class=3D"hljs-keyword">not</span> <span class=3D"hl=
js-literal">None</span>:
            loss =3D self.compute_loss(logits, labels)
        <span class=3D"hljs-keyword">return</span> {<span class=3D"hljs-str=
ing">'logits'</span>: logits, <span class=3D"hljs-string">'loss'</span>: lo=
ss}

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">compute_loss</span>(<span class=3D"hljs-params">self, logits, labels<=
/span>):
        <span class=3D"hljs-comment"># Define your loss computation here</s=
pan>
        <span class=3D"hljs-keyword">pass</span>

model =3D CustomWav2Vec2ForCTC.from_pretrained(<span class=3D"hljs-string">=
"facebook/wav2vec2-base"</span>)
</code></pre>
<h3 id=3D"step-6-fine-tune-the-model" tabindex=3D"-1"><a class=3D"header-an=
chor" href=3D"https://slickgpt.com/t/5#step-6-fine-tune-the-model" aria-hid=
den=3D"true">#</a> Step 6: Fine-Tune the Model</h3>
<p>Set up the training loop:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">from=
</span> transformers <span class=3D"hljs-keyword">import</span> TrainingArg=
uments, Trainer

<span class=3D"hljs-comment"># Define training arguments</span>
training_args =3D TrainingArguments(
    output_dir=3D<span class=3D"hljs-string">"./wav2vec2-custom-korean"</sp=
an>,
    group_by_length=3D<span class=3D"hljs-literal">True</span>,
    per_device_train_batch_size=3D<span class=3D"hljs-number">16</span>,
    evaluation_strategy=3D<span class=3D"hljs-string">"steps"</span>,
    num_train_epochs=3D<span class=3D"hljs-number">3</span>,
    save_steps=3D<span class=3D"hljs-number">400</span>,
    eval_steps=3D<span class=3D"hljs-number">400</span>,
    logging_steps=3D<span class=3D"hljs-number">400</span>,
    learning_rate=3D<span class=3D"hljs-number">3e-4</span>,
    warmup_steps=3D<span class=3D"hljs-number">500</span>,
    save_total_limit=3D<span class=3D"hljs-number">2</span>,
)

<span class=3D"hljs-comment"># Initialize Trainer</span>
trainer =3D Trainer(
    model=3Dmodel,
    data_collator=3D<span class=3D"hljs-keyword">lambda</span> data: {<span=
 class=3D"hljs-string">'input_features'</span>: torch.stack([f[<span class=
=3D"hljs-string">'input_features'</span>] <span class=3D"hljs-keyword">for<=
/span> f <span class=3D"hljs-keyword">in</span> data]),
                                <span class=3D"hljs-string">'labels'</span>=
: torch.stack([f[<span class=3D"hljs-string">'labels'</span>] <span class=
=3D"hljs-keyword">for</span> f <span class=3D"hljs-keyword">in</span> data]=
)},
    args=3Dtraining_args,
    train_dataset=3Dcommon_voice_train,
    eval_dataset=3Dcommon_voice_test,
    tokenizer=3Dprocessor.feature_extractor,
)

<span class=3D"hljs-comment"># Train the model</span>
trainer.train()
</code></pre>
<h3 id=3D"step-7-convert-the-model-to-onnx" tabindex=3D"-1"><a class=3D"hea=
der-anchor" href=3D"https://slickgpt.com/t/5#step-7-convert-the-model-to-on=
nx" aria-hidden=3D"true">#</a> Step 7: Convert the Model to ONNX</h3>
<p>Export the fine-tuned model to ONNX:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch

<span class=3D"hljs-comment"># Define dummy input for ONNX export</span>
dummy_input =3D torch.randn(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">16000</span>, device=3Dmodel.device)

<span class=3D"hljs-comment"># Export the model to ONNX</span>
torch.onnx.export(
    model,=20
    dummy_input,
    <span class=3D"hljs-string">"wav2vec2_custom_korean.onnx"</span>,
    input_names=3D[<span class=3D"hljs-string">"input_features"</span>],
    output_names=3D[<span class=3D"hljs-string">"logits"</span>],
    dynamic_axes=3D{<span class=3D"hljs-string">"input_features"</span>: {<=
span class=3D"hljs-number">0</span>: <span class=3D"hljs-string">"batch_siz=
e"</span>, <span class=3D"hljs-number">1</span>: <span class=3D"hljs-string=
">"sequence_length"</span>}, <span class=3D"hljs-string">"logits"</span>: {=
<span class=3D"hljs-number">0</span>: <span class=3D"hljs-string">"batch_si=
ze"</span>, <span class=3D"hljs-number">1</span>: <span class=3D"hljs-strin=
g">"sequence_length"</span>}},
    opset_version=3D<span class=3D"hljs-number">11</span>
)
</code></pre>
<h3 id=3D"step-8-verify-the-onnx-model" tabindex=3D"-1"><a class=3D"header-=
anchor" href=3D"https://slickgpt.com/t/5#step-8-verify-the-onnx-model" aria=
-hidden=3D"true">#</a> Step 8: Verify the ONNX Model</h3>
<p>Load the ONNX model and run inference to ensure it works correctly:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort
<span class=3D"hljs-keyword">import</span> numpy <span class=3D"hljs-keywor=
d">as</span> np
<span class=3D"hljs-keyword">import</span> soundfile <span class=3D"hljs-ke=
yword">as</span> sf

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(<span class=3D"hljs-string">"wav2vec2_c=
ustom_korean.onnx"</span>)

<span class=3D"hljs-comment"># Load an example audio file</span>
audio_path =3D <span class=3D"hljs-string">"path_to_audio_file.wav"</span>
audio, rate =3D sf.read(audio_path)
<span class=3D"hljs-keyword">assert</span> rate =3D=3D <span class=3D"hljs-=
number">16000</span>  <span class=3D"hljs-comment"># ensure the sample rate=
 is 16000 Hz</span>

<span class=3D"hljs-comment"># Preprocess the audio</span>
input_values =3D processor(audio, sampling_rate=3D<span class=3D"hljs-numbe=
r">16000</span>).input_values[<span class=3D"hljs-number">0</span>]
input_values =3D np.expand_dims(input_values, axis=3D<span class=3D"hljs-nu=
mber">0</span>)  <span class=3D"hljs-comment"># add batch dimension</span>

<span class=3D"hljs-comment"># Run inference</span>
onnx_inputs =3D {<span class=3D"hljs-string">"input_features"</span>: input=
_values}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-comment"># Decode the output if needed</span>
<span class=3D"hljs-comment"># This step depends on your model's output for=
mat</span>
<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output:"</span>, onnx_outputs)
</code></pre>
<p>This guide provides the steps to customize a Wav2Vec2 ASR model using th=
e Hugging Face Transformers library, including adding/removing layers, usin=
g a custom tokenizer, and converting the model to ONNX for deployment. Adju=
st paths, parameters, and configurations as needed for your specific use ca=
se.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div =
class=3D"flex items-start py-3"><!----><div class=3D"overflow-hidden bg-bla=
ck rounded h-8 w-8 mr-3"><img referrerpolicy=3D"no-referrer" src=3D"https:/=
/lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G=
9E0cdWXQ=3Ds96-c" alt=3D"" loading=3D"lazy" class=3D"transition h-full w-fu=
ll opacity-100"></div><!----><div class=3D"flex flex-col flex-1"><div class=
=3D"flex items-center"><div class=3D"text-sm leading-none font-bold text-wh=
ite mr-2"><!----><span>You</span><!----></div><div class=3D"text-xs leading=
-none text-slate-400 hover:underline" title=3D"Thursday, May 16, 2024 at 7:=
02 PM">7:02 PM</div></div><div class=3D"flex-1 chat-content break-words" ag=
ent=3D"Assistant"><p>do the same thing with kaldi</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><!----><button cla=
ss=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:bor=
der-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://s=
lickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></div=
><div class=3D"chat-base px-6 group relative hover:bg-slate-800/50"><div cl=
ass=3D"flex items-start py-3"><!----><!----><div class=3D"h-8 w-8 mr-3 roun=
ded flex items-center justify-center bg-slate-500/20"><img src=3D"https://s=
lickgpt.com/img/slickgpt.svg" alt=3D"system" height=3D"24" width=3D"24"></d=
iv><div class=3D"flex flex-col flex-1"><div class=3D"flex items-center"><di=
v class=3D"text-sm leading-none font-bold text-white mr-2"><!----><!----><s=
pan>Assistant</span></div><div class=3D"text-xs leading-none text-slate-400=
 hover:underline" title=3D"Thursday, May 16, 2024 at 7:02 PM">7:02 PM</div>=
</div><div class=3D"flex-1 chat-content break-words" agent=3D"Assistant"><p=
>Kaldi is a highly flexible and powerful toolkit for speech recognition, bu=
t it is more complex and less user-friendly compared to other modern framew=
orks like SpeechBrain or Hugging Face Transformers. However, it provides a =
great deal of flexibility for customizing models, including adding/removing=
 layers and using custom tokenizers. Below is a guide on how to customize a=
 Kaldi ASR model, fine-tune it, and export it to an ONNX format.</p>
<h3 id=3D"step-1-install-kaldi" tabindex=3D"-1"><a class=3D"header-anchor" =
href=3D"https://slickgpt.com/t/5#step-1-install-kaldi" aria-hidden=3D"true"=
>#</a> Step 1: Install Kaldi</h3>
<p>First, you need to install Kaldi. Follow the official <a href=3D"http://=
kaldi-asr.org/doc/install.html">Kaldi installation instructions</a>.</p>
<h3 id=3D"step-2-prepare-the-common-voice-dataset" tabindex=3D"-1"><a class=
=3D"header-anchor" href=3D"https://slickgpt.com/t/5#step-2-prepare-the-comm=
on-voice-dataset" aria-hidden=3D"true">#</a> Step 2: Prepare the Common Voi=
ce Dataset</h3>
<p>Download and prepare the Common Voice dataset. Kaldi uses a specific dir=
ectory structure and file formats.</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-comment"># Navi=
gate to the Kaldi directory</span>
<span class=3D"hljs-built_in">cd</span> ~/kaldi/egs

<span class=3D"hljs-comment"># Create a new directory for your project</spa=
n>
<span class=3D"hljs-built_in">mkdir</span> commonvoice
<span class=3D"hljs-built_in">cd</span> commonvoice

<span class=3D"hljs-comment"># Create necessary directories</span>
<span class=3D"hljs-built_in">mkdir</span> data exp mfcc

<span class=3D"hljs-comment"># Download and preprocess the dataset</span>
<span class=3D"hljs-comment"># (Assuming you have downloaded the Mozilla Co=
mmon Voice dataset)</span>
<span class=3D"hljs-comment"># Adjust paths as necessary</span>
COMMONVOICE_DIR=3D/path/to/common_voice

<span class=3D"hljs-comment"># Prepare data directories</span>
<span class=3D"hljs-keyword">for</span> part <span class=3D"hljs-keyword">i=
n</span> train <span class=3D"hljs-built_in">test</span>; <span class=3D"hl=
js-keyword">do</span>
  <span class=3D"hljs-built_in">mkdir</span> -p data/<span class=3D"hljs-va=
riable">$part</span>
  python3 <span class=3D"hljs-built_in">local</span>/prepare_data.py <span =
class=3D"hljs-variable">$COMMONVOICE_DIR</span> <span class=3D"hljs-variabl=
e">$part</span> data/<span class=3D"hljs-variable">$part</span>
<span class=3D"hljs-keyword">done</span>
</code></pre>
<h3 id=3D"step-3-data-preparation-scripts" tabindex=3D"-1"><a class=3D"head=
er-anchor" href=3D"https://slickgpt.com/t/5#step-3-data-preparation-scripts=
" aria-hidden=3D"true">#</a> Step 3: Data Preparation Scripts</h3>
<p>Create a <code>prepare_data.py</code> script to convert Common Voice dat=
aset to Kaldi format:</p>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-comment"># lo=
cal/prepare_data.py</span>
<span class=3D"hljs-keyword">import</span> os
<span class=3D"hljs-keyword">import</span> sys
<span class=3D"hljs-keyword">import</span> csv

<span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title function_=
">prepare_data</span>(<span class=3D"hljs-params">commonvoice_dir, part, ou=
tput_dir</span>):
    wav_scp =3D <span class=3D"hljs-built_in">open</span>(os.path.join(outp=
ut_dir, <span class=3D"hljs-string">'wav.scp'</span>), <span class=3D"hljs-=
string">'w'</span>)
    text =3D <span class=3D"hljs-built_in">open</span>(os.path.join(output_=
dir, <span class=3D"hljs-string">'text'</span>), <span class=3D"hljs-string=
">'w'</span>)
    utt2spk =3D <span class=3D"hljs-built_in">open</span>(os.path.join(outp=
ut_dir, <span class=3D"hljs-string">'utt2spk'</span>), <span class=3D"hljs-=
string">'w'</span>)
   =20
    <span class=3D"hljs-keyword">with</span> <span class=3D"hljs-built_in">=
open</span>(os.path.join(commonvoice_dir, part, <span class=3D"hljs-string"=
>'validated.tsv'</span>), encoding=3D<span class=3D"hljs-string">'utf-8'</s=
pan>) <span class=3D"hljs-keyword">as</span> tsv_file:
        reader =3D csv.DictReader(tsv_file, delimiter=3D<span class=3D"hljs=
-string">'\t'</span>)
        <span class=3D"hljs-keyword">for</span> row <span class=3D"hljs-key=
word">in</span> reader:
            utt_id =3D row[<span class=3D"hljs-string">'client_id'</span>] =
+ <span class=3D"hljs-string">'-'</span> + row[<span class=3D"hljs-string">=
'path'</span>].replace(<span class=3D"hljs-string">'.mp3'</span>, <span cla=
ss=3D"hljs-string">''</span>)
            wav_path =3D os.path.join(commonvoice_dir, part, <span class=3D=
"hljs-string">'clips'</span>, row[<span class=3D"hljs-string">'path'</span>=
])
            transcription =3D row[<span class=3D"hljs-string">'sentence'</s=
pan>]
           =20
            wav_scp.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{utt_id}</span> sox <span class=3D"hljs-subst">{wav_path}</span> -t=
 wav -r 16000 - |\n"</span>)
            text.write(<span class=3D"hljs-string">f"<span class=3D"hljs-su=
bst">{utt_id}</span> <span class=3D"hljs-subst">{transcription}</span>\n"</=
span>)
            utt2spk.write(<span class=3D"hljs-string">f"<span class=3D"hljs=
-subst">{utt_id}</span> <span class=3D"hljs-subst">{row[<span class=3D"hljs=
-string">'client_id'</span>]}</span>\n"</span>)
   =20
    wav_scp.close()
    text.close()
    utt2spk.close()

<span class=3D"hljs-keyword">if</span> __name__ =3D=3D <span class=3D"hljs-=
string">"__main__"</span>:
    commonvoice_dir =3D sys.argv[<span class=3D"hljs-number">1</span>]
    part =3D sys.argv[<span class=3D"hljs-number">2</span>]
    output_dir =3D sys.argv[<span class=3D"hljs-number">3</span>]
    prepare_data(commonvoice_dir, part, output_dir)
</code></pre>
<h3 id=3D"step-4-feature-extraction" tabindex=3D"-1"><a class=3D"header-anc=
hor" href=3D"https://slickgpt.com/t/5#step-4-feature-extraction" aria-hidde=
n=3D"true">#</a> Step 4: Feature Extraction</h3>
<p>Extract features from the audio files:</p>
<pre><code class=3D"hljs language-bash"><span class=3D"hljs-keyword">for</s=
pan> part <span class=3D"hljs-keyword">in</span> train <span class=3D"hljs-=
built_in">test</span>; <span class=3D"hljs-keyword">do</span>
  steps/make_mfcc.sh --nj 10 --mfcc-config conf/mfcc.conf data/<span class=
=3D"hljs-variable">$part</span> exp/make_mfcc/<span class=3D"hljs-variable"=
>$part</span> mfcc
  steps/compute_cmvn_stats.sh data/<span class=3D"hljs-variable">$part</spa=
n> exp/make_mfcc/<span class=3D"hljs-variable">$part</span> mfcc
<span class=3D"hljs-keyword">done</span>
</code></pre>
<h3 id=3D"step-5-train-a-custom-asr-model" tabindex=3D"-1"><a class=3D"head=
er-anchor" href=3D"https://slickgpt.com/t/5#step-5-train-a-custom-asr-model=
" aria-hidden=3D"true">#</a> Step 5: Train a Custom ASR Model</h3>
<p>Modify the existing Kaldi scripts to include your custom architecture. F=
or example, you can customize the TDNN-F model:</p>
<ol>
<li><strong>Define the neural network architecture</strong> in a configurat=
ion file (e.g., <code>conf/custom_tdnnf.conf</code>):</li>
</ol>
<pre><code class=3D"hljs language-plaintext"># conf/custom_tdnnf.conf
component name=3Didct type=3DFixedAffineComponent input-dim=3D40 output-dim=
=3D40 matrix=3DIdctMatrix num-cols=3D13
component name=3Dtdnn1.affine type=3DNaturalGradientAffineComponent input-d=
im=3D40 output-dim=3D1024
component name=3Dtdnn1.relu type=3DRectifiedLinearComponent dim=3D1024
component name=3Dtdnn1.batchnorm type=3DBatchNormComponent dim=3D1024

# Add more layers as needed
</code></pre>
<ol start=3D"2">
<li><strong>Modify the training script</strong> to use your custom configur=
ation:</li>
</ol>
<pre><code class=3D"hljs language-bash">steps/nnet3/train_tdnnf.sh --cmd <s=
pan class=3D"hljs-string">"<span class=3D"hljs-variable">$train_cmd</span>"=
</span> --feat.online-ivector-dir exp/nnet3/ivectors_train --feat.cmvn-opts=
 <span class=3D"hljs-string">"--norm-means=3Dfalse --norm-vars=3Dfalse"</sp=
an> --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l=
2-regularize 0.00005 --chain.apply-deriv-weights <span class=3D"hljs-litera=
l">false</span> --chain.lm-opts=3D<span class=3D"hljs-string">"--num-extra-=
lm-states=3D2000"</span> --egs.dir <span class=3D"hljs-string">""</span> --=
egs.stage -10 --egs.opts <span class=3D"hljs-string">"--frames-overlap-per-=
eg 0"</span> --egs.chunk-width 140,100,160 --trainer.num-chunk-per-minibatc=
h 128,64 --trainer.frames-per-iter 1500000 --trainer.num-shrinkage-iters 20=
 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-=
final 2 --trainer.optimization.initial-effective-lrate 0.00025 --trainer.op=
timization.final-effective-lrate 0.000025 --trainer.optimization.shrink-val=
ue 1.0 --trainer.max-param-change 2.0 --trainer.num-epochs 2 --cleanup.remo=
ve-egs <span class=3D"hljs-literal">true</span> --feat-dir data/train --tre=
e-dir exp/chain/tree --lat-dir exp/tri4_lats --<span class=3D"hljs-built_in=
">dir</span> exp/chain/custom_tdnnf
</code></pre>
<h3 id=3D"step-6-decode-the-model" tabindex=3D"-1"><a class=3D"header-ancho=
r" href=3D"https://slickgpt.com/t/5#step-6-decode-the-model" aria-hidden=3D=
"true">#</a> Step 6: Decode the Model</h3>
<p>Decode using the trained model:</p>
<pre><code class=3D"hljs language-bash">steps/nnet3/decode.sh --nj 10 --cmd=
 <span class=3D"hljs-string">"<span class=3D"hljs-variable">$decode_cmd</sp=
an>"</span> exp/chain/tree/graph data/test exp/chain/custom_tdnnf/decode
</code></pre>
<h3 id=3D"step-7-export-the-model-to-onnx" tabindex=3D"-1"><a class=3D"head=
er-anchor" href=3D"https://slickgpt.com/t/5#step-7-export-the-model-to-onnx=
" aria-hidden=3D"true">#</a> Step 7: Export the Model to ONNX</h3>
<p>Kaldi does not natively support exporting to ONNX, so you will need to c=
onvert the Kaldi model to a PyTorch model first, and then export it to ONNX=
. This process can be complex, but here=E2=80=99s a general approach:</p>
<ol>
<li><strong>Convert Kaldi model to PyTorch</strong>: You may need to write =
a custom script to load Kaldi model parameters into a PyTorch model.</li>
</ol>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> torch
<span class=3D"hljs-keyword">import</span> kaldi_io

<span class=3D"hljs-comment"># Define PyTorch model equivalent to your Kald=
i model</span>
<span class=3D"hljs-keyword">class</span> <span class=3D"hljs-title class_"=
>CustomTDNNF</span>(torch.nn.Module):
    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">__init__</span>(<span class=3D"hljs-params">self</span>):
        <span class=3D"hljs-built_in">super</span>(CustomTDNNF, self).__ini=
t__()
        self.tdnn1 =3D torch.nn.Linear(<span class=3D"hljs-number">40</span=
>, <span class=3D"hljs-number">1024</span>)
        self.relu =3D torch.nn.ReLU()
        self.batchnorm =3D torch.nn.BatchNorm1d(<span class=3D"hljs-number"=
>1024</span>)
        <span class=3D"hljs-comment"># Add more layers as needed</span>

    <span class=3D"hljs-keyword">def</span> <span class=3D"hljs-title funct=
ion_">forward</span>(<span class=3D"hljs-params">self, x</span>):
        x =3D self.tdnn1(x)
        x =3D self.relu(x)
        x =3D self.batchnorm(x)
        <span class=3D"hljs-comment"># Add more layers as needed</span>
        <span class=3D"hljs-keyword">return</span> x

<span class=3D"hljs-comment"># Load Kaldi parameters into PyTorch model (ex=
ample, adjust as needed)</span>
model =3D CustomTDNNF()
<span class=3D"hljs-keyword">with</span> kaldi_io.open_or_fd(<span class=3D=
"hljs-string">'exp/chain/custom_tdnnf/final.mdl'</span>) <span class=3D"hlj=
s-keyword">as</span> f:
    kaldi_params =3D torch.load(f)
    model.load_state_dict(kaldi_params)

<span class=3D"hljs-comment"># Export to ONNX</span>
dummy_input =3D torch.randn(<span class=3D"hljs-number">1</span>, <span cla=
ss=3D"hljs-number">40</span>, <span class=3D"hljs-number">160</span>)  <spa=
n class=3D"hljs-comment"># Example input</span>
torch.onnx.export(model, dummy_input, <span class=3D"hljs-string">"custom_t=
dnnf.onnx"</span>, input_names=3D[<span class=3D"hljs-string">"input"</span=
>], output_names=3D[<span class=3D"hljs-string">"output"</span>])
</code></pre>
<ol start=3D"2">
<li><strong>Verify the ONNX model</strong>:</li>
</ol>
<pre><code class=3D"hljs language-python"><span class=3D"hljs-keyword">impo=
rt</span> onnxruntime <span class=3D"hljs-keyword">as</span> ort
<span class=3D"hljs-keyword">import</span> numpy <span class=3D"hljs-keywor=
d">as</span> np

<span class=3D"hljs-comment"># Load the ONNX model</span>
onnx_model =3D ort.InferenceSession(<span class=3D"hljs-string">"custom_tdn=
nf.onnx"</span>)

<span class=3D"hljs-comment"># Create a dummy input</span>
dummy_input =3D np.random.randn(<span class=3D"hljs-number">1</span>, <span=
 class=3D"hljs-number">40</span>, <span class=3D"hljs-number">160</span>).a=
stype(np.float32)

<span class=3D"hljs-comment"># Run inference</span>
onnx_inputs =3D {<span class=3D"hljs-string">"input"</span>: dummy_input}
onnx_outputs =3D onnx_model.run(<span class=3D"hljs-literal">None</span>, o=
nnx_inputs)

<span class=3D"hljs-built_in">print</span>(<span class=3D"hljs-string">"ONN=
X model output:"</span>, onnx_outputs)
</code></pre>
<h3 id=3D"summary" tabindex=3D"-1"><a class=3D"header-anchor" href=3D"https=
://slickgpt.com/t/5#summary" aria-hidden=3D"true">#</a> Summary</h3>
<p>This guide provides a high-level overview of how to customize an ASR mod=
el with Kaldi, including adding/removing layers and preparing data. The pro=
cess of converting a Kaldi model to ONNX involves an intermediate step wher=
e you convert the Kaldi model to a PyTorch model, and then export it to ONN=
X. This process can be complex and may require writing custom scripts to lo=
ad Kaldi parameters into PyTorch. Adjust paths, parameters, and configurati=
ons as needed for your specific use case.</p>
</div></div></div><div class=3D"absolute right-0 top-0 -mt-4 mr-4 h-8 px-2 =
flex items-center justify-center text-xs font-bold text-white bg-slate-800 =
rounded-md transition opacity-0 group-hover:opacity-100"><button class=3D"p=
-1 rounded hover:bg-slate-100/10 border border-transparent hover:border-sla=
te-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https://slickgpt=
.com/img/emoji/symbols/repeat-button.svg" alt=3D"repeat"></button><button c=
lass=3D"p-1 rounded hover:bg-slate-100/10 border border-transparent hover:b=
order-slate-600 group cursor-pointer"><img class=3D"h-4 w-4" src=3D"https:/=
/slickgpt.com/img/emoji/objects/pencil.svg" alt=3D"edit"></button></div></d=
iv></div><div class=3D"sticky bottom-0 border-r border-slate-800/50 text-wh=
ite bg-[#090b16] px-2 pb-2 sm:px-6 sm:pb-6 flex gap-2 mt-6 w-full h-auto z-=
10 max-sm:max-h-11"><!----><div class=3D"group relative -mt-1.5 flex w-full=
 rounded-md border border-slate-500/30 focus-within:border-blue-500/50 bg-s=
late-900 p-0.5 text-base font-normal text-white outline-slate-200/40 active=
:outline-2 max-sm:text-sm md:p-1 shrink"><div class=3D"relative flex w-full=
 items-center gap-2"><textarea autocomplete=3D"off" placeholder=3D"Write a =
message..." name=3D"message" title=3D"message" class=3D"font-default pl-4 w=
-full placeholder:text-slate-500 focus:outline-none bg-transparent border-n=
one appearance-none focus:ring-0 resize-none max-h-[60vh]" style=3D"height:=
 40px;"></textarea></div><div class=3D"group-focus-within:opacity-0 transit=
ion flex items-center space-x-0.5 text-xs font-black text-slate-100 dark:te=
xt-slate-500"><kbd class=3D"w-5 h-5 flex items-center justify-center border=
 uppercase border-slate-800 rounded-md">=E2=8C=A5</kbd><kbd class=3D"w-5 h-=
5 flex items-center justify-center border uppercase border-slate-800 rounde=
d-md">L</kbd></div><button class=3D"flex w-auto justify-center items-center=
 p-2 aspect-square text-base font-medium shadow-sm transition-colors rounde=
d-full focus:outline-none bg-slate-800/10 text-slate-500/50" aria-label=3D"=
Send message"><svg class=3D"w-5 h-5" xmlns=3D"http://www.w3.org/2000/svg" v=
iewBox=3D"0 0 24 24" fill=3D"currentColor"><path d=3D"M3.478 2.405a.75.75 0=
 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 0=
0.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 0=
03.478 2.405z"></path></svg></button></div></div></div></div></div><div cla=
ss=3D"fixed z-50 inset-0 flex items-end justify-center px-4 py-6 pointer-ev=
ents-none sm:px-6 sm:py-12 sm:items-start sm:justify-end"><div class=3D"max=
-w-sm w-full"></div></div><!----></div>
   =20

   =20
 =20

<!----></body></html>
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: text/css
Content-Transfer-Encoding: quoted-printable
Content-Location: cid:css-482fdfc1-8f4a-493f-8577-bad422bc9e2c@mhtml.blink

@charset "utf-8";

body { background-color: rgb(249, 249, 250); color: rgb(17, 24, 39); margin=
: 0px; overflow-y: overlay; }

body.dark { background-color: rgb(8, 11, 22); color: rgb(249, 249, 253); }

.loading-app { min-height: 100vh; display: flex; -webkit-box-orient: vertic=
al; -webkit-box-direction: normal; flex-direction: column; -webkit-box-pack=
: center; justify-content: center; -webkit-box-align: center; align-items: =
center; overflow: hidden; }

.loading-app img, .animate-ring { animation: 2s linear 0s infinite normal n=
one running ring; }

@-webkit-keyframes ring {=20
  0% { transform: rotate(0deg); animation-timing-function: cubic-bezier(0.5=
5, 0.055, 0.675, 0.19); }
  50% { transform: rotate(900deg); animation-timing-function: cubic-bezier(=
0.215, 0.61, 0.355, 1); }
  100% { transform: rotate(1800deg); }
}

@keyframes ring {=20
  0% { transform: rotate(0deg); animation-timing-function: cubic-bezier(0.5=
5, 0.055, 0.675, 0.19); }
  50% { transform: rotate(900deg); animation-timing-function: cubic-bezier(=
0.215, 0.61, 0.355, 1); }
  100% { transform: rotate(1800deg); }
}
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: text/css
Content-Transfer-Encoding: quoted-printable
Content-Location: https://slickgpt.com/assets/index-0587c55e.css

@charset "utf-8";

#bar1[data-v-30b9e74e] { animation: 3s linear 0s infinite normal none runni=
ng move1-30b9e74e, 3s linear 0s infinite normal none running grow1-30b9e74e=
; }

#bar2[data-v-30b9e74e] { animation: 3s linear 0s infinite normal none runni=
ng move2-30b9e74e, 3s linear 0s infinite normal none running grow2-30b9e74e=
; }

@-webkit-keyframes move1-30b9e74e {=20
  0% { left: -100%; }
  10% { left: 0%; }
  65% { left: 80%; }
  100% { left: 100%; }
}

@keyframes move1-30b9e74e {=20
  0% { left: -100%; }
  10% { left: 0%; }
  65% { left: 80%; }
  100% { left: 100%; }
}

@-webkit-keyframes grow1-30b9e74e {=20
  0% { transform: scaleX(0.8); }
  50% { transform: scaleX(0.9); }
  75% { transform: scaleX(0.1); }
  100% { transform: scaleX(0.1); }
}

@keyframes grow1-30b9e74e {=20
  0% { transform: scaleX(0.8); }
  50% { transform: scaleX(0.9); }
  75% { transform: scaleX(0.1); }
  100% { transform: scaleX(0.1); }
}

@-webkit-keyframes move2-30b9e74e {=20
  0% { left: -100%; }
  50% { left: -100%; }
  100% { left: 100%; }
}

@keyframes move2-30b9e74e {=20
  0% { left: -100%; }
  50% { left: -100%; }
  100% { left: 100%; }
}

@-webkit-keyframes grow2-30b9e74e {=20
  0% { transform: scaleX(0.8); }
  50% { transform: scaleX(0.9); }
  75% { transform: scaleX(0.8); }
  100% { transform: scaleX(0.7); }
}

@keyframes grow2-30b9e74e {=20
  0% { transform: scaleX(0.8); }
  50% { transform: scaleX(0.9); }
  75% { transform: scaleX(0.8); }
  100% { transform: scaleX(0.7); }
}

*, ::before, ::after { box-sizing: border-box; border-width: 0px; border-st=
yle: solid; border-color: rgb(226, 232, 240); }

::before, ::after { --tw-content: ""; }

html { line-height: 1.5; text-size-adjust: 100%; tab-size: 4; font-family: =
Satoshi-Variable, Satoshi, ui-sans-serif, system-ui, -apple-system, BlinkMa=
cSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans=
-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Col=
or Emoji"; font-feature-settings: normal; font-variation-settings: normal; =
}

body { margin: 0px; line-height: inherit; }

hr { height: 0px; color: inherit; border-top-width: 1px; }

abbr:where([title]) { text-decoration: underline dotted; }

h1, h2, h3, h4, h5, h6 { font-size: inherit; font-weight: inherit; }

a { color: inherit; text-decoration: inherit; }

b, strong { font-weight: bolder; }

code, kbd, samp, pre { font-family: MonoLisa, ui-monospace, SFMono-Regular,=
 Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font=
-size: 1em; }

small { font-size: 80%; }

sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-ali=
gn: baseline; }

sub { bottom: -0.25em; }

sup { top: -0.5em; }

table { text-indent: 0px; border-color: inherit; border-collapse: collapse;=
 }

button, input, optgroup, select, textarea { font-family: inherit; font-feat=
ure-settings: inherit; font-variation-settings: inherit; font-size: 100%; f=
ont-weight: inherit; line-height: inherit; color: inherit; margin: 0px; pad=
ding: 0px; }

button, select { text-transform: none; }

button, [type=3D"button"], [type=3D"reset"], [type=3D"submit"] { appearance=
: button; background-color: transparent; background-image: none; }

progress { vertical-align: baseline; }

::-webkit-inner-spin-button, ::-webkit-outer-spin-button { height: auto; }

[type=3D"search"] { appearance: textfield; outline-offset: -2px; }

::-webkit-search-decoration { appearance: none; }

::-webkit-file-upload-button { appearance: button; font: inherit; }

summary { display: list-item; }

blockquote, dl, dd, h1, h2, h3, h4, h5, h6, hr, figure, p, pre { margin: 0p=
x; }

fieldset { margin: 0px; padding: 0px; }

legend { padding: 0px; }

ol, ul, menu { list-style: none; margin: 0px; padding: 0px; }

dialog { padding: 0px; }

textarea { resize: vertical; }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { opa=
city: 1; color: rgb(148, 163, 184); }

input::placeholder, textarea::placeholder { opacity: 1; color: rgb(148, 163=
, 184); }

button, [role=3D"button"] { cursor: pointer; }

:disabled { cursor: default; }

img, svg, video, canvas, audio, iframe, embed, object { display: block; ver=
tical-align: middle; }

img, video { max-width: 100%; height: auto; }

[hidden] { display: none; }

[type=3D"text"], input:where(:not([type])), [type=3D"email"], [type=3D"url"=
], [type=3D"password"], [type=3D"number"], [type=3D"date"], [type=3D"dateti=
me-local"], [type=3D"month"], [type=3D"search"], [type=3D"tel"], [type=3D"t=
ime"], [type=3D"week"], [multiple], textarea, select { appearance: none; ba=
ckground-color: rgb(255, 255, 255); border-color: rgb(100, 116, 139); borde=
r-width: 1px; border-radius: 0px; padding: 0.5rem 0.75rem; font-size: 1rem;=
 line-height: 1.5rem; --tw-shadow: 0 0 #0000; }

[type=3D"text"]:focus, input:where(:not([type])):focus, [type=3D"email"]:fo=
cus, [type=3D"url"]:focus, [type=3D"password"]:focus, [type=3D"number"]:foc=
us, [type=3D"date"]:focus, [type=3D"datetime-local"]:focus, [type=3D"month"=
]:focus, [type=3D"search"]:focus, [type=3D"tel"]:focus, [type=3D"time"]:foc=
us, [type=3D"week"]:focus, [multiple]:focus, textarea:focus, select:focus {=
 outline: transparent solid 2px; outline-offset: 2px; --tw-ring-inset: var(=
--tw-empty, ); --tw-ring-offset-width: 0px; --tw-ring-offset-color: #fff; -=
-tw-ring-color: #3182CE; --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 =
0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow=
: var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--=
tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shad=
ow),var(--tw-shadow); border-color: rgb(49, 130, 206); }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { col=
or: rgb(100, 116, 139); opacity: 1; }

input::placeholder, textarea::placeholder { color: rgb(100, 116, 139); opac=
ity: 1; }

::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

::-webkit-date-and-time-value { min-height: 1.5em; text-align: inherit; }

::-webkit-datetime-edit { display: inline-flex; }

::-webkit-datetime-edit, ::-webkit-datetime-edit-year-field, ::-webkit-date=
time-edit-month-field, ::-webkit-datetime-edit-day-field, ::-webkit-datetim=
e-edit-hour-field, ::-webkit-datetime-edit-minute-field, ::-webkit-datetime=
-edit-second-field, ::-webkit-datetime-edit-millisecond-field, ::-webkit-da=
tetime-edit-meridiem-field { padding-top: 0px; padding-bottom: 0px; }

select { background-image: url("data:image/svg+xml,%3csvg xmlns=3D'http://w=
ww.w3.org/2000/svg' fill=3D'none' viewBox=3D'0 0 20 20'%3e%3cpath stroke=3D=
'%2364748b' stroke-linecap=3D'round' stroke-linejoin=3D'round' stroke-width=
=3D'1.5' d=3D'M6 8l4 4 4-4'/%3e%3c/svg%3e"); background-position: right 0.5=
rem center; background-repeat: no-repeat; background-size: 1.5em 1.5em; pad=
ding-right: 2.5rem; -webkit-print-color-adjust: exact; }

[multiple], [size]:where(select:not([size=3D"1"])) { background-image: init=
ial; background-position: initial; background-repeat: unset; background-siz=
e: initial; padding-right: 0.75rem; -webkit-print-color-adjust: unset; }

[type=3D"checkbox"], [type=3D"radio"] { appearance: none; padding: 0px; -we=
bkit-print-color-adjust: exact; display: inline-block; vertical-align: midd=
le; background-origin: border-box; user-select: none; flex-shrink: 0; heigh=
t: 1rem; width: 1rem; color: rgb(49, 130, 206); background-color: rgb(255, =
255, 255); border-color: rgb(100, 116, 139); border-width: 1px; --tw-shadow=
: 0 0 #0000; }

[type=3D"checkbox"] { border-radius: 0px; }

[type=3D"radio"] { border-radius: 100%; }

[type=3D"checkbox"]:focus, [type=3D"radio"]:focus { outline: transparent so=
lid 2px; outline-offset: 2px; --tw-ring-inset: var(--tw-empty, ); --tw-ring=
-offset-width: 2px; --tw-ring-offset-color: #fff; --tw-ring-color: #3182CE;=
 --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-w=
idth) var(--tw-ring-offset-color); --tw-ring-shadow: var(--tw-ring-inset) 0=
 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shad=
ow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); }

[type=3D"checkbox"]:checked, [type=3D"radio"]:checked { border-color: trans=
parent; background-color: currentcolor; background-size: 100% 100%; backgro=
und-position: center center; background-repeat: no-repeat; }

[type=3D"checkbox"]:checked { background-image: url("data:image/svg+xml,%3c=
svg viewBox=3D'0 0 16 16' fill=3D'white' xmlns=3D'http://www.w3.org/2000/sv=
g'%3e%3cpath d=3D'M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a=
1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e")=
; }

[type=3D"radio"]:checked { background-image: url("data:image/svg+xml,%3csvg=
 viewBox=3D'0 0 16 16' fill=3D'white' xmlns=3D'http://www.w3.org/2000/svg'%=
3e%3ccircle cx=3D'8' cy=3D'8' r=3D'3'/%3e%3c/svg%3e"); }

[type=3D"checkbox"]:checked:hover, [type=3D"checkbox"]:checked:focus, [type=
=3D"radio"]:checked:hover, [type=3D"radio"]:checked:focus { border-color: t=
ransparent; background-color: currentcolor; }

[type=3D"checkbox"]:indeterminate { background-image: url("data:image/svg+x=
ml,%3csvg xmlns=3D'http://www.w3.org/2000/svg' fill=3D'none' viewBox=3D'0 0=
 16 16'%3e%3cpath stroke=3D'white' stroke-linecap=3D'round' stroke-linejoin=
=3D'round' stroke-width=3D'2' d=3D'M4 8h8'/%3e%3c/svg%3e"); border-color: t=
ransparent; background-color: currentcolor; background-size: 100% 100%; bac=
kground-position: center center; background-repeat: no-repeat; }

[type=3D"checkbox"]:indeterminate:hover, [type=3D"checkbox"]:indeterminate:=
focus { border-color: transparent; background-color: currentcolor; }

[type=3D"file"] { background: unset; border-color: inherit; border-width: 0=
px; border-radius: 0px; padding: 0px; font-size: unset; line-height: inheri=
t; }

[type=3D"file"]:focus { outline: -webkit-focus-ring-color auto 1px; }

*, ::before, ::after { --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; =
--tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; -=
-tw-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-pan-x: ; --tw-pan-y: =
; --tw-pinch-zoom: ; --tw-scroll-snap-strictness: proximity; --tw-gradient-=
from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ;=
 --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-s=
pacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-widt=
h: 0px; --tw-ring-offset-color: #fff; --tw-ring-color: rgb(65 153 225 / .5)=
; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-shadow: 0 0 #0000; --tw-sha=
dow: 0 0 #0000; --tw-shadow-colored: 0 0 #0000; --tw-blur: ; --tw-brightnes=
s: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; -=
-tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --t=
w-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale:=
 ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacit=
y: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::-webkit-backdrop { --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --=
tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --t=
w-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-pan-x: ; --tw-pan-y: ; =
--tw-pinch-zoom: ; --tw-scroll-snap-strictness: proximity; --tw-gradient-fr=
om-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; -=
-tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spa=
cing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:=
 0px; --tw-ring-offset-color: #fff; --tw-ring-color: rgb(65 153 225 / .5); =
--tw-ring-offset-shadow: 0 0 #0000; --tw-ring-shadow: 0 0 #0000; --tw-shado=
w: 0 0 #0000; --tw-shadow-colored: 0 0 #0000; --tw-blur: ; --tw-brightness:=
 ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --t=
w-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-=
backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ;=
 --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity:=
 ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::backdrop { --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-trans=
late-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --tw-skew-y=
: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-pan-x: ; --tw-pan-y: ; --tw-pin=
ch-zoom: ; --tw-scroll-snap-strictness: proximity; --tw-gradient-from-posit=
ion: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordi=
nal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; =
--tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width: 0px; --=
tw-ring-offset-color: #fff; --tw-ring-color: rgb(65 153 225 / .5); --tw-rin=
g-offset-shadow: 0 0 #0000; --tw-ring-shadow: 0 0 #0000; --tw-shadow: 0 0 #=
0000; --tw-shadow-colored: 0 0 #0000; --tw-blur: ; --tw-brightness: ; --tw-=
contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-satura=
te: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop=
-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-ba=
ckdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-=
backdrop-saturate: ; --tw-backdrop-sepia: ; }

.\!container { width: 100% !important; }

.container { width: 100%; }

@media (min-width: 480px) {
  .\!container { max-width: 480px !important; }
  .container { max-width: 480px; }
}

@media (min-width: 640px) {
  .\!container { max-width: 640px !important; }
  .container { max-width: 640px; }
}

@media (min-width: 768px) {
  .\!container { max-width: 768px !important; }
  .container { max-width: 768px; }
}

@media (min-width: 1024px) {
  .\!container { max-width: 1024px !important; }
  .container { max-width: 1024px; }
}

@media (min-width: 1280px) {
  .\!container { max-width: 1280px !important; }
  .container { max-width: 1280px; }
}

@media (min-width: 1536px) {
  .\!container { max-width: 1536px !important; }
  .container { max-width: 1536px; }
}

.form-input, .form-textarea, .form-select, .form-multiselect { appearance: =
none; background-color: rgb(255, 255, 255); border-color: rgb(100, 116, 139=
); border-width: 1px; border-radius: 0px; padding: 0.5rem 0.75rem; font-siz=
e: 1rem; line-height: 1.5rem; --tw-shadow: 0 0 #0000; }

.form-input:focus, .form-textarea:focus, .form-select:focus, .form-multisel=
ect:focus { outline: transparent solid 2px; outline-offset: 2px; --tw-ring-=
inset: var(--tw-empty, ); --tw-ring-offset-width: 0px; --tw-ring-offset-col=
or: #fff; --tw-ring-color: #3182CE; --tw-ring-offset-shadow: var(--tw-ring-=
inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-=
ring-shadow: var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-wid=
th)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--t=
w-ring-shadow),var(--tw-shadow); border-color: rgb(49, 130, 206); }

.form-input::-webkit-input-placeholder, .form-textarea::-webkit-input-place=
holder { color: rgb(100, 116, 139); opacity: 1; }

.form-input::placeholder, .form-textarea::placeholder { color: rgb(100, 116=
, 139); opacity: 1; }

.form-input::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

.form-input::-webkit-date-and-time-value { min-height: 1.5em; text-align: i=
nherit; }

.form-input::-webkit-datetime-edit { display: inline-flex; }

.form-input::-webkit-datetime-edit, .form-input::-webkit-datetime-edit-year=
-field, .form-input::-webkit-datetime-edit-month-field, .form-input::-webki=
t-datetime-edit-day-field, .form-input::-webkit-datetime-edit-hour-field, .=
form-input::-webkit-datetime-edit-minute-field, .form-input::-webkit-dateti=
me-edit-second-field, .form-input::-webkit-datetime-edit-millisecond-field,=
 .form-input::-webkit-datetime-edit-meridiem-field { padding-top: 0px; padd=
ing-bottom: 0px; }

.form-select { background-image: url("data:image/svg+xml,%3csvg xmlns=3D'ht=
tp://www.w3.org/2000/svg' fill=3D'none' viewBox=3D'0 0 20 20'%3e%3cpath str=
oke=3D'%2364748b' stroke-linecap=3D'round' stroke-linejoin=3D'round' stroke=
-width=3D'1.5' d=3D'M6 8l4 4 4-4'/%3e%3c/svg%3e"); background-position: rig=
ht 0.5rem center; background-repeat: no-repeat; background-size: 1.5em 1.5e=
m; padding-right: 2.5rem; -webkit-print-color-adjust: exact; }

.form-select:where([size]:not([size=3D"1"])) { background-image: initial; b=
ackground-position: initial; background-repeat: unset; background-size: ini=
tial; padding-right: 0.75rem; -webkit-print-color-adjust: unset; }

.prose { color: var(--tw-prose-body); max-width: 65ch; }

.prose :where(p):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] =
*)) { margin-top: 1.25em; margin-bottom: 1.25em; }

.prose :where([class~=3D"lead"]):not(:where([class~=3D"not-prose"], [class~=
=3D"not-prose"] *)) { color: var(--tw-prose-lead); font-size: 1.25em; line-=
height: 1.6; margin-top: 1.2em; margin-bottom: 1.2em; }

.prose :where(a):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] =
*)) { color: var(--tw-prose-links); text-decoration: underline; font-weight=
: 500; }

.prose :where(strong):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { color: var(--tw-prose-bold); font-weight: 600; }

.prose :where(a strong):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { color: inherit; }

.prose :where(blockquote strong):not(:where([class~=3D"not-prose"], [class~=
=3D"not-prose"] *)) { color: inherit; }

.prose :where(thead th strong):not(:where([class~=3D"not-prose"], [class~=
=3D"not-prose"] *)) { color: inherit; }

.prose :where(ol):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { list-style-type: decimal; margin-top: 1.25em; margin-bottom: 1.25em;=
 padding-left: 1.625em; }

.prose :where(ol[type=3D"A"]):not(:where([class~=3D"not-prose"], [class~=3D=
"not-prose"] *)) { list-style-type: upper-alpha; }

.prose :where(ol[type=3D"a"]):not(:where([class~=3D"not-prose"], [class~=3D=
"not-prose"] *)) { list-style-type: lower-alpha; }

.prose :where():not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] *=
)) { list-style-type: upper-alpha; }

.prose :where():not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] *=
)) { list-style-type: lower-alpha; }

.prose :where(ol[type=3D"I"]):not(:where([class~=3D"not-prose"], [class~=3D=
"not-prose"] *)) { list-style-type: upper-roman; }

.prose :where(ol[type=3D"i"]):not(:where([class~=3D"not-prose"], [class~=3D=
"not-prose"] *)) { list-style-type: lower-roman; }

.prose :where():not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] *=
)) { list-style-type: upper-roman; }

.prose :where():not(:where([class~=3D"not-prose"], [class~=3D"not-prose"] *=
)) { list-style-type: lower-roman; }

.prose :where(ol[type=3D"1"]):not(:where([class~=3D"not-prose"], [class~=3D=
"not-prose"] *)) { list-style-type: decimal; }

.prose :where(ul):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { list-style-type: disc; margin-top: 1.25em; margin-bottom: 1.25em; pa=
dding-left: 1.625em; }

.prose :where(ol > li):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *))::marker { font-weight: 400; color: var(--tw-prose-counters); }

.prose :where(ul > li):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *))::marker { color: var(--tw-prose-bullets); }

.prose :where(dt):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { color: var(--tw-prose-headings); font-weight: 600; margin-top: 1.25e=
m; }

.prose :where(hr):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { border-color: var(--tw-prose-hr); border-top-width: 1px; margin-top:=
 3em; margin-bottom: 3em; }

.prose :where(blockquote):not(:where([class~=3D"not-prose"], [class~=3D"not=
-prose"] *)) { font-weight: 500; font-style: italic; color: var(--tw-prose-=
quotes); border-left-width: 0.25rem; border-left-color: var(--tw-prose-quot=
e-borders); quotes: "=E2=80=9C" "=E2=80=9D" "=E2=80=98" "=E2=80=99"; margin=
-top: 1.6em; margin-bottom: 1.6em; padding-left: 1em; }

.prose :where(blockquote p:first-of-type):not(:where([class~=3D"not-prose"]=
, [class~=3D"not-prose"] *))::before { content: open-quote; }

.prose :where(blockquote p:last-of-type):not(:where([class~=3D"not-prose"],=
 [class~=3D"not-prose"] *))::after { content: close-quote; }

.prose :where(h1):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { color: var(--tw-prose-headings); font-weight: 800; font-size: 2.25em=
; margin-top: 0px; margin-bottom: 0.888889em; line-height: 1.11111; }

.prose :where(h1 strong):not(:where([class~=3D"not-prose"], [class~=3D"not-=
prose"] *)) { font-weight: 900; color: inherit; }

.prose :where(h2):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { color: var(--tw-prose-headings); font-weight: 700; font-size: 1.5em;=
 margin-top: 2em; margin-bottom: 1em; line-height: 1.33333; }

.prose :where(h2 strong):not(:where([class~=3D"not-prose"], [class~=3D"not-=
prose"] *)) { font-weight: 800; color: inherit; }

.prose :where(h3):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { color: var(--tw-prose-headings); font-weight: 600; font-size: 1.25em=
; margin-top: 1.6em; margin-bottom: 0.6em; line-height: 1.6; }

.prose :where(h3 strong):not(:where([class~=3D"not-prose"], [class~=3D"not-=
prose"] *)) { font-weight: 700; color: inherit; }

.prose :where(h4):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { color: var(--tw-prose-headings); font-weight: 600; margin-top: 1.5em=
; margin-bottom: 0.5em; line-height: 1.5; }

.prose :where(h4 strong):not(:where([class~=3D"not-prose"], [class~=3D"not-=
prose"] *)) { font-weight: 700; color: inherit; }

.prose :where(img):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"=
] *)) { margin-top: 2em; margin-bottom: 2em; }

.prose :where(picture):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { display: block; margin-top: 2em; margin-bottom: 2em; }

.prose :where(kbd):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"=
] *)) { font-weight: 500; font-family: inherit; color: var(--tw-prose-kbd);=
 box-shadow: 0 0 0 1px rgb(var(--tw-prose-kbd-shadows) / 10%),0 3px 0 rgb(v=
ar(--tw-prose-kbd-shadows) / 10%); font-size: 0.875em; border-radius: 0.312=
5rem; padding: 0.1875em 0.375em; }

.prose :where(code):not(:where([class~=3D"not-prose"], [class~=3D"not-prose=
"] *)) { color: var(--tw-prose-code); font-weight: 600; font-size: 0.875em;=
 }

.prose :where(code):not(:where([class~=3D"not-prose"], [class~=3D"not-prose=
"] *))::before { content: "`"; }

.prose :where(code):not(:where([class~=3D"not-prose"], [class~=3D"not-prose=
"] *))::after { content: "`"; }

.prose :where(a code):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { color: inherit; }

.prose :where(h1 code):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { color: inherit; }

.prose :where(h2 code):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { color: inherit; font-size: 0.875em; }

.prose :where(h3 code):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { color: inherit; font-size: 0.9em; }

.prose :where(h4 code):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { color: inherit; }

.prose :where(blockquote code):not(:where([class~=3D"not-prose"], [class~=
=3D"not-prose"] *)) { color: inherit; }

.prose :where(thead th code):not(:where([class~=3D"not-prose"], [class~=3D"=
not-prose"] *)) { color: inherit; }

.prose :where(pre):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"=
] *)) { color: var(--tw-prose-pre-code); background-color: var(--tw-prose-p=
re-bg); overflow-x: auto; font-weight: 400; font-size: 0.875em; line-height=
: 1.71429; margin-top: 1.71429em; margin-bottom: 1.71429em; border-radius: =
0.375rem; padding: 0.857143em 1.14286em; }

.prose :where(pre code):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { background-color: transparent; border-width: 0px; border-radiu=
s: 0px; padding: 0px; font-weight: inherit; color: inherit; font-size: inhe=
rit; font-family: inherit; line-height: inherit; }

.prose :where(pre code):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *))::before { content: none; }

.prose :where(pre code):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *))::after { content: none; }

.prose :where(table):not(:where([class~=3D"not-prose"], [class~=3D"not-pros=
e"] *)) { width: 100%; table-layout: auto; text-align: left; margin-top: 2e=
m; margin-bottom: 2em; font-size: 0.875em; line-height: 1.71429; }

.prose :where(thead):not(:where([class~=3D"not-prose"], [class~=3D"not-pros=
e"] *)) { border-bottom-width: 1px; border-bottom-color: var(--tw-prose-th-=
borders); }

.prose :where(thead th):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { color: var(--tw-prose-headings); font-weight: 600; vertical-al=
ign: bottom; padding-right: 0.571429em; padding-bottom: 0.571429em; padding=
-left: 0.571429em; }

.prose :where(tbody tr):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { border-bottom-width: 1px; border-bottom-color: var(--tw-prose-=
td-borders); }

.prose :where(tbody tr:last-child):not(:where([class~=3D"not-prose"], [clas=
s~=3D"not-prose"] *)) { border-bottom-width: 0px; }

.prose :where(tbody td):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { vertical-align: baseline; }

.prose :where(tfoot):not(:where([class~=3D"not-prose"], [class~=3D"not-pros=
e"] *)) { border-top-width: 1px; border-top-color: var(--tw-prose-th-border=
s); }

.prose :where(tfoot td):not(:where([class~=3D"not-prose"], [class~=3D"not-p=
rose"] *)) { vertical-align: top; }

.prose :where(figure > *):not(:where([class~=3D"not-prose"], [class~=3D"not=
-prose"] *)) { margin-top: 0px; margin-bottom: 0px; }

.prose :where(figcaption):not(:where([class~=3D"not-prose"], [class~=3D"not=
-prose"] *)) { color: var(--tw-prose-captions); font-size: 0.875em; line-he=
ight: 1.42857; margin-top: 0.857143em; }

.prose { --tw-prose-body: #374151; --tw-prose-headings: #111827; --tw-prose=
-lead: #4b5563; --tw-prose-links: #111827; --tw-prose-bold: #111827; --tw-p=
rose-counters: #6b7280; --tw-prose-bullets: #d1d5db; --tw-prose-hr: #e5e7eb=
; --tw-prose-quotes: #111827; --tw-prose-quote-borders: #e5e7eb; --tw-prose=
-captions: #6b7280; --tw-prose-kbd: #111827; --tw-prose-kbd-shadows: 17 24 =
39; --tw-prose-code: #111827; --tw-prose-pre-code: #e5e7eb; --tw-prose-pre-=
bg: #1f2937; --tw-prose-th-borders: #d1d5db; --tw-prose-td-borders: #e5e7eb=
; --tw-prose-invert-body: #d1d5db; --tw-prose-invert-headings: #fff; --tw-p=
rose-invert-lead: #9ca3af; --tw-prose-invert-links: #fff; --tw-prose-invert=
-bold: #fff; --tw-prose-invert-counters: #9ca3af; --tw-prose-invert-bullets=
: #4b5563; --tw-prose-invert-hr: #374151; --tw-prose-invert-quotes: #f3f4f6=
; --tw-prose-invert-quote-borders: #374151; --tw-prose-invert-captions: #9c=
a3af; --tw-prose-invert-kbd: #fff; --tw-prose-invert-kbd-shadows: 255 255 2=
55; --tw-prose-invert-code: #fff; --tw-prose-invert-pre-code: #d1d5db; --tw=
-prose-invert-pre-bg: rgb(0 0 0 / 50%); --tw-prose-invert-th-borders: #4b55=
63; --tw-prose-invert-td-borders: #374151; font-size: 1rem; line-height: 1.=
75; }

.prose :where(picture > img):not(:where([class~=3D"not-prose"], [class~=3D"=
not-prose"] *)) { margin-top: 0px; margin-bottom: 0px; }

.prose :where(video):not(:where([class~=3D"not-prose"], [class~=3D"not-pros=
e"] *)) { margin-top: 2em; margin-bottom: 2em; }

.prose :where(li):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { margin-top: 0.5em; margin-bottom: 0.5em; }

.prose :where(ol > li):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { padding-left: 0.375em; }

.prose :where(ul > li):not(:where([class~=3D"not-prose"], [class~=3D"not-pr=
ose"] *)) { padding-left: 0.375em; }

.prose :where(.prose > ul > li p):not(:where([class~=3D"not-prose"], [class=
~=3D"not-prose"] *)) { margin-top: 0.75em; margin-bottom: 0.75em; }

.prose :where(.prose > ul > li > :first-child):not(:where([class~=3D"not-pr=
ose"], [class~=3D"not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ul > li > :last-child):not(:where([class~=3D"not-pro=
se"], [class~=3D"not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(.prose > ol > li > :first-child):not(:where([class~=3D"not-pr=
ose"], [class~=3D"not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ol > li > :last-child):not(:where([class~=3D"not-pro=
se"], [class~=3D"not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(ul ul, ul ol, ol ul, ol ol):not(:where([class~=3D"not-prose"]=
, [class~=3D"not-prose"] *)) { margin-top: 0.75em; margin-bottom: 0.75em; }

.prose :where(dl):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { margin-top: 1.25em; margin-bottom: 1.25em; }

.prose :where(dd):not(:where([class~=3D"not-prose"], [class~=3D"not-prose"]=
 *)) { margin-top: 0.5em; padding-left: 1.625em; }

.prose :where(hr + *):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { margin-top: 0px; }

.prose :where(h2 + *):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { margin-top: 0px; }

.prose :where(h3 + *):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { margin-top: 0px; }

.prose :where(h4 + *):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { margin-top: 0px; }

.prose :where(thead th:first-child):not(:where([class~=3D"not-prose"], [cla=
ss~=3D"not-prose"] *)) { padding-left: 0px; }

.prose :where(thead th:last-child):not(:where([class~=3D"not-prose"], [clas=
s~=3D"not-prose"] *)) { padding-right: 0px; }

.prose :where(tbody td, tfoot td):not(:where([class~=3D"not-prose"], [class=
~=3D"not-prose"] *)) { padding: 0.571429em; }

.prose :where(tbody td:first-child, tfoot td:first-child):not(:where([class=
~=3D"not-prose"], [class~=3D"not-prose"] *)) { padding-left: 0px; }

.prose :where(tbody td:last-child, tfoot td:last-child):not(:where([class~=
=3D"not-prose"], [class~=3D"not-prose"] *)) { padding-right: 0px; }

.prose :where(figure):not(:where([class~=3D"not-prose"], [class~=3D"not-pro=
se"] *)) { margin-top: 2em; margin-bottom: 2em; }

.prose :where(.prose > :first-child):not(:where([class~=3D"not-prose"], [cl=
ass~=3D"not-prose"] *)) { margin-top: 0px; }

.prose :where(.prose > :last-child):not(:where([class~=3D"not-prose"], [cla=
ss~=3D"not-prose"] *)) { margin-bottom: 0px; }

pre code.hljs { display: block; overflow-x: auto; padding: 1em; }

code.hljs { padding: 3px 5px; }

.hljs { background: rgb(1, 22, 39); color: rgb(214, 222, 235); }

.hljs-keyword { color: rgb(199, 146, 234); font-style: italic; }

.hljs-built_in { color: rgb(173, 219, 103); font-style: italic; }

.hljs-type { color: rgb(130, 170, 255); }

.hljs-literal { color: rgb(255, 88, 116); }

.hljs-number { color: rgb(247, 140, 108); }

.hljs-regexp { color: rgb(92, 167, 228); }

.hljs-string { color: rgb(236, 196, 141); }

.hljs-subst { color: rgb(211, 66, 62); }

.hljs-symbol { color: rgb(130, 170, 255); }

.hljs-class { color: rgb(255, 203, 139); }

.hljs-function { color: rgb(130, 170, 255); }

.hljs-title { color: rgb(220, 220, 170); font-style: italic; }

.hljs-params { color: rgb(127, 219, 202); }

.hljs-comment { color: rgb(99, 119, 119); font-style: italic; }

.hljs-doctag { color: rgb(127, 219, 202); }

.hljs-meta, .hljs-meta .hljs-keyword { color: rgb(130, 170, 255); }

.hljs-meta .hljs-string { color: rgb(236, 196, 141); }

.hljs-section { color: rgb(130, 177, 255); }

.hljs-tag, .hljs-name, .hljs-attr { color: rgb(127, 219, 202); }

.hljs-attribute { color: rgb(128, 203, 196); }

.hljs-variable { color: rgb(173, 219, 103); }

.hljs-bullet { color: rgb(217, 245, 221); }

.hljs-code { color: rgb(128, 203, 196); }

.hljs-emphasis { color: rgb(199, 146, 234); font-style: italic; }

.hljs-strong { color: rgb(173, 219, 103); font-weight: 700; }

.hljs-formula { color: rgb(199, 146, 234); }

.hljs-link { color: rgb(255, 134, 154); }

.hljs-quote { color: rgb(105, 112, 152); font-style: italic; }

.hljs-selector-tag { color: rgb(255, 99, 99); }

.hljs-selector-id { color: rgb(250, 212, 48); }

.hljs-selector-class { color: rgb(173, 219, 103); font-style: italic; }

.hljs-selector-attr, .hljs-selector-pseudo { color: rgb(199, 146, 234); fon=
t-style: italic; }

.hljs-template-tag { color: rgb(199, 146, 234); }

.hljs-template-variable { color: rgb(173, 219, 103); }

.hljs-addition { color: rgb(173, 219, 103); font-style: italic; }

.hljs-deletion { color: rgba(239, 83, 80, 0.565); font-style: italic; }

@font-face { font-family: MonoLisa; font-weight: 100 900; font-display: swa=
p; font-style: normal; src: url("/fonts/MonoLisaNormal.woff2") format("woff=
2"); }

@font-face { font-family: Satoshi-Variable; src: url("/fonts/satoshi/Satosh=
i-Variable.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-Variable.wo=
ff") format("woff"), url("/fonts/satoshi/Satoshi-Variable.ttf") format("tru=
etype"); font-weight: 300 900; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi-Variable; src: url("/fonts/satoshi/Satosh=
i-VariableItalic.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-Varia=
bleItalic.woff") format("woff"), url("/fonts/satoshi/Satoshi-VariableItalic=
.ttf") format("truetype"); font-weight: 300 900; font-display: swap; font-s=
tyle: italic; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Light.w=
off2") format("woff2"), url("/fonts/satoshi/Satoshi-Light.woff") format("wo=
ff"), url("/fonts/satoshi/Satoshi-Light.ttf") format("truetype"); font-weig=
ht: 300; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-LightIt=
alic.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-LightItalic.woff"=
) format("woff"), url("/fonts/satoshi/Satoshi-LightItalic.ttf") format("tru=
etype"); font-weight: 300; font-display: swap; font-style: italic; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Regular=
.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-Regular.woff") format=
("woff"), url("/fonts/satoshi/Satoshi-Regular.ttf") format("truetype"); fon=
t-weight: 400; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Italic.=
woff2") format("woff2"), url("/fonts/satoshi/Satoshi-Italic.woff") format("=
woff"), url("/fonts/satoshi/Satoshi-Italic.ttf") format("truetype"); font-w=
eight: 400; font-display: swap; font-style: italic; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Medium.=
woff2") format("woff2"), url("/fonts/satoshi/Satoshi-Medium.woff") format("=
woff"), url("/fonts/satoshi/Satoshi-Medium.ttf") format("truetype"); font-w=
eight: 500; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-MediumI=
talic.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-MediumItalic.wof=
f") format("woff"), url("/fonts/satoshi/Satoshi-MediumItalic.ttf") format("=
truetype"); font-weight: 500; font-display: swap; font-style: italic; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Bold.wo=
ff2") format("woff2"), url("/fonts/satoshi/Satoshi-Bold.woff") format("woff=
"), url("/fonts/satoshi/Satoshi-Bold.ttf") format("truetype"); font-weight:=
 700; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-BoldIta=
lic.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-BoldItalic.woff") =
format("woff"), url("/fonts/satoshi/Satoshi-BoldItalic.ttf") format("truety=
pe"); font-weight: 700; font-display: swap; font-style: italic; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-Black.w=
off2") format("woff2"), url("/fonts/satoshi/Satoshi-Black.woff") format("wo=
ff"), url("/fonts/satoshi/Satoshi-Black.ttf") format("truetype"); font-weig=
ht: 900; font-display: swap; font-style: normal; }

@font-face { font-family: Satoshi; src: url("/fonts/satoshi/Satoshi-BlackIt=
alic.woff2") format("woff2"), url("/fonts/satoshi/Satoshi-BlackItalic.woff"=
) format("woff"), url("/fonts/satoshi/Satoshi-BlackItalic.ttf") format("tru=
etype"); font-weight: 900; font-display: swap; font-style: italic; }

img { max-width: none; }

:root { scroll-behavior: smooth; }

html { font-family: Satoshi, system-ui, -apple-system, BlinkMacSystemFont, =
"Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Appl=
e Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; }

@supports (font-variation-settings: normal) {
  html { font-family: Satoshi-Variable, system-ui, -apple-system, BlinkMacS=
ystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-s=
erif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color=
 Emoji"; }
}

body { -webkit-tap-highlight-color: transparent; touch-action: manipulation=
; text-rendering: optimizelegibility; text-size-adjust: 100%; --tw-bg-opaci=
ty: 1; background-color: rgb(249 249 250 / var(--tw-bg-opacity)); --tw-text=
-opacity: 1; color: rgb(15 23 42 / var(--tw-text-opacity)); -webkit-font-sm=
oothing: antialiased; }

body.dark { background-color: rgb(8, 11, 22); color: rgb(249, 249, 253); }

a { color: inherit; text-decoration: none; }

a.link { font-weight: 500; --tw-text-opacity: 1; color: rgb(139 92 246 / va=
r(--tw-text-opacity)); }

a.link:hover { --tw-text-opacity: 1; color: rgb(124 58 237 / var(--tw-text-=
opacity)); text-decoration-line: underline; }

a.link:focus { text-decoration-line: underline; }

b { font-weight: 600; }

strong { font-weight: 700; }

::selection { --tw-bg-opacity: 1; background-color: rgb(139 92 246 / var(--=
tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 255 255 / var(--tw-te=
xt-opacity)); }

.contain { margin-left: auto; margin-right: auto; width: 100%; max-width: 8=
0rem; padding-left: 1.5rem; padding-right: 1.5rem; }

.pad, .contain { padding-left: 1.5rem; padding-right: 1.5rem; }

@media (min-width: 640px) {
  .pad, .contain { padding-left: 2rem; padding-right: 2rem; }
}

@media (min-width: 768px) {
  .pad, .contain { padding-left: 2.5rem; padding-right: 2.5rem; }
}

.overflow-y-scroll { }

.route-enter-active-class { transition-duration: 0.3s; transition-timing-fu=
nction: cubic-bezier(0, 0, 0.2, 1); }

.route-enter-active-class .page-fade-in, .route-enter-active-class.page-fad=
e-in { transform: translate3d(var(--tw-translate-x),var(--tw-translate-y),0=
) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) s=
caleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); transition-duration: 0.=
3s; transition-timing-function: cubic-bezier(0, 0, 0.2, 1); }

.route-enter-from-class .page-fade-in, .route-enter-from-class.page-fade-in=
 { --tw-translate-y: -.25rem; transform: translate(var(--tw-translate-x),va=
r(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(=
var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); opac=
ity: 0; }

.route-enter-to-class .page-fade-in, .route-enter-to-class.page-fade-in { -=
-tw-translate-y: 0px; transform: translate(var(--tw-translate-x),var(--tw-t=
ranslate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw=
-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); opacity: 1; =
}

.button { border-radius: 0.75rem; border-width: 1px; border-color: transpar=
ent; font-weight: 600; transition-property: color, background-color, border=
-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform=
, filter, backdrop-filter, -webkit-text-decoration-color, -webkit-box-shado=
w, -webkit-transform, -webkit-filter, -webkit-backdrop-filter; transition-t=
iming-function: cubic-bezier(0, 0, 0.2, 1); transition-duration: 0.15s; }

.button:focus { outline: transparent solid 2px; outline-offset: 2px; }

.button--gray { --tw-bg-opacity: 1; background-color: rgb(241 245 249 / var=
(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(71 85 105 / var(--tw-t=
ext-opacity)); }

:is(.dark .button--gray) { --tw-bg-opacity: 1; background-color: rgb(30 41 =
59 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(148 163 184 / =
var(--tw-text-opacity)); }

.button--gray:hover { --tw-bg-opacity: 1; background-color: rgb(226 232 240=
 / var(--tw-bg-opacity)); }

:is(.dark .button--gray:hover) { --tw-bg-opacity: 1; background-color: rgb(=
71 85 105 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(241 245=
 249 / var(--tw-text-opacity)); }

.button--gray:focus { --tw-border-opacity: 1; border-color: rgb(191 219 254=
 / var(--tw-border-opacity)); }

:is(.dark .button--gray:focus) { --tw-border-opacity: 1; border-color: rgb(=
49 130 206 / var(--tw-border-opacity)); }

.button--black { --tw-bg-opacity: 1; background-color: rgb(0 0 0 / var(--tw=
-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 255 255 / var(--tw-text=
-opacity)); }

.button--black:hover { --tw-bg-opacity: 1; background-color: rgb(30 41 59 /=
 var(--tw-bg-opacity)); }

.button--black:focus { --tw-border-opacity: 1; border-color: rgb(30 41 59 /=
 var(--tw-border-opacity)); }

.button--slate { --tw-bg-opacity: 1; background-color: rgb(241 245 249 / va=
r(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(71 85 105 / var(--tw-=
text-opacity)); }

:is(.dark .button--slate) { --tw-bg-opacity: 1; background-color: rgb(51 65=
 85 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(148 163 184 /=
 var(--tw-text-opacity)); }

.button--slate:hover { --tw-bg-opacity: 1; background-color: rgb(226 232 24=
0 / var(--tw-bg-opacity)); }

:is(.dark .button--slate:hover) { --tw-bg-opacity: 1; background-color: rgb=
(71 85 105 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(241 24=
5 249 / var(--tw-text-opacity)); }

.button--slate:focus { --tw-border-opacity: 1; border-color: rgb(191 219 25=
4 / var(--tw-border-opacity)); }

:is(.dark .button--slate:focus) { --tw-border-opacity: 1; border-color: rgb=
(49 130 206 / var(--tw-border-opacity)); }

.button--purple { --tw-bg-opacity: 1; background-color: rgb(243 232 255 / v=
ar(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(147 51 234 / var(--t=
w-text-opacity)); }

:is(.dark .button--purple) { --tw-bg-opacity: 1; background-color: rgb(126 =
34 206 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(243 232 25=
5 / var(--tw-text-opacity)); }

.button--purple:hover { --tw-bg-opacity: 1; background-color: rgb(233 213 2=
55 / var(--tw-bg-opacity)); }

:is(.dark .button--purple:hover) { --tw-bg-opacity: 1; background-color: rg=
b(147 51 234 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 =
255 255 / var(--tw-text-opacity)); }

.button--purple:focus { --tw-border-opacity: 1; border-color: rgb(233 213 2=
55 / var(--tw-border-opacity)); }

:is(.dark .button--purple:focus) { --tw-border-opacity: 1; border-color: rg=
b(147 51 234 / var(--tw-border-opacity)); }

.button--orange { --tw-bg-opacity: 1; background-color: rgb(255 237 213 / v=
ar(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(234 88 12 / var(--tw=
-text-opacity)); }

:is(.dark .button--orange) { --tw-bg-opacity: 1; background-color: rgb(194 =
65 12 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 237 213=
 / var(--tw-text-opacity)); }

.button--orange:hover { --tw-bg-opacity: 1; background-color: rgb(254 215 1=
70 / var(--tw-bg-opacity)); }

:is(.dark .button--orange:hover) { --tw-bg-opacity: 1; background-color: rg=
b(234 88 12 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 2=
55 255 / var(--tw-text-opacity)); }

.button--orange:focus { --tw-border-opacity: 1; border-color: rgb(254 215 1=
70 / var(--tw-border-opacity)); }

:is(.dark .button--orange:focus) { --tw-border-opacity: 1; border-color: rg=
b(234 88 12 / var(--tw-border-opacity)); }

.button--blue { --tw-bg-opacity: 1; background-color: rgb(235 248 255 / var=
(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(49 130 206 / var(--tw-=
text-opacity)); }

:is(.dark .button--blue) { --tw-bg-opacity: 1; background-color: rgb(43 108=
 176 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(235 248 255 =
/ var(--tw-text-opacity)); }

.button--blue:hover { --tw-bg-opacity: 1; background-color: rgb(191 219 254=
 / var(--tw-bg-opacity)); }

:is(.dark .button--blue:hover) { --tw-bg-opacity: 1; background-color: rgb(=
49 130 206 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(255 25=
5 255 / var(--tw-text-opacity)); }

.button--blue:focus { --tw-border-opacity: 1; border-color: rgb(191 219 254=
 / var(--tw-border-opacity)); }

:is(.dark .button--blue:focus) { --tw-border-opacity: 1; border-color: rgb(=
49 130 206 / var(--tw-border-opacity)); }

.button-purple { display: inline-flex; cursor: pointer; user-select: none; =
-webkit-box-align: center; align-items: center; border-width: 1px; border-c=
olor: transparent; text-align: center; font-weight: 700; transition-propert=
y: color, background-color, border-color, text-decoration-color, fill, stro=
ke, opacity, box-shadow, transform, filter, backdrop-filter, -webkit-text-d=
ecoration-color, -webkit-box-shadow, -webkit-transform, -webkit-filter, -we=
bkit-backdrop-filter; transition-timing-function: cubic-bezier(0, 0, 0.2, 1=
); transition-duration: 0.15s; --tw-bg-opacity: 1; background-color: rgb(24=
3 232 255 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(168 85 =
247 / var(--tw-text-opacity)); }

.button-purple:hover { --tw-bg-opacity: 1; background-color: rgb(233 213 25=
5 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(147 51 234 / va=
r(--tw-text-opacity)); }

.button-purple:active { --tw-bg-opacity: 1; background-color: rgb(216 180 2=
54 / var(--tw-bg-opacity)); }

:is(.dark .button-purple) { --tw-border-opacity: 1; border-color: rgb(168 8=
5 247 / var(--tw-border-opacity)); background-color: rgba(168, 85, 247, 0.5=
); --tw-text-opacity: 1; color: rgb(250 245 255 / var(--tw-text-opacity)); =
}

:is(.dark .button-purple:hover) { background-color: rgba(192, 132, 252, 0.5=
); --tw-text-opacity: 1; color: rgb(255 255 255 / var(--tw-text-opacity)); =
}

:is(.dark .button-purple:active) { background-color: rgba(147, 51, 234, 0.5=
); }

.button-blue { display: inline-flex; cursor: pointer; user-select: none; -w=
ebkit-box-align: center; align-items: center; border-width: 1px; border-col=
or: transparent; text-align: center; font-weight: 700; transition-property:=
 color, background-color, border-color, text-decoration-color, fill, stroke=
, opacity, box-shadow, transform, filter, backdrop-filter, -webkit-text-dec=
oration-color, -webkit-box-shadow, -webkit-transform, -webkit-filter, -webk=
it-backdrop-filter; transition-timing-function: cubic-bezier(0, 0, 0.2, 1);=
 transition-duration: 0.15s; --tw-bg-opacity: 1; background-color: rgb(235 =
248 255 / var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(65 153 22=
5 / var(--tw-text-opacity)); }

.button-blue:hover { --tw-bg-opacity: 1; background-color: rgb(191 219 254 =
/ var(--tw-bg-opacity)); --tw-text-opacity: 1; color: rgb(49 130 206 / var(=
--tw-text-opacity)); }

.button-blue:active { --tw-bg-opacity: 1; background-color: rgb(147 197 253=
 / var(--tw-bg-opacity)); }

:is(.dark .button-blue) { --tw-border-opacity: 1; border-color: rgb(65 153 =
225 / var(--tw-border-opacity)); background-color: rgba(65, 153, 225, 0.5);=
 --tw-text-opacity: 1; color: rgb(239 246 255 / var(--tw-text-opacity)); }

:is(.dark .button-blue:hover) { background-color: rgba(99, 179, 237, 0.5); =
--tw-text-opacity: 1; color: rgb(255 255 255 / var(--tw-text-opacity)); }

:is(.dark .button-blue:active) { background-color: rgba(49, 130, 206, 0.5);=
 }

.button-lg { border-radius: 0.75rem; padding: 1rem 2rem; }

.font-num { font-family: MonoLisa, ui-monospace, SFMono-Regular, Menlo, Mon=
aco, Consolas, "Liberation Mono", "Courier New", monospace; --tw-slashed-ze=
ro: slashed-zero; --tw-numeric-spacing: tabular-nums; font-variant-numeric:=
 var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw=
-numeric-spacing) var(--tw-numeric-fraction); }

.prevent-scroll { width: 100%; overflow-y: hidden; position: fixed !importa=
nt; }

.tbody { display: table-row-group; }

.tr { display: table-row; }

.td, .th { display: table-cell; }

.thead { display: table-header-group; }

.tfoot { display: table-footer-group; }

.button-nav { border-width: 1px; transition-property: color, background-col=
or, border-color, text-decoration-color, fill, stroke, opacity, box-shadow,=
 transform, filter, backdrop-filter, -webkit-text-decoration-color, -webkit=
-box-shadow, -webkit-transform, -webkit-filter, -webkit-backdrop-filter; tr=
ansition-timing-function: cubic-bezier(0, 0, 0.2, 1); transition-duration: =
0.15s; border-color: rgb(100 116 139 / var(--tw-border-opacity)); --tw-bord=
er-opacity: 0; background-color: rgb(226 232 240 / var(--tw-bg-opacity)); -=
-tw-bg-opacity: 0; --tw-text-opacity: 1; color: rgb(100 116 139 / var(--tw-=
text-opacity)); }

.button-nav:hover { --tw-border-opacity: .1; --tw-bg-opacity: .5; --tw-text=
-opacity: 1; color: rgb(71 85 105 / var(--tw-text-opacity)); }

.dark .button-nav { border-color: rgb(148 163 184 / var(--tw-border-opacity=
)); --tw-border-opacity: 0; background-color: rgb(100 116 139 / var(--tw-bg=
-opacity)); --tw-bg-opacity: 0; --tw-text-opacity: 1; color: rgb(148 163 18=
4 / var(--tw-text-opacity)); }

.dark .button-nav:hover { --tw-border-opacity: .1; --tw-bg-opacity: .2; --t=
w-text-opacity: 1; color: rgb(203 213 225 / var(--tw-text-opacity)); }

.fade-enter-active, .fade-leave-active { transition: opacity 0.5s cubic-bez=
ier(0.175, 0.885, 0.32, 1.275) 0s; }

.fade-enter, .fade-leave-to { opacity: 0; }

.notion-image-inset { position: absolute; inset: 0px; margin: 0px !importan=
t; }

.notion-h2 span { font-weight: 700; }

.notion-toggle > div { margin-left: 1.25rem; }

.notion-asset-wrapper { display: flex; -webkit-box-orient: vertical; -webki=
t-box-direction: normal; flex-direction: column; -webkit-box-align: center;=
 align-items: center; }

.notion-asset-wrapper > div { height: 100%; width: 100%; }

.notion-asset-wrapper > div > iframe { height: 100%; width: 100%; }

.notion img { width: 100%; }

.twitter-tweet { margin-left: auto; margin-right: auto; }

@media (pointer: fine) {
  .miniScrollbar::-webkit-scrollbar { height: 18px; width: 18px; }
  .miniScrollbar::-webkit-scrollbar-track { background-color: transparent; =
}
  .miniScrollbar::-webkit-scrollbar-thumb { background-clip: content-box; b=
ackground-color: rgba(51, 65, 85, 0.7); border: 6px solid transparent; bord=
er-radius: 20px; min-height: 60px; }
  .miniScrollbar::-webkit-scrollbar-thumb:hover { background-color: rgb(168=
, 187, 191); }
  html::-webkit-scrollbar { height: 18px; width: 18px; }
  html::-webkit-scrollbar-track { background-color: transparent; }
  html::-webkit-scrollbar-thumb { background-clip: content-box; background-=
color: rgba(51, 65, 85, 0.7); border: 6px solid transparent; border-radius:=
 20px; min-height: 60px; }
  html::-webkit-scrollbar-thumb:hover { background-color: rgb(168, 187, 191=
); }
  .microScrollbar::-webkit-scrollbar { height: 15px; width: 15px; }
  .microScrollbar::-webkit-scrollbar-track { background-color: transparent;=
 }
  .microScrollbar::-webkit-scrollbar-thumb { background-clip: content-box; =
background-color: rgba(51, 65, 85, 0.7); border: 6px solid transparent; bor=
der-radius: 10px; min-height: 60px; }
  .microScrollbar::-webkit-scrollbar-thumb:hover { background-color: rgb(16=
8, 187, 191); }
}

.scroll-container { will-change: transform; }

.noScrollbar { overflow-y: overlay; }

.noScrollbar::-webkit-scrollbar { width: 20px; }

.noScrollbar::-webkit-scrollbar-track { background-color: transparent; }

.noScrollbar::-webkit-scrollbar-thumb { background-clip: content-box; backg=
round-color: transparent; }

body { overflow-y: overlay; }

.chat-content { --tw-text-opacity: 1; color: rgb(209 213 219 / var(--tw-tex=
t-opacity)); }

.chat-content :where(p) { margin-top: 1rem; margin-bottom: 1rem; }

.chat-content :where(h1) { margin-top: 0px; margin-bottom: 1rem; font-size:=
 1.125rem; line-height: 1.75rem; font-weight: 900; --tw-text-opacity: 1; co=
lor: rgb(255 255 255 / var(--tw-text-opacity)); }

.chat-content :where(h2) { margin-top: 0px; margin-bottom: 1rem; font-size:=
 1.125rem; line-height: 1.75rem; font-weight: 700; color: rgba(255, 255, 25=
5, 0.9); }

.chat-content :where(h3, h4, h5, h6) { margin-top: 0px; margin-bottom: 1rem=
; font-size: 1rem; line-height: 1.5rem; font-weight: 700; color: rgba(255, =
255, 255, 0.8); }

.chat-content :where(strong) { font-weight: 600; --tw-text-opacity: 1; colo=
r: rgb(255 255 255 / var(--tw-text-opacity)); }

.chat-content :where(ul) { margin-top: 1rem; margin-bottom: 1rem; list-styl=
e-type: disc; padding-left: 1.5rem; }

.chat-content :where(ul > li) { padding-left: 0.25rem; }

.chat-content :where(li) { margin-top: 0.5rem; margin-bottom: 0.5rem; }

.chat-content :where(ol) { margin-top: 1rem; margin-bottom: 1rem; list-styl=
e-type: decimal; padding-left: 1.5rem; }

.chat-content :where(ol > li) { padding-left: 0.25rem; }

.chat-content :where(a) { font-weight: 500; --tw-text-opacity: 1; color: rg=
b(88 202 247 / var(--tw-text-opacity)); }

.chat-content :where(a):hover { text-decoration-line: underline; }

.chat-content :where(img) { margin-top: 2rem; margin-bottom: 2rem; max-widt=
h: 100%; }

.chat-content :where(blockquote) { margin-top: 1rem; margin-bottom: 1rem; b=
order-left-width: 2px; --tw-border-opacity: 1; border-color: rgb(113 114 11=
7 / var(--tw-border-opacity)); padding-left: 1rem; font-weight: 500; font-s=
tyle: italic; --tw-text-opacity: 1; color: rgb(243 244 246 / var(--tw-text-=
opacity)); quotes: "=E2=80=9C" "=E2=80=9D" "=E2=80=98" "=E2=80=99"; }

.chat-content :where(blockquote p:first-of-type)::before { content: open-qu=
ote; }

.chat-content :where(blockquote p:last-of-type)::after { content: close-quo=
te; }

.chat-content :where(table) { width: 100%; table-layout: auto; text-align: =
left; margin-top: 2em; margin-bottom: 2em; font-size: 0.875em; line-height:=
 1.71429; }

.chat-content :where(table thead) { border-bottom-width: 1px; --tw-border-o=
pacity: 1; border-bottom-color: rgb(75 85 99 / var(--tw-border-opacity)); }

.chat-content :where(table th) { padding-right: 1rem; padding-bottom: 1rem;=
 padding-left: 1rem; vertical-align: bottom; font-weight: 600; --tw-text-op=
acity: 1; color: rgb(255 255 255 / var(--tw-text-opacity)); }

.chat-content :where(table th:first-child) { padding-left: 0px; }

.chat-content :where(table th:last-child) { padding-right: 0px; }

.chat-content :where(tbody tr) { border-bottom-width: 1px; --tw-border-opac=
ity: 1; border-bottom-color: rgb(75 85 99 / var(--tw-border-opacity)); }

.chat-content :where(tbody td, tfoot td) { padding-right: 1rem; padding-bot=
tom: 1rem; padding-left: 1rem; }

.chat-content :where(tbody td) { vertical-align: baseline; }

.chat-content :where(tbody tr:last-child) { border-bottom-width: 0px; }

.chat-content :where(tbody td:first-child, tfoot td:first-child) { padding-=
left: 0px; }

.chat-content :where(.chat-content > :last-child) { margin-bottom: 0px; }

.chat-content :where(.chat-content > :first-child) { margin-top: 0px; }

.chat-content :where(code) { white-space: pre-wrap; border-radius: 0.25rem;=
 background-color: rgba(30, 41, 59, 0.5); padding: 1px 0.25rem; font-family=
: MonoLisa, ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberat=
ion Mono", "Courier New", monospace; font-size: 0.75rem; line-height: 1rem;=
 font-weight: 700; --tw-text-opacity: 1; color: rgb(36 228 142 / var(--tw-t=
ext-opacity)); }

.chat-content :where(pre code) { border-width: 1px; border-color: rgba(51, =
65, 85, 0.5); }

pre code.hljs { padding: 1rem; --tw-text-opacity: 1; color: rgb(209 213 219=
 / var(--tw-text-opacity)); }

.animate-cursor-blink { animation: 1s ease 0s infinite normal none running =
cursor-blink; }

@-webkit-keyframes cursor-blink {=20
  0% { opacity: 1; }
  40% { opacity: 1; }
  50% { opacity: 0; }
  90% { opacity: 0; }
  100% { opacity: 1; }
}

@keyframes cursor-blink {=20
  0% { opacity: 1; }
  40% { opacity: 1; }
  50% { opacity: 0; }
  90% { opacity: 0; }
  100% { opacity: 1; }
}

.chat-content-busy > p:last-child::after, .chat-content-busy > ol:last-chil=
d > li:last-child > p:last-child::after, .chat-content-busy > ul:last-child=
 > li:last-child > p:last-child::after, .chat-content-busy > h1:last-child:=
:after, .chat-content-busy > h2:last-child::after, .chat-content-busy > h3:=
last-child::after, .chat-content-busy > h4:last-child::after, .chat-content=
-busy > h5:last-child::after, .chat-content-busy > pre:last-child > code:la=
st-child::after { --tw-text-opacity: 1; color: rgb(249 187 73 / var(--tw-te=
xt-opacity)); animation: 1s ease 0s infinite normal none running cursor-bli=
nk; content: " =E2=96=8C"; }

.chat-content .header-anchor { padding-right: 8px; margin-left: -20px; colo=
r: inherit; float: left; display: none; opacity: 0; transition-property: co=
lor, background-color, border-color, text-decoration-color, fill, stroke, o=
pacity, box-shadow, transform, filter, backdrop-filter, -webkit-text-decora=
tion-color, -webkit-box-shadow, -webkit-transform, -webkit-filter, -webkit-=
backdrop-filter; transition-timing-function: cubic-bezier(0, 0, 0.2, 1); tr=
ansition-duration: 0.15s; }

.chat-content .header-anchor:hover { text-decoration-line: none; }

@media (min-width: 640px) {
  .chat-content .header-anchor { display: block; }
}

.chat-content :hover .header-anchor { opacity: 0.5; }

.hoverUpSmall { --tw-scale-x: 99.99999%; --tw-scale-y: 99.99999%; transform=
: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-ro=
tate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale=
-x)) scaleY(var(--tw-scale-y)); }

@media (hover: hover) and (pointer: fine) {
  .hoverUpSmall:hover { --tw-translate-y: -2px; transform: translate(var(--=
tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--=
tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--=
tw-scale-y)); }
}

.hoverUpSmall:active { --tw-translate-y: -0px; transform: translate(var(--t=
w-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--t=
w-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--t=
w-scale-y)); transition-duration: 75ms; }

.hoverUpSmall { --tw-shadow: 0 0 #0000; --tw-shadow-colored: 0 0 #0000; box=
-shadow: var(--tw-ring-offset-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 =
#0000),var(--tw-shadow); }

@media (hover: hover) and (pointer: fine) {
  .hoverUpSmall:hover { --tw-shadow: 0 10px 15px -3px rgba(0, 0, 0, .1), 0 =
4px 6px -4px rgba(0, 0, 0, .1); --tw-shadow-colored: 0 10px 15px -3px var(-=
-tw-shadow-color), 0 4px 6px -4px var(--tw-shadow-color); box-shadow: var(-=
-tw-ring-offset-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--t=
w-shadow); }
}

.hoverUpSmall:active { --tw-shadow: 0 0 #0000; --tw-shadow-colored: 0 0 #00=
00; box-shadow: var(--tw-ring-offset-shadow, 0 0 #0000),var(--tw-ring-shado=
w, 0 0 #0000),var(--tw-shadow); }

@media (hover: hover) and (pointer: fine) {
  .hoverUpSmall:hover { --tw-shadow-color: rgba(0, 0, 0, .5); --tw-shadow: =
var(--tw-shadow-colored); }
}

.hoverUpSmall { backface-visibility: hidden; transition-duration: 0.15s; tr=
ansition-property: color, background-color, border-color, text-decoration-c=
olor, fill, stroke, opacity, box-shadow, transform, filter, backdrop-filter=
, -webkit-backdrop-filter; transition-timing-function: cubic-bezier(0.4, 0,=
 0.2, 1); }

@media (color-gamut: p3) {
  svg path[fill=3D"#50c18e"] { fill: oklch(0.7322 0.214 161.1); }
  svg path[fill=3D"#f9bb49"] { fill: oklch(0.8294 0.194 79.26); }
  svg path[fill=3D"#e92e42"] { fill: oklch(0.6087 0.274 21.9); }
  svg path[fill=3D"#58caf7"] { fill: oklch(0.7912 0.148 227.38); }
}

.pointer-events-none { pointer-events: none; }

.pointer-events-auto { pointer-events: auto; }

.visible { visibility: visible; }

.invisible { visibility: hidden; }

.\!collapse { visibility: collapse !important; }

.collapse { visibility: collapse; }

.fixed { position: fixed; }

.absolute { position: absolute; }

.relative { position: relative; }

.sticky { position: sticky; }

.inset-0 { inset: 0px; }

.inset-x-0 { left: 0px; right: 0px; }

.inset-x-2 { left: 0.5rem; right: 0.5rem; }

.inset-y-0 { top: 0px; bottom: 0px; }

.-left-full { left: -100%; }

.bottom-0 { bottom: 0px; }

.bottom-2 { bottom: 0.5rem; }

.bottom-4 { bottom: 1rem; }

.left-0 { left: 0px; }

.left-1\/2 { left: 50%; }

.right-0 { right: 0px; }

.right-4 { right: 1rem; }

.top-0 { top: 0px; }

.top-full { top: 100%; }

.-z-10 { z-index: -10; }

.-z-50 { z-index: -50; }

.z-0 { z-index: 0; }

.z-10 { z-index: 10; }

.z-20 { z-index: 20; }

.z-40 { z-index: 40; }

.z-50 { z-index: 50; }

.z-\[1000000000000\] { z-index: 2147483647; }

.z-\[1000000\] { z-index: 1000000; }

.z-\[100\] { z-index: 100; }

.z-\[49\] { z-index: 49; }

.z-\[50000000\] { z-index: 50000000; }

.col-span-1 { grid-column: span 1 / span 1; }

.col-span-full { grid-column: 1 / -1; }

.m-0 { margin: 0px; }

.m-auto { margin: auto; }

.-mx-2 { margin-left: -0.5rem; margin-right: -0.5rem; }

.-mx-3 { margin-left: -0.75rem; margin-right: -0.75rem; }

.-mx-6 { margin-left: -1.5rem; margin-right: -1.5rem; }

.-my-0 { margin-top: 0px; margin-bottom: 0px; }

.-my-0\.5 { margin-top: -0.125rem; margin-bottom: -0.125rem; }

.mx-1 { margin-left: 0.25rem; margin-right: 0.25rem; }

.mx-3 { margin-left: 0.75rem; margin-right: 0.75rem; }

.mx-6 { margin-left: 1.5rem; margin-right: 1.5rem; }

.mx-auto { margin-left: auto; margin-right: auto; }

.mx-px { margin-left: 1px; margin-right: 1px; }

.my-0 { margin-top: 0px; margin-bottom: 0px; }

.my-0\.5 { margin-top: 0.125rem; margin-bottom: 0.125rem; }

.my-1 { margin-top: 0.25rem; margin-bottom: 0.25rem; }

.my-2 { margin-top: 0.5rem; margin-bottom: 0.5rem; }

.my-3 { margin-top: 0.75rem; margin-bottom: 0.75rem; }

.my-4 { margin-top: 1rem; margin-bottom: 1rem; }

.my-8 { margin-top: 2rem; margin-bottom: 2rem; }

.-ml-1 { margin-left: -0.25rem; }

.-ml-3 { margin-left: -0.75rem; }

.-ml-4 { margin-left: -1rem; }

.-mt-1 { margin-top: -0.25rem; }

.-mt-1\.5 { margin-top: -0.375rem; }

.-mt-16 { margin-top: -4rem; }

.-mt-24 { margin-top: -6rem; }

.-mt-4 { margin-top: -1rem; }

.mb-1 { margin-bottom: 0.25rem; }

.mb-14 { margin-bottom: 3.5rem; }

.mb-16 { margin-bottom: 4rem; }

.mb-2 { margin-bottom: 0.5rem; }

.mb-4 { margin-bottom: 1rem; }

.mb-6 { margin-bottom: 1.5rem; }

.ml-1 { margin-left: 0.25rem; }

.ml-2 { margin-left: 0.5rem; }

.ml-3 { margin-left: 0.75rem; }

.ml-4 { margin-left: 1rem; }

.ml-5 { margin-left: 1.25rem; }

.ml-auto { margin-left: auto; }

.mr-1 { margin-right: 0.25rem; }

.mr-2 { margin-right: 0.5rem; }

.mr-3 { margin-right: 0.75rem; }

.mr-4 { margin-right: 1rem; }

.mr-6 { margin-right: 1.5rem; }

.mr-auto { margin-right: auto; }

.mt-1 { margin-top: 0.25rem; }

.mt-12 { margin-top: 3rem; }

.mt-2 { margin-top: 0.5rem; }

.mt-3 { margin-top: 0.75rem; }

.mt-4 { margin-top: 1rem; }

.mt-5 { margin-top: 1.25rem; }

.mt-6 { margin-top: 1.5rem; }

.mt-64 { margin-top: 16rem; }

.mt-8 { margin-top: 2rem; }

.block { display: block; }

.inline-block { display: inline-block; }

.inline { display: inline; }

.flex { display: flex; }

.inline-flex { display: inline-flex; }

.table { display: table; }

.grid { display: grid; }

.hidden { display: none; }

.h-0 { height: 0px; }

.h-1 { height: 0.25rem; }

.h-10 { height: 2.5rem; }

.h-11 { height: 2.75rem; }

.h-12 { height: 3rem; }

.h-16 { height: 4rem; }

.h-2 { height: 0.5rem; }

.h-3 { height: 0.75rem; }

.h-3\.5 { height: 0.875rem; }

.h-32 { height: 8rem; }

.h-4 { height: 1rem; }

.h-5 { height: 1.25rem; }

.h-52 { height: 13rem; }

.h-6 { height: 1.5rem; }

.h-64 { height: 16rem; }

.h-7 { height: 1.75rem; }

.h-8 { height: 2rem; }

.h-\[400px\] { height: 400px; }

.h-auto { height: auto; }

.h-full { height: 100%; }

.h-px { height: 1px; }

.h-screen { height: 100vh; }

.max-h-\[60vh\] { max-height: 60vh; }

.max-h-screen { max-height: 100vh; }

.min-h-\[3rem\] { min-height: 3rem; }

.min-h-full { min-height: 100%; }

.min-h-screen { min-height: 100vh; }

.w-0 { width: 0px; }

.w-1 { width: 0.25rem; }

.w-1\/2 { width: 50%; }

.w-10 { width: 2.5rem; }

.w-12 { width: 3rem; }

.w-2 { width: 0.5rem; }

.w-3 { width: 0.75rem; }

.w-3\.5 { width: 0.875rem; }

.w-32 { width: 8rem; }

.w-4 { width: 1rem; }

.w-5 { width: 1.25rem; }

.w-6 { width: 1.5rem; }

.w-64 { width: 16rem; }

.w-7 { width: 1.75rem; }

.w-8 { width: 2rem; }

.w-\[256px\] { width: 256px; }

.w-auto { width: auto; }

.w-full { width: 100%; }

.w-px { width: 1px; }

.min-w-\[14px\] { min-width: 14px; }

.min-w-\[16px\] { min-width: 16px; }

.min-w-\[20px\] { min-width: 20px; }

.min-w-\[24px\] { min-width: 24px; }

.max-w-lg { max-width: 32rem; }

.max-w-screen-sm { max-width: 640px; }

.max-w-sm { max-width: 24rem; }

.max-w-xl { max-width: 36rem; }

.max-w-xs { max-width: 20rem; }

.flex-1 { -webkit-box-flex: 1; flex: 1 1 0%; }

.flex-shrink-0 { flex-shrink: 0; }

.shrink { flex-shrink: 1; }

.shrink-0 { flex-shrink: 0; }

.grow { -webkit-box-flex: 1; flex-grow: 1; }

.origin-center { transform-origin: center center; }

.origin-top-left { transform-origin: left top; }

.-translate-x-1\/2 { --tw-translate-x: -50%; transform: translate(var(--tw-=
translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-=
skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-=
scale-y)); }

.-translate-x-\[256px\] { --tw-translate-x: -256px; transform: translate(va=
r(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(va=
r(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(va=
r(--tw-scale-y)); }

.-translate-y-4 { --tw-translate-y: -1rem; transform: translate(var(--tw-tr=
anslate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-sk=
ew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-sc=
ale-y)); }

.translate-x-0 { --tw-translate-x: 0px; transform: translate(var(--tw-trans=
late-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-=
x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale=
-y)); }

.translate-x-16 { --tw-translate-x: 4rem; transform: translate(var(--tw-tra=
nslate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-ske=
w-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-sca=
le-y)); }

.translate-y-0 { --tw-translate-y: 0px; transform: translate(var(--tw-trans=
late-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-=
x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale=
-y)); }

.translate-y-2 { --tw-translate-y: .5rem; transform: translate(var(--tw-tra=
nslate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-ske=
w-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-sca=
le-y)); }

.translate-y-4 { --tw-translate-y: 1rem; transform: translate(var(--tw-tran=
slate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew=
-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scal=
e-y)); }

.-rotate-90 { --tw-rotate: -90deg; transform: translate(var(--tw-translate-=
x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) s=
kewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));=
 }

.rotate-180 { --tw-rotate: 180deg; transform: translate(var(--tw-translate-=
x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) s=
kewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));=
 }

.scale-0 { --tw-scale-x: 0; --tw-scale-y: 0; transform: translate(var(--tw-=
translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-=
skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-=
scale-y)); }

.scale-100 { --tw-scale-x: 1; --tw-scale-y: 1; transform: translate(var(--t=
w-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--t=
w-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--t=
w-scale-y)); }

.scale-105 { --tw-scale-x: 1.05; --tw-scale-y: 1.05; transform: translate(v=
ar(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(v=
ar(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(v=
ar(--tw-scale-y)); }

.scale-75 { --tw-scale-x: .75; --tw-scale-y: .75; transform: translate(var(=
--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(=
--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(=
--tw-scale-y)); }

.scale-95 { --tw-scale-x: .95; --tw-scale-y: .95; transform: translate(var(=
--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(=
--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(=
--tw-scale-y)); }

.-scale-x-100 { --tw-scale-x: -1; transform: translate(var(--tw-translate-x=
),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) sk=
ewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); =
}

.transform { transform: translate(var(--tw-translate-x),var(--tw-translate-=
y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y))=
 scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.transform-gpu { transform: translate3d(var(--tw-translate-x),var(--tw-tran=
slate-y),0) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-=
skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

@-webkit-keyframes ping {=20
  75%, 100% { transform: scale(2); opacity: 0; }
}

.animate-\[ping_1\.5s_ease-out_infinite\] { animation: 1.5s ease-out 0s inf=
inite normal none running ping; }

.animate-ping { animation: 1s cubic-bezier(0, 0, 0.2, 1) 0s infinite normal=
 none running ping; }

@-webkit-keyframes pulse {=20
  50% { opacity: 0.5; }
}

@keyframes pulse {=20
  50% { opacity: 0.5; }
}

.animate-pulse { animation: 2s cubic-bezier(0.4, 0, 0.6, 1) 0s infinite nor=
mal none running pulse; }

@-webkit-keyframes spin {=20
  100% { transform: rotate(360deg); }
}

@keyframes spin {=20
  100% { transform: rotate(360deg); }
}

.animate-spin { animation: 1s linear 0s infinite normal none running spin; =
}

.cursor-default { cursor: default; }

.cursor-pointer { cursor: pointer; }

.cursor-zoom-in { cursor: zoom-in; }

.cursor-zoom-out { cursor: zoom-out; }

.select-none { user-select: none; }

.resize-none { resize: none; }

.appearance-none { appearance: none; }

.grid-cols-1 { grid-template-columns: repeat(1, minmax(0px, 1fr)); }

.grid-cols-\[repeat\(auto-fit\,minmax\(350px\,1fr\)\)\] { grid-template-col=
umns: repeat(auto-fit, minmax(350px, 1fr)); }

.flex-col { -webkit-box-orient: vertical; -webkit-box-direction: normal; fl=
ex-direction: column; }

.flex-col-reverse { -webkit-box-orient: vertical; -webkit-box-direction: re=
verse; flex-direction: column-reverse; }

.flex-wrap { flex-wrap: wrap; }

.items-start { -webkit-box-align: start; align-items: flex-start; }

.items-end { -webkit-box-align: end; align-items: flex-end; }

.items-center { -webkit-box-align: center; align-items: center; }

.items-stretch { -webkit-box-align: stretch; align-items: stretch; }

.justify-start { -webkit-box-pack: start; justify-content: flex-start; }

.justify-end { -webkit-box-pack: end; justify-content: flex-end; }

.justify-center { -webkit-box-pack: center; justify-content: center; }

.justify-between { -webkit-box-pack: justify; justify-content: space-betwee=
n; }

.gap-1 { gap: 0.25rem; }

.gap-12 { gap: 3rem; }

.gap-2 { gap: 0.5rem; }

.gap-3 { gap: 0.75rem; }

.gap-4 { gap: 1rem; }

.gap-6 { gap: 1.5rem; }

.gap-x-2 { column-gap: 0.5rem; }

.gap-x-4 { column-gap: 1rem; }

.space-x-0 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse: 0; mar=
gin-right: calc(0px * var(--tw-space-x-reverse)); margin-left: calc(0px * c=
alc(1 - var(--tw-space-x-reverse))); }

.space-x-0\.5 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse: 0; =
margin-right: calc(.125rem * var(--tw-space-x-reverse)); margin-left: calc(=
.125rem * calc(1 - var(--tw-space-x-reverse))); }

.space-x-2 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse: 0; mar=
gin-right: calc(.5rem * var(--tw-space-x-reverse)); margin-left: calc(.5rem=
 * calc(1 - var(--tw-space-x-reverse))); }

.space-x-4 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse: 0; mar=
gin-right: calc(1rem * var(--tw-space-x-reverse)); margin-left: calc(1rem *=
 calc(1 - var(--tw-space-x-reverse))); }

.space-y-0 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; mar=
gin-top: calc(0px * calc(1 - var(--tw-space-y-reverse))); margin-bottom: ca=
lc(0px * var(--tw-space-y-reverse)); }

.space-y-0\.5 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; =
margin-top: calc(.125rem * calc(1 - var(--tw-space-y-reverse))); margin-bot=
tom: calc(.125rem * var(--tw-space-y-reverse)); }

.space-y-1 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; mar=
gin-top: calc(.25rem * calc(1 - var(--tw-space-y-reverse))); margin-bottom:=
 calc(.25rem * var(--tw-space-y-reverse)); }

.space-y-1\.5 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; =
margin-top: calc(.375rem * calc(1 - var(--tw-space-y-reverse))); margin-bot=
tom: calc(.375rem * var(--tw-space-y-reverse)); }

.space-y-2 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; mar=
gin-top: calc(.5rem * calc(1 - var(--tw-space-y-reverse))); margin-bottom: =
calc(.5rem * var(--tw-space-y-reverse)); }

.space-y-3 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; mar=
gin-top: calc(.75rem * calc(1 - var(--tw-space-y-reverse))); margin-bottom:=
 calc(.75rem * var(--tw-space-y-reverse)); }

.space-y-6 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse: 0; mar=
gin-top: calc(1.5rem * calc(1 - var(--tw-space-y-reverse))); margin-bottom:=
 calc(1.5rem * var(--tw-space-y-reverse)); }

.divide-y > :not([hidden]) ~ :not([hidden]) { --tw-divide-y-reverse: 0; bor=
der-top-width: calc(1px * calc(1 - var(--tw-divide-y-reverse))); border-bot=
tom-width: calc(1px * var(--tw-divide-y-reverse)); }

.divide-slate-800 > :not([hidden]) ~ :not([hidden]) { --tw-divide-opacity: =
1; border-color: rgb(30 41 59 / var(--tw-divide-opacity)); }

.divide-white\/5 > :not([hidden]) ~ :not([hidden]) { border-color: rgba(255=
, 255, 255, 0.05); }

.overflow-auto { overflow: auto; }

.overflow-hidden { overflow: hidden; }

.overflow-visible { overflow: visible; }

.overflow-y-auto { overflow-y: auto; }

.overflow-x-scroll { overflow-x: scroll; }

.overscroll-none { overscroll-behavior: none; }

.truncate { overflow: hidden; text-overflow: ellipsis; white-space: nowrap;=
 }

.whitespace-nowrap { white-space: nowrap; }

.whitespace-pre { white-space: pre; }

.break-words { overflow-wrap: break-word; }

.rounded { border-radius: 0.25rem; }

.rounded-2xl { border-radius: 1rem; }

.rounded-3xl { border-radius: 1.5rem; }

.rounded-full { border-radius: 9999px; }

.rounded-lg { border-radius: 0.5rem; }

.rounded-md { border-radius: 0.375rem; }

.rounded-xl { border-radius: 0.75rem; }

.rounded-t-2xl { border-top-left-radius: 1rem; border-top-right-radius: 1re=
m; }

.\!border { border-width: 1px !important; }

.border { border-width: 1px; }

.border-2 { border-width: 2px; }

.border-b { border-bottom-width: 1px; }

.border-b-2 { border-bottom-width: 2px; }

.border-r { border-right-width: 1px; }

.border-r-2 { border-right-width: 2px; }

.border-t { border-top-width: 1px; }

.border-dashed { border-style: dashed; }

.border-none { border-style: none; }

.\!border-transparent { border-color: transparent !important; }

.border-\[\#50c18e\]\/90 { border-color: rgba(80, 193, 142, 0.9); }

.border-blue-400 { --tw-border-opacity: 1; border-color: rgb(99 179 237 / v=
ar(--tw-border-opacity)); }

.border-blue-400\/50 { border-color: rgba(99, 179, 237, 0.5); }

.border-blue-600 { --tw-border-opacity: 1; border-color: rgb(49 130 206 / v=
ar(--tw-border-opacity)); }

.border-blue-900\/30 { border-color: rgba(42, 67, 101, 0.3); }

.border-darkBlue-400 { --tw-border-opacity: 1; border-color: rgb(96 165 250=
 / var(--tw-border-opacity)); }

.border-darkBlue-500 { --tw-border-opacity: 1; border-color: rgb(26 30 45 /=
 var(--tw-border-opacity)); }

.border-darkBlue-500\/50 { border-color: rgba(26, 30, 45, 0.5); }

.border-gray-200 { --tw-border-opacity: 1; border-color: rgb(226 232 240 / =
var(--tw-border-opacity)); }

.border-gray-300 { --tw-border-opacity: 1; border-color: rgb(203 213 225 / =
var(--tw-border-opacity)); }

.border-gray-400 { --tw-border-opacity: 1; border-color: rgb(148 163 184 / =
var(--tw-border-opacity)); }

.border-gray-600 { --tw-border-opacity: 1; border-color: rgb(71 85 105 / va=
r(--tw-border-opacity)); }

.border-gray-700 { --tw-border-opacity: 1; border-color: rgb(51 65 85 / var=
(--tw-border-opacity)); }

.border-gray-800 { --tw-border-opacity: 1; border-color: rgb(30 41 59 / var=
(--tw-border-opacity)); }

.border-green-100 { --tw-border-opacity: 1; border-color: rgb(220 252 231 /=
 var(--tw-border-opacity)); }

.border-green-400 { --tw-border-opacity: 1; border-color: rgb(74 222 128 / =
var(--tw-border-opacity)); }

.border-green-600 { --tw-border-opacity: 1; border-color: rgb(22 163 74 / v=
ar(--tw-border-opacity)); }

.border-orange-100 { --tw-border-opacity: 1; border-color: rgb(255 237 213 =
/ var(--tw-border-opacity)); }

.border-red-100 { --tw-border-opacity: 1; border-color: rgb(254 226 226 / v=
ar(--tw-border-opacity)); }

.border-red-300 { --tw-border-opacity: 1; border-color: rgb(252 165 165 / v=
ar(--tw-border-opacity)); }

.border-red-400 { --tw-border-opacity: 1; border-color: rgb(248 113 113 / v=
ar(--tw-border-opacity)); }

.border-slate-500\/10 { border-color: rgba(100, 116, 139, 0.1); }

.border-slate-500\/20 { border-color: rgba(100, 116, 139, 0.2); }

.border-slate-500\/30 { border-color: rgba(100, 116, 139, 0.3); }

.border-slate-700\/10 { border-color: rgba(51, 65, 85, 0.1); }

.border-slate-700\/50 { border-color: rgba(51, 65, 85, 0.5); }

.border-slate-800 { --tw-border-opacity: 1; border-color: rgb(30 41 59 / va=
r(--tw-border-opacity)); }

.border-slate-800\/30 { border-color: rgba(30, 41, 59, 0.3); }

.border-slate-800\/50 { border-color: rgba(30, 41, 59, 0.5); }

.border-transparent { border-color: transparent; }

.border-white\/10 { border-color: rgba(255, 255, 255, 0.1); }

.border-white\/5 { border-color: rgba(255, 255, 255, 0.05); }

.border-yellow-500 { --tw-border-opacity: 1; border-color: rgb(234 179 8 / =
var(--tw-border-opacity)); }

.border-t-slate-500\/10 { border-top-color: rgba(100, 116, 139, 0.1); }

.border-opacity-20 { --tw-border-opacity: .2; }

.bg-\[\#080f1f\] { --tw-bg-opacity: 1; background-color: rgb(8 15 31 / var(=
--tw-bg-opacity)); }

.bg-\[\#090b16\] { --tw-bg-opacity: 1; background-color: rgb(9 11 22 / var(=
--tw-bg-opacity)); }

.bg-\[\#090b16\]\/50 { background-color: rgba(9, 11, 22, 0.5); }

.bg-\[\#0c101f\] { --tw-bg-opacity: 1; background-color: rgb(12 16 31 / var=
(--tw-bg-opacity)); }

.bg-\[\#50c18e\]\/10 { background-color: rgba(80, 193, 142, 0.1); }

.bg-black { --tw-bg-opacity: 1; background-color: rgb(0 0 0 / var(--tw-bg-o=
pacity)); }

.bg-black\/5 { background-color: rgba(0, 0, 0, 0.05); }

.bg-blue-100 { --tw-bg-opacity: 1; background-color: rgb(235 248 255 / var(=
--tw-bg-opacity)); }

.bg-blue-400 { --tw-bg-opacity: 1; background-color: rgb(99 179 237 / var(-=
-tw-bg-opacity)); }

.bg-blue-500 { --tw-bg-opacity: 1; background-color: rgb(65 153 225 / var(-=
-tw-bg-opacity)); }

.bg-blue-600 { --tw-bg-opacity: 1; background-color: rgb(49 130 206 / var(-=
-tw-bg-opacity)); }

.bg-blue-700 { --tw-bg-opacity: 1; background-color: rgb(43 108 176 / var(-=
-tw-bg-opacity)); }

.bg-blue-800 { --tw-bg-opacity: 1; background-color: rgb(44 82 130 / var(--=
tw-bg-opacity)); }

.bg-blue-900\/30 { background-color: rgba(42, 67, 101, 0.3); }

.bg-blue-900\/90 { background-color: rgba(42, 67, 101, 0.9); }

.bg-darkBlue-500 { --tw-bg-opacity: 1; background-color: rgb(26 30 45 / var=
(--tw-bg-opacity)); }

.bg-darkBlue-500\/50 { background-color: rgba(26, 30, 45, 0.5); }

.bg-darkBlue-500\/70 { background-color: rgba(26, 30, 45, 0.7); }

.bg-darkBlue-500\/75 { background-color: rgba(26, 30, 45, 0.75); }

.bg-darkBlue-600 { --tw-bg-opacity: 1; background-color: rgb(37 99 235 / va=
r(--tw-bg-opacity)); }

.bg-darkBlue-700 { --tw-bg-opacity: 1; background-color: rgb(15 18 32 / var=
(--tw-bg-opacity)); }

.bg-darkBlue-900\/50 { background-color: rgba(8, 11, 22, 0.5); }

.bg-darkBlue-900\/60 { background-color: rgba(8, 11, 22, 0.6); }

.bg-darkBlue-900\/90 { background-color: rgba(8, 11, 22, 0.9); }

.bg-gray-100 { --tw-bg-opacity: 1; background-color: rgb(241 245 249 / var(=
--tw-bg-opacity)); }

.bg-gray-200 { --tw-bg-opacity: 1; background-color: rgb(226 232 240 / var(=
--tw-bg-opacity)); }

.bg-gray-400 { --tw-bg-opacity: 1; background-color: rgb(148 163 184 / var(=
--tw-bg-opacity)); }

.bg-gray-600 { --tw-bg-opacity: 1; background-color: rgb(71 85 105 / var(--=
tw-bg-opacity)); }

.bg-gray-800 { --tw-bg-opacity: 1; background-color: rgb(30 41 59 / var(--t=
w-bg-opacity)); }

.bg-green-400 { --tw-bg-opacity: 1; background-color: rgb(74 222 128 / var(=
--tw-bg-opacity)); }

.bg-green-50 { --tw-bg-opacity: 1; background-color: rgb(240 253 244 / var(=
--tw-bg-opacity)); }

.bg-green-500 { --tw-bg-opacity: 1; background-color: rgb(34 197 94 / var(-=
-tw-bg-opacity)); }

.bg-orange-50 { --tw-bg-opacity: 1; background-color: rgb(255 247 237 / var=
(--tw-bg-opacity)); }

.bg-purple-200 { --tw-bg-opacity: 1; background-color: rgb(233 213 255 / va=
r(--tw-bg-opacity)); }

.bg-purple-600 { --tw-bg-opacity: 1; background-color: rgb(147 51 234 / var=
(--tw-bg-opacity)); }

.bg-red-100 { --tw-bg-opacity: 1; background-color: rgb(254 226 226 / var(-=
-tw-bg-opacity)); }

.bg-red-400 { --tw-bg-opacity: 1; background-color: rgb(248 113 113 / var(-=
-tw-bg-opacity)); }

.bg-red-50 { --tw-bg-opacity: 1; background-color: rgb(254 242 242 / var(--=
tw-bg-opacity)); }

.bg-red-500 { --tw-bg-opacity: 1; background-color: rgb(239 68 68 / var(--t=
w-bg-opacity)); }

.bg-red-500\/10 { background-color: rgba(239, 68, 68, 0.1); }

.bg-red-700 { --tw-bg-opacity: 1; background-color: rgb(185 28 28 / var(--t=
w-bg-opacity)); }

.bg-slate-400 { --tw-bg-opacity: 1; background-color: rgb(148 163 184 / var=
(--tw-bg-opacity)); }

.bg-slate-50 { --tw-bg-opacity: 1; background-color: rgb(248 250 252 / var(=
--tw-bg-opacity)); }

.bg-slate-500\/10 { background-color: rgba(100, 116, 139, 0.1); }

.bg-slate-500\/20 { background-color: rgba(100, 116, 139, 0.2); }

.bg-slate-500\/\[0\.05\] { background-color: rgba(100, 116, 139, 0.05); }

.bg-slate-700 { --tw-bg-opacity: 1; background-color: rgb(51 65 85 / var(--=
tw-bg-opacity)); }

.bg-slate-800 { --tw-bg-opacity: 1; background-color: rgb(30 41 59 / var(--=
tw-bg-opacity)); }

.bg-slate-800\/10 { background-color: rgba(30, 41, 59, 0.1); }

.bg-slate-800\/50 { background-color: rgba(30, 41, 59, 0.5); }

.bg-slate-900 { --tw-bg-opacity: 1; background-color: rgb(15 23 42 / var(--=
tw-bg-opacity)); }

.bg-transparent { background-color: transparent; }

.bg-uiBlue-600 { --tw-bg-opacity: 1; background-color: rgb(76 82 134 / var(=
--tw-bg-opacity)); }

.bg-white { --tw-bg-opacity: 1; background-color: rgb(255 255 255 / var(--t=
w-bg-opacity)); }

.bg-white\/10 { background-color: rgba(255, 255, 255, 0.1); }

.bg-yellow-400 { --tw-bg-opacity: 1; background-color: rgb(250 204 21 / var=
(--tw-bg-opacity)); }

.bg-yellow-500 { --tw-bg-opacity: 1; background-color: rgb(234 179 8 / var(=
--tw-bg-opacity)); }

.bg-yellow-500\/10 { background-color: rgba(234, 179, 8, 0.1); }

.\!bg-opacity-100 { --tw-bg-opacity: 1 !important; }

.\!bg-opacity-20 { --tw-bg-opacity: .2 !important; }

.\!bg-opacity-95 { --tw-bg-opacity: .95 !important; }

.bg-opacity-10 { --tw-bg-opacity: .1; }

.bg-opacity-20 { --tw-bg-opacity: .2; }

.bg-opacity-5 { --tw-bg-opacity: .05; }

.bg-opacity-75 { --tw-bg-opacity: .75; }

.bg-opacity-80 { --tw-bg-opacity: .8; }

.bg-\[image\:url\(\'\/img\/waves\.svg\'\)\] { background-image: url("/img/w=
aves.svg"); }

.bg-gradient-to-bl { background-image: linear-gradient(to bottom left,var(-=
-tw-gradient-stops)); }

.bg-gradient-to-br { background-image: linear-gradient(to bottom right,var(=
--tw-gradient-stops)); }

.from-\[\#172B51\] { --tw-gradient-from: #172B51 var(--tw-gradient-from-pos=
ition); --tw-gradient-to: rgb(23 43 81 / 0) var(--tw-gradient-to-position);=
 --tw-gradient-stops: var(--tw-gradient-from), var(--tw-gradient-to); }

.from-red-300\/5 { --tw-gradient-from: rgb(252 165 165 / .05) var(--tw-grad=
ient-from-position); --tw-gradient-to: rgb(252 165 165 / 0) var(--tw-gradie=
nt-to-position); --tw-gradient-stops: var(--tw-gradient-from), var(--tw-gra=
dient-to); }

.to-\[\#1d3259\] { --tw-gradient-to: #1d3259 var(--tw-gradient-to-position)=
; }

.to-transparent { --tw-gradient-to: transparent var(--tw-gradient-to-positi=
on); }

.bg-cover { background-size: cover; }

.object-contain { object-fit: contain; }

.object-cover { object-fit: cover; }

.p-0 { padding: 0px; }

.p-0\.5 { padding: 0.125rem; }

.p-1 { padding: 0.25rem; }

.p-1\.5 { padding: 0.375rem; }

.p-2 { padding: 0.5rem; }

.p-4 { padding: 1rem; }

.p-6 { padding: 1.5rem; }

.px-0 { padding-left: 0px; padding-right: 0px; }

.px-0\.5 { padding-left: 0.125rem; padding-right: 0.125rem; }

.px-1 { padding-left: 0.25rem; padding-right: 0.25rem; }

.px-1\.5 { padding-left: 0.375rem; padding-right: 0.375rem; }

.px-10 { padding-left: 2.5rem; padding-right: 2.5rem; }

.px-2 { padding-left: 0.5rem; padding-right: 0.5rem; }

.px-2\.5 { padding-left: 0.625rem; padding-right: 0.625rem; }

.px-3 { padding-left: 0.75rem; padding-right: 0.75rem; }

.px-3\.5 { padding-left: 0.875rem; padding-right: 0.875rem; }

.px-4 { padding-left: 1rem; padding-right: 1rem; }

.px-5 { padding-left: 1.25rem; padding-right: 1.25rem; }

.px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }

.py-0 { padding-top: 0px; padding-bottom: 0px; }

.py-0\.5 { padding-top: 0.125rem; padding-bottom: 0.125rem; }

.py-1 { padding-top: 0.25rem; padding-bottom: 0.25rem; }

.py-1\.5 { padding-top: 0.375rem; padding-bottom: 0.375rem; }

.py-16 { padding-top: 4rem; padding-bottom: 4rem; }

.py-2 { padding-top: 0.5rem; padding-bottom: 0.5rem; }

.py-2\.5 { padding-top: 0.625rem; padding-bottom: 0.625rem; }

.py-3 { padding-top: 0.75rem; padding-bottom: 0.75rem; }

.py-32 { padding-top: 8rem; padding-bottom: 8rem; }

.py-4 { padding-top: 1rem; padding-bottom: 1rem; }

.py-5 { padding-top: 1.25rem; padding-bottom: 1.25rem; }

.py-6 { padding-top: 1.5rem; padding-bottom: 1.5rem; }

.py-8 { padding-top: 2rem; padding-bottom: 2rem; }

.pb-16 { padding-bottom: 4rem; }

.pb-2 { padding-bottom: 0.5rem; }

.pb-20 { padding-bottom: 5rem; }

.pb-24 { padding-bottom: 6rem; }

.pb-3 { padding-bottom: 0.75rem; }

.pb-4 { padding-bottom: 1rem; }

.pb-6 { padding-bottom: 1.5rem; }

.pl-0 { padding-left: 0px; }

.pl-0\.5 { padding-left: 0.125rem; }

.pl-2 { padding-left: 0.5rem; }

.pl-3 { padding-left: 0.75rem; }

.pl-4 { padding-left: 1rem; }

.pl-6 { padding-left: 1.5rem; }

.pl-7 { padding-left: 1.75rem; }

.pr-10 { padding-right: 2.5rem; }

.pr-12 { padding-right: 3rem; }

.pr-2 { padding-right: 0.5rem; }

.pr-2\.5 { padding-right: 0.625rem; }

.pr-3 { padding-right: 0.75rem; }

.pr-6 { padding-right: 1.5rem; }

.pt-0 { padding-top: 0px; }

.pt-0\.5 { padding-top: 0.125rem; }

.pt-12 { padding-top: 3rem; }

.pt-2 { padding-top: 0.5rem; }

.pt-4 { padding-top: 1rem; }

.pt-5 { padding-top: 1.25rem; }

.pt-6 { padding-top: 1.5rem; }

.pt-8 { padding-top: 2rem; }

.text-left { text-align: left; }

.text-center { text-align: center; }

.text-right { text-align: right; }

.align-middle { vertical-align: middle; }

.align-bottom { vertical-align: bottom; }

.font-default { font-family: ui-sans-serif, system-ui, -apple-system, Blink=
MacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sa=
ns-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto C=
olor Emoji"; }

.text-2xl { font-size: 1.5rem; line-height: 2rem; }

.text-3xl { font-size: 1.875rem; line-height: 2.25rem; }

.text-4xl { font-size: 2.25rem; line-height: 2.5rem; }

.text-\[10px\] { font-size: 10px; }

.text-\[15px\] { font-size: 15px; }

.text-\[8px\] { font-size: 8px; }

.text-base { font-size: 1rem; line-height: 1.5rem; }

.text-lg { font-size: 1.125rem; line-height: 1.75rem; }

.text-sm { font-size: 0.875rem; line-height: 1.25rem; }

.text-xl { font-size: 1.25rem; line-height: 1.75rem; }

.text-xs { font-size: 0.75rem; line-height: 1rem; }

.font-black { font-weight: 900; }

.font-bold { font-weight: 700; }

.font-extrabold { font-weight: 800; }

.font-medium { font-weight: 500; }

.font-normal { font-weight: 400; }

.font-semibold { font-weight: 600; }

.uppercase { text-transform: uppercase; }

.capitalize { text-transform: capitalize; }

.leading-4 { line-height: 1rem; }

.leading-5 { line-height: 1.25rem; }

.leading-6 { line-height: 1.5rem; }

.leading-9 { line-height: 2.25rem; }

.leading-\[16px\] { line-height: 16px; }

.leading-\[18px\] { line-height: 18px; }

.leading-none { line-height: 1; }

.tracking-tight { letter-spacing: -0.025em; }

.tracking-tighter { letter-spacing: -0.05em; }

.tracking-wide { letter-spacing: 0.025em; }

.tracking-widest { letter-spacing: 0.1em; }

.text-\[\#0088cc\] { --tw-text-opacity: 1; color: rgb(0 136 204 / var(--tw-=
text-opacity)); }

.text-\[\#1da1f2\] { --tw-text-opacity: 1; color: rgb(29 161 242 / var(--tw=
-text-opacity)); }

.text-\[\#50c18e\] { --tw-text-opacity: 1; color: rgb(80 193 142 / var(--tw=
-text-opacity)); }

.text-\[\#7289da\] { --tw-text-opacity: 1; color: rgb(114 137 218 / var(--t=
w-text-opacity)); }

.text-\[\#c0d0f1\] { --tw-text-opacity: 1; color: rgb(192 208 241 / var(--t=
w-text-opacity)); }

.text-\[\#c0d0f1\]\/50 { color: rgba(192, 208, 241, 0.5); }

.text-\[\#dcffff\] { --tw-text-opacity: 1; color: rgb(220 255 255 / var(--t=
w-text-opacity)); }

.text-black { --tw-text-opacity: 1; color: rgb(0 0 0 / var(--tw-text-opacit=
y)); }

.text-black\/70 { color: rgba(0, 0, 0, 0.7); }

.text-blue-400 { --tw-text-opacity: 1; color: rgb(99 179 237 / var(--tw-tex=
t-opacity)); }

.text-blue-500 { --tw-text-opacity: 1; color: rgb(65 153 225 / var(--tw-tex=
t-opacity)); }

.text-blue-500\/90 { color: rgba(65, 153, 225, 0.9); }

.text-blue-600 { --tw-text-opacity: 1; color: rgb(49 130 206 / var(--tw-tex=
t-opacity)); }

.text-blue-800 { --tw-text-opacity: 1; color: rgb(44 82 130 / var(--tw-text=
-opacity)); }

.text-darkBlue-600 { --tw-text-opacity: 1; color: rgb(37 99 235 / var(--tw-=
text-opacity)); }

.text-gray-200 { --tw-text-opacity: 1; color: rgb(226 232 240 / var(--tw-te=
xt-opacity)); }

.text-gray-300 { --tw-text-opacity: 1; color: rgb(203 213 225 / var(--tw-te=
xt-opacity)); }

.text-gray-400 { --tw-text-opacity: 1; color: rgb(148 163 184 / var(--tw-te=
xt-opacity)); }

.text-gray-500 { --tw-text-opacity: 1; color: rgb(100 116 139 / var(--tw-te=
xt-opacity)); }

.text-gray-600 { --tw-text-opacity: 1; color: rgb(71 85 105 / var(--tw-text=
-opacity)); }

.text-gray-700 { --tw-text-opacity: 1; color: rgb(51 65 85 / var(--tw-text-=
opacity)); }

.text-gray-800 { --tw-text-opacity: 1; color: rgb(30 41 59 / var(--tw-text-=
opacity)); }

.text-gray-900 { --tw-text-opacity: 1; color: rgb(15 23 42 / var(--tw-text-=
opacity)); }

.text-green-400 { --tw-text-opacity: 1; color: rgb(74 222 128 / var(--tw-te=
xt-opacity)); }

.text-green-500 { --tw-text-opacity: 1; color: rgb(34 197 94 / var(--tw-tex=
t-opacity)); }

.text-green-600 { --tw-text-opacity: 1; color: rgb(22 163 74 / var(--tw-tex=
t-opacity)); }

.text-orange-500 { --tw-text-opacity: 1; color: rgb(249 115 22 / var(--tw-t=
ext-opacity)); }

.text-red-100 { --tw-text-opacity: 1; color: rgb(254 226 226 / var(--tw-tex=
t-opacity)); }

.text-red-300 { --tw-text-opacity: 1; color: rgb(252 165 165 / var(--tw-tex=
t-opacity)); }

.text-red-400 { --tw-text-opacity: 1; color: rgb(248 113 113 / var(--tw-tex=
t-opacity)); }

.text-red-500 { --tw-text-opacity: 1; color: rgb(239 68 68 / var(--tw-text-=
opacity)); }

.text-red-600 { --tw-text-opacity: 1; color: rgb(220 38 38 / var(--tw-text-=
opacity)); }

.text-red-700 { --tw-text-opacity: 1; color: rgb(185 28 28 / var(--tw-text-=
opacity)); }

.text-red-900 { --tw-text-opacity: 1; color: rgb(127 29 29 / var(--tw-text-=
opacity)); }

.text-slate-100 { --tw-text-opacity: 1; color: rgb(241 245 249 / var(--tw-t=
ext-opacity)); }

.text-slate-100\/50 { color: rgba(241, 245, 249, 0.5); }

.text-slate-200 { --tw-text-opacity: 1; color: rgb(226 232 240 / var(--tw-t=
ext-opacity)); }

.text-slate-300 { --tw-text-opacity: 1; color: rgb(203 213 225 / var(--tw-t=
ext-opacity)); }

.text-slate-400 { --tw-text-opacity: 1; color: rgb(148 163 184 / var(--tw-t=
ext-opacity)); }

.text-slate-500 { --tw-text-opacity: 1; color: rgb(100 116 139 / var(--tw-t=
ext-opacity)); }

.text-slate-500\/50 { color: rgba(100, 116, 139, 0.5); }

.text-slate-700 { --tw-text-opacity: 1; color: rgb(51 65 85 / var(--tw-text=
-opacity)); }

.text-slate-900 { --tw-text-opacity: 1; color: rgb(15 23 42 / var(--tw-text=
-opacity)); }

.text-slate-900\/\[0\.07\] { color: rgba(15, 23, 42, 0.07); }

.text-slate-900\/\[0\.1\] { color: rgba(15, 23, 42, 0.1); }

.text-white { --tw-text-opacity: 1; color: rgb(255 255 255 / var(--tw-text-=
opacity)); }

.text-white\/50 { color: rgba(255, 255, 255, 0.5); }

.text-white\/70 { color: rgba(255, 255, 255, 0.7); }

.text-white\/80 { color: rgba(255, 255, 255, 0.8); }

.text-yellow-400 { --tw-text-opacity: 1; color: rgb(250 204 21 / var(--tw-t=
ext-opacity)); }

.text-yellow-500 { --tw-text-opacity: 1; color: rgb(234 179 8 / var(--tw-te=
xt-opacity)); }

.underline { text-decoration-line: underline; }

.underline-offset-2 { text-underline-offset: 2px; }

.placeholder-gray-300::-webkit-input-placeholder { --tw-placeholder-opacity=
: 1; color: rgb(203 213 225 / var(--tw-placeholder-opacity)); }

.placeholder-gray-300::placeholder { --tw-placeholder-opacity: 1; color: rg=
b(203 213 225 / var(--tw-placeholder-opacity)); }

.placeholder-red-300::-webkit-input-placeholder { --tw-placeholder-opacity:=
 1; color: rgb(252 165 165 / var(--tw-placeholder-opacity)); }

.placeholder-red-300::placeholder { --tw-placeholder-opacity: 1; color: rgb=
(252 165 165 / var(--tw-placeholder-opacity)); }

.opacity-0 { opacity: 0; }

.opacity-10 { opacity: 0.1; }

.opacity-100 { opacity: 1; }

.opacity-25 { opacity: 0.25; }

.opacity-50 { opacity: 0.5; }

.opacity-75 { opacity: 0.75; }

.opacity-90 { opacity: 0.9; }

.bg-blend-darken { background-blend-mode: darken; }

.mix-blend-overlay { mix-blend-mode: overlay; }

.\!shadow-sm { --tw-shadow: 0 1px 2px 0 rgb(0 0 0 / .05) !important; --tw-s=
hadow-colored: 0 1px 2px 0 var(--tw-shadow-color) !important; box-shadow: v=
ar(--tw-ring-offset-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var=
(--tw-shadow) !important; }

.shadow { --tw-shadow: 0 1px 3px 0 rgb(0 0 0 / .1), 0 1px 2px -1px rgb(0 0 =
0 / .1); --tw-shadow-colored: 0 1px 3px 0 var(--tw-shadow-color), 0 1px 2px=
 -1px var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-shadow, 0 0 =
#0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shadow); }

.shadow-2xl { --tw-shadow: 0 25px 50px -12px rgb(0 0 0 / .25); --tw-shadow-=
colored: 0 25px 50px -12px var(--tw-shadow-color); box-shadow: var(--tw-rin=
g-offset-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shado=
w); }

.shadow-lg { --tw-shadow: 0 10px 15px -3px rgb(0 0 0 / .1), 0 4px 6px -4px =
rgb(0 0 0 / .1); --tw-shadow-colored: 0 10px 15px -3px var(--tw-shadow-colo=
r), 0 4px 6px -4px var(--tw-shadow-color); box-shadow: var(--tw-ring-offset=
-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shadow); }

.shadow-md { --tw-shadow: 0 4px 6px -1px rgb(0 0 0 / .1), 0 2px 4px -2px rg=
b(0 0 0 / .1); --tw-shadow-colored: 0 4px 6px -1px var(--tw-shadow-color), =
0 2px 4px -2px var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-sha=
dow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shadow); }

.shadow-sm { --tw-shadow: 0 1px 2px 0 rgb(0 0 0 / .05); --tw-shadow-colored=
: 0 1px 2px 0 var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-shad=
ow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shadow); }

.shadow-xl { --tw-shadow: 0 20px 25px -5px rgb(0 0 0 / .1), 0 8px 10px -6px=
 rgb(0 0 0 / .1); --tw-shadow-colored: 0 20px 25px -5px var(--tw-shadow-col=
or), 0 8px 10px -6px var(--tw-shadow-color); box-shadow: var(--tw-ring-offs=
et-shadow, 0 0 #0000),var(--tw-ring-shadow, 0 0 #0000),var(--tw-shadow); }

.shadow-darkBlue-900\/50 { --tw-shadow-color: rgb(8 11 22 / .5); --tw-shado=
w: var(--tw-shadow-colored); }

.\!outline-none { outline: transparent solid 2px !important; outline-offset=
: 2px !important; }

.outline-slate-200\/40 { outline-color: rgba(226, 232, 240, 0.4); }

.ring { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-o=
ffset-width) var(--tw-ring-offset-color); --tw-ring-shadow: var(--tw-ring-i=
nset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color); b=
ox-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shad=
ow, 0 0 #0000); }

.ring-1 { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring=
-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow: var(--tw-ring=
-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color);=
 box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-sh=
adow, 0 0 #0000); }

.ring-2 { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring=
-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow: var(--tw-ring=
-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color);=
 box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-sh=
adow, 0 0 #0000); }

.ring-inset { --tw-ring-inset: inset; }

.ring-black { --tw-ring-opacity: 1; --tw-ring-color: rgb(0 0 0 / var(--tw-r=
ing-opacity)); }

.ring-black\/20 { --tw-ring-color: rgb(0 0 0 / .2); }

.ring-blue-500 { --tw-ring-opacity: 1; --tw-ring-color: rgb(65 153 225 / va=
r(--tw-ring-opacity)); }

.ring-blue-600 { --tw-ring-opacity: 1; --tw-ring-color: rgb(49 130 206 / va=
r(--tw-ring-opacity)); }

.ring-slate-800 { --tw-ring-opacity: 1; --tw-ring-color: rgb(30 41 59 / var=
(--tw-ring-opacity)); }

.ring-slate-900\/10 { --tw-ring-color: rgb(15 23 42 / .1); }

.ring-transparent { --tw-ring-color: transparent; }

.ring-opacity-5 { --tw-ring-opacity: .05; }

.grayscale-\[0\.75\] { --tw-grayscale: grayscale(.75); filter: var(--tw-blu=
r) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue=
-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-=
shadow); }

.filter { filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) va=
r(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) =
var(--tw-sepia) var(--tw-drop-shadow); }

.backdrop-blur { --tw-backdrop-blur: blur(8px); backdrop-filter: var(--tw-b=
ackdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var=
(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-i=
nvert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-back=
drop-sepia); }

.backdrop-blur-sm { --tw-backdrop-blur: blur(4px); backdrop-filter: var(--t=
w-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) =
var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdro=
p-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-b=
ackdrop-sepia); }

.backdrop-blur-xl { --tw-backdrop-blur: blur(24px); backdrop-filter: var(--=
tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast)=
 var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdr=
op-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-=
backdrop-sepia); }

.transition { transition-property: color, background-color, border-color, t=
ext-decoration-color, fill, stroke, opacity, box-shadow, transform, filter,=
 backdrop-filter, -webkit-text-decoration-color, -webkit-box-shadow, -webki=
t-transform, -webkit-filter, -webkit-backdrop-filter; transition-timing-fun=
ction: cubic-bezier(0, 0, 0.2, 1); transition-duration: 0.15s; }

.transition-\[border\] { transition-property: border; transition-timing-fun=
ction: cubic-bezier(0, 0, 0.2, 1); transition-duration: 0.15s; }

.transition-all { transition-property: all; transition-timing-function: cub=
ic-bezier(0, 0, 0.2, 1); transition-duration: 0.15s; }

.transition-colors { transition-property: color, background-color, border-c=
olor, text-decoration-color, fill, stroke, -webkit-text-decoration-color; t=
ransition-timing-function: cubic-bezier(0, 0, 0.2, 1); transition-duration:=
 0.15s; }

.transition-opacity { transition-property: opacity; transition-timing-funct=
ion: cubic-bezier(0, 0, 0.2, 1); transition-duration: 0.15s; }

.duration-100 { transition-duration: 0.1s; }

.duration-150 { transition-duration: 0.15s; }

.duration-200 { transition-duration: 0.2s; }

.duration-300 { transition-duration: 0.3s; }

.duration-75 { transition-duration: 75ms; }

.ease-in { transition-timing-function: cubic-bezier(0.4, 0, 1, 1); }

.ease-in-out { transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.ease-out { transition-timing-function: cubic-bezier(0, 0, 0.2, 1); }

.\[mask-image\:linear-gradient\(to_bottom_left\,white\,transparent\,transpa=
rent\)\] { mask-image: linear-gradient(to left bottom, white, transparent, =
transparent); }

@media (max-width: 640px) {
  .h-screen { height: calc(var(--vh, 1vh) * 100); }
  .min-h-screen { min-height: calc(var(--vh, 1vh) * 100); }
}

:is(.dark .dark\:prose-invert) { --tw-prose-body: var(--tw-prose-invert-bod=
y); --tw-prose-headings: var(--tw-prose-invert-headings); --tw-prose-lead: =
var(--tw-prose-invert-lead); --tw-prose-links: var(--tw-prose-invert-links)=
; --tw-prose-bold: var(--tw-prose-invert-bold); --tw-prose-counters: var(--=
tw-prose-invert-counters); --tw-prose-bullets: var(--tw-prose-invert-bullet=
s); --tw-prose-hr: var(--tw-prose-invert-hr); --tw-prose-quotes: var(--tw-p=
rose-invert-quotes); --tw-prose-quote-borders: var(--tw-prose-invert-quote-=
borders); --tw-prose-captions: var(--tw-prose-invert-captions); --tw-prose-=
kbd: var(--tw-prose-invert-kbd); --tw-prose-kbd-shadows: var(--tw-prose-inv=
ert-kbd-shadows); --tw-prose-code: var(--tw-prose-invert-code); --tw-prose-=
pre-code: var(--tw-prose-invert-pre-code); --tw-prose-pre-bg: var(--tw-pros=
e-invert-pre-bg); --tw-prose-th-borders: var(--tw-prose-invert-th-borders);=
 --tw-prose-td-borders: var(--tw-prose-invert-td-borders); }

.placeholder\:text-slate-500::-webkit-input-placeholder { --tw-text-opacity=
: 1; color: rgb(100 116 139 / var(--tw-text-opacity)); }

.placeholder\:text-slate-500::placeholder { --tw-text-opacity: 1; color: rg=
b(100 116 139 / var(--tw-text-opacity)); }

.focus-within\:border-blue-500:focus-within { --tw-border-opacity: 1; borde=
r-color: rgb(65 153 225 / var(--tw-border-opacity)); }

.focus-within\:border-blue-500\/50:focus-within { border-color: rgba(65, 15=
3, 225, 0.5); }

.focus-within\:ring-blue-500:focus-within { --tw-ring-opacity: 1; --tw-ring=
-color: rgb(65 153 225 / var(--tw-ring-opacity)); }

.hover\:scale-105:hover { --tw-scale-x: 1.05; --tw-scale-y: 1.05; transform=
: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-ro=
tate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale=
-x)) scaleY(var(--tw-scale-y)); }

.hover\:border-blue-500:hover { --tw-border-opacity: 1; border-color: rgb(6=
5 153 225 / var(--tw-border-opacity)); }

.hover\:border-gray-600:hover { --tw-border-opacity: 1; border-color: rgb(7=
1 85 105 / var(--tw-border-opacity)); }

.hover\:border-red-500:hover { --tw-border-opacity: 1; border-color: rgb(23=
9 68 68 / var(--tw-border-opacity)); }

.hover\:border-slate-400\/30:hover { border-color: rgba(148, 163, 184, 0.3)=
; }

.hover\:border-slate-600:hover { --tw-border-opacity: 1; border-color: rgb(=
71 85 105 / var(--tw-border-opacity)); }

.hover\:\!bg-blue-900:hover { --tw-bg-opacity: 1 !important; background-col=
or: rgb(42 67 101 / var(--tw-bg-opacity)) !important; }

.hover\:\!bg-slate-700:hover { --tw-bg-opacity: 1 !important; background-co=
lor: rgb(51 65 85 / var(--tw-bg-opacity)) !important; }

.hover\:bg-\[\#172B51\]\/50:hover { background-color: rgba(23, 43, 81, 0.5)=
; }

.hover\:bg-black\/5:hover { background-color: rgba(0, 0, 0, 0.05); }

.hover\:bg-blue-500:hover { --tw-bg-opacity: 1; background-color: rgb(65 15=
3 225 / var(--tw-bg-opacity)); }

.hover\:bg-blue-500\/10:hover { background-color: rgba(65, 153, 225, 0.1); =
}

.hover\:bg-blue-500\/20:hover { background-color: rgba(65, 153, 225, 0.2); =
}

.hover\:bg-blue-800:hover { --tw-bg-opacity: 1; background-color: rgb(44 82=
 130 / var(--tw-bg-opacity)); }

.hover\:bg-blue-900:hover { --tw-bg-opacity: 1; background-color: rgb(42 67=
 101 / var(--tw-bg-opacity)); }

.hover\:bg-darkBlue-500:hover { --tw-bg-opacity: 1; background-color: rgb(2=
6 30 45 / var(--tw-bg-opacity)); }

.hover\:bg-darkBlue-500\/70:hover { background-color: rgba(26, 30, 45, 0.7)=
; }

.hover\:bg-gray-100:hover { --tw-bg-opacity: 1; background-color: rgb(241 2=
45 249 / var(--tw-bg-opacity)); }

.hover\:bg-gray-50:hover { --tw-bg-opacity: 1; background-color: rgb(248 25=
0 252 / var(--tw-bg-opacity)); }

.hover\:bg-orange-100:hover { --tw-bg-opacity: 1; background-color: rgb(255=
 237 213 / var(--tw-bg-opacity)); }

.hover\:bg-red-400:hover { --tw-bg-opacity: 1; background-color: rgb(248 11=
3 113 / var(--tw-bg-opacity)); }

.hover\:bg-red-500:hover { --tw-bg-opacity: 1; background-color: rgb(239 68=
 68 / var(--tw-bg-opacity)); }

.hover\:bg-red-500\/20:hover { background-color: rgba(239, 68, 68, 0.2); }

.hover\:bg-red-800:hover { --tw-bg-opacity: 1; background-color: rgb(153 27=
 27 / var(--tw-bg-opacity)); }

.hover\:bg-slate-100:hover { --tw-bg-opacity: 1; background-color: rgb(241 =
245 249 / var(--tw-bg-opacity)); }

.hover\:bg-slate-100\/10:hover { background-color: rgba(241, 245, 249, 0.1)=
; }

.hover\:bg-slate-500:hover { --tw-bg-opacity: 1; background-color: rgb(100 =
116 139 / var(--tw-bg-opacity)); }

.hover\:bg-slate-500\/10:hover { background-color: rgba(100, 116, 139, 0.1)=
; }

.hover\:bg-slate-500\/50:hover { background-color: rgba(100, 116, 139, 0.5)=
; }

.hover\:bg-slate-800\/50:hover { background-color: rgba(30, 41, 59, 0.5); }

.hover\:bg-uiBlue-500:hover { --tw-bg-opacity: 1; background-color: rgb(52 =
57 106 / var(--tw-bg-opacity)); }

.hover\:bg-uiBlue-500\/70:hover { background-color: rgba(52, 57, 106, 0.7);=
 }

.hover\:bg-uiBlue-600\/10:hover { background-color: rgba(76, 82, 134, 0.1);=
 }

.hover\:bg-uiBlue-600\/80:hover { background-color: rgba(76, 82, 134, 0.8);=
 }

.hover\:bg-white\/5:hover { background-color: rgba(255, 255, 255, 0.05); }

.hover\:bg-white\/\[0\.08\]:hover { background-color: rgba(255, 255, 255, 0=
.08); }

.hover\:text-\[\#f9bb49\]:hover { --tw-text-opacity: 1; color: rgb(249 187 =
73 / var(--tw-text-opacity)); }

.hover\:text-black:hover { --tw-text-opacity: 1; color: rgb(0 0 0 / var(--t=
w-text-opacity)); }

.hover\:text-blue-500:hover { --tw-text-opacity: 1; color: rgb(65 153 225 /=
 var(--tw-text-opacity)); }

.hover\:text-gray-100:hover { --tw-text-opacity: 1; color: rgb(241 245 249 =
/ var(--tw-text-opacity)); }

.hover\:text-gray-500:hover { --tw-text-opacity: 1; color: rgb(100 116 139 =
/ var(--tw-text-opacity)); }

.hover\:text-orange-500:hover { --tw-text-opacity: 1; color: rgb(249 115 22=
 / var(--tw-text-opacity)); }

.hover\:text-purple-800:hover { --tw-text-opacity: 1; color: rgb(107 33 168=
 / var(--tw-text-opacity)); }

.hover\:text-red-100:hover { --tw-text-opacity: 1; color: rgb(254 226 226 /=
 var(--tw-text-opacity)); }

.hover\:text-red-500:hover { --tw-text-opacity: 1; color: rgb(239 68 68 / v=
ar(--tw-text-opacity)); }

.hover\:text-slate-100:hover { --tw-text-opacity: 1; color: rgb(241 245 249=
 / var(--tw-text-opacity)); }

.hover\:text-slate-300:hover { --tw-text-opacity: 1; color: rgb(203 213 225=
 / var(--tw-text-opacity)); }

.hover\:text-slate-500:hover { --tw-text-opacity: 1; color: rgb(100 116 139=
 / var(--tw-text-opacity)); }

.hover\:text-white:hover { --tw-text-opacity: 1; color: rgb(255 255 255 / v=
ar(--tw-text-opacity)); }

.hover\:underline:hover { text-decoration-line: underline; }

.hover\:opacity-100:hover { opacity: 1; }

.hover\:opacity-75:hover { opacity: 0.75; }

.hover\:opacity-80:hover { opacity: 0.8; }

.hover\:bg-blend-darken:hover { background-blend-mode: darken; }

.hover\:ring-blue-500:hover { --tw-ring-opacity: 1; --tw-ring-color: rgb(65=
 153 225 / var(--tw-ring-opacity)); }

.focus\:border-blue-300:focus { --tw-border-opacity: 1; border-color: rgb(1=
47 197 253 / var(--tw-border-opacity)); }

.focus\:border-blue-700:focus { --tw-border-opacity: 1; border-color: rgb(4=
3 108 176 / var(--tw-border-opacity)); }

.focus\:border-darkBlue-700:focus { --tw-border-opacity: 1; border-color: r=
gb(15 18 32 / var(--tw-border-opacity)); }

.focus\:border-red-300:focus { --tw-border-opacity: 1; border-color: rgb(25=
2 165 165 / var(--tw-border-opacity)); }

.focus\:border-slate-700:focus { --tw-border-opacity: 1; border-color: rgb(=
51 65 85 / var(--tw-border-opacity)); }

.focus\:border-uiBlue-600:focus { --tw-border-opacity: 1; border-color: rgb=
(76 82 134 / var(--tw-border-opacity)); }

.focus\:text-slate-300:focus { --tw-text-opacity: 1; color: rgb(203 213 225=
 / var(--tw-text-opacity)); }

.focus\:underline:focus { text-decoration-line: underline; }

.focus\:outline-none:focus { outline: transparent solid 2px; outline-offset=
: 2px; }

.focus\:ring-0:focus { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 =
var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow: =
var(--tw-ring-inset) 0 0 0 calc(0px + var(--tw-ring-offset-width)) var(--tw=
-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow=
),var(--tw-shadow, 0 0 #0000); }

.focus\:ring-1:focus { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 =
var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow: =
var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw=
-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow=
),var(--tw-shadow, 0 0 #0000); }

.focus\:ring-2:focus { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 =
var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow: =
var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw=
-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow=
),var(--tw-shadow, 0 0 #0000); }

.focus\:ring-blue-500:focus { --tw-ring-opacity: 1; --tw-ring-color: rgb(65=
 153 225 / var(--tw-ring-opacity)); }

.focus\:ring-slate-500:focus { --tw-ring-opacity: 1; --tw-ring-color: rgb(1=
00 116 139 / var(--tw-ring-opacity)); }

.focus\:ring-uiBlue-400:focus { --tw-ring-opacity: 1; --tw-ring-color: rgb(=
96 165 250 / var(--tw-ring-opacity)); }

.focus\:ring-uiBlue-500:focus { --tw-ring-opacity: 1; --tw-ring-color: rgb(=
52 57 106 / var(--tw-ring-opacity)); }

.active\:scale-125:active { --tw-scale-x: 1.25; --tw-scale-y: 1.25; transfo=
rm: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-=
rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-sca=
le-x)) scaleY(var(--tw-scale-y)); }

.active\:bg-\[\#090b16\]\/80:active { background-color: rgba(9, 11, 22, 0.8=
); }

.active\:bg-blue-700:active { --tw-bg-opacity: 1; background-color: rgb(43 =
108 176 / var(--tw-bg-opacity)); }

.active\:bg-darkBlue-700:active { --tw-bg-opacity: 1; background-color: rgb=
(15 18 32 / var(--tw-bg-opacity)); }

.active\:bg-gray-50:active { --tw-bg-opacity: 1; background-color: rgb(248 =
250 252 / var(--tw-bg-opacity)); }

.active\:bg-red-50:active { --tw-bg-opacity: 1; background-color: rgb(254 2=
42 242 / var(--tw-bg-opacity)); }

.active\:bg-red-800:active { --tw-bg-opacity: 1; background-color: rgb(153 =
27 27 / var(--tw-bg-opacity)); }

.active\:bg-red-900:active { --tw-bg-opacity: 1; background-color: rgb(127 =
29 29 / var(--tw-bg-opacity)); }

.active\:bg-slate-200:active { --tw-bg-opacity: 1; background-color: rgb(22=
6 232 240 / var(--tw-bg-opacity)); }

.active\:bg-slate-500\/20:active { background-color: rgba(100, 116, 139, 0.=
2); }

.active\:bg-slate-700:active { --tw-bg-opacity: 1; background-color: rgb(51=
 65 85 / var(--tw-bg-opacity)); }

.active\:bg-slate-800:active { --tw-bg-opacity: 1; background-color: rgb(30=
 41 59 / var(--tw-bg-opacity)); }

.active\:bg-slate-800\/50:active { background-color: rgba(30, 41, 59, 0.5);=
 }

.active\:bg-uiBlue-600:active { --tw-bg-opacity: 1; background-color: rgb(7=
6 82 134 / var(--tw-bg-opacity)); }

.active\:text-gray-800:active { --tw-text-opacity: 1; color: rgb(30 41 59 /=
 var(--tw-text-opacity)); }

.active\:text-red-800:active { --tw-text-opacity: 1; color: rgb(153 27 27 /=
 var(--tw-text-opacity)); }

.active\:text-white\/80:active { color: rgba(255, 255, 255, 0.8); }

.active\:outline-2:active { outline-width: 2px; }

.active\:ring-2:active { --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 =
0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow=
: var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--=
tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shad=
ow),var(--tw-shadow, 0 0 #0000); }

.active\:ring-red-500:active { --tw-ring-opacity: 1; --tw-ring-color: rgb(2=
39 68 68 / var(--tw-ring-opacity)); }

.active\:ring-uiBlue-400:active { --tw-ring-opacity: 1; --tw-ring-color: rg=
b(96 165 250 / var(--tw-ring-opacity)); }

.active\:ring-uiBlue-600:active { --tw-ring-opacity: 1; --tw-ring-color: rg=
b(76 82 134 / var(--tw-ring-opacity)); }

.active\:ring-offset-gray-100:active { --tw-ring-offset-color: #f1f5f9; }

.disabled\:pointer-events-none:disabled { pointer-events: none; }

.disabled\:cursor-not-allowed:disabled { cursor: not-allowed; }

.disabled\:opacity-60:disabled { opacity: 0.6; }

.group:focus-within .group-focus-within\:opacity-0 { opacity: 0; }

.group:hover .group-hover\:scale-110 { --tw-scale-x: 1.1; --tw-scale-y: 1.1=
; transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(=
var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var=
(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

@keyframes ping {=20
  75%, 100% { transform: scale(2); opacity: 0; }
}

.group:hover .group-hover\:animate-ping { animation: 1s cubic-bezier(0, 0, =
0.2, 1) 0s infinite normal none running ping; }

.group:hover .group-hover\:border-slate-300 { --tw-border-opacity: 1; borde=
r-color: rgb(203 213 225 / var(--tw-border-opacity)); }

.group:hover .group-hover\:border-slate-700 { --tw-border-opacity: 1; borde=
r-color: rgb(51 65 85 / var(--tw-border-opacity)); }

.group:hover .group-hover\:bg-\[\#172B51\]\/50 { background-color: rgba(23,=
 43, 81, 0.5); }

.group:hover .group-hover\:text-\[\#7289da\] { --tw-text-opacity: 1; color:=
 rgb(114 137 218 / var(--tw-text-opacity)); }

.group:hover .group-hover\:text-black { --tw-text-opacity: 1; color: rgb(0 =
0 0 / var(--tw-text-opacity)); }

.group:hover .group-hover\:text-blue-600 { --tw-text-opacity: 1; color: rgb=
(49 130 206 / var(--tw-text-opacity)); }

.group:hover .group-hover\:text-white { --tw-text-opacity: 1; color: rgb(25=
5 255 255 / var(--tw-text-opacity)); }

.group:hover .group-hover\:opacity-100 { opacity: 1; }

.group:hover .group-hover\:opacity-75 { opacity: 0.75; }

.peer:hover ~ .peer-hover\:bg-blue-900 { --tw-bg-opacity: 1; background-col=
or: rgb(42 67 101 / var(--tw-bg-opacity)); }

.ui-open\:bg-white\/10[data-headlessui-state~=3D"open"] { background-color:=
 rgba(255, 255, 255, 0.1); }

.ui-open\:text-white[data-headlessui-state~=3D"open"] { --tw-text-opacity: =
1; color: rgb(255 255 255 / var(--tw-text-opacity)); }

:where([data-headlessui-state~=3D"open"]) .ui-open\:bg-white\/10 { backgrou=
nd-color: rgba(255, 255, 255, 0.1); }

:where([data-headlessui-state~=3D"open"]) .ui-open\:text-white { --tw-text-=
opacity: 1; color: rgb(255 255 255 / var(--tw-text-opacity)); }

.ui-not-open\:hover\:bg-white\/\[0\.08\]:hover[data-headlessui-state]:not([=
data-headlessui-state~=3D"open"]) { background-color: rgba(255, 255, 255, 0=
.08); }

:where([data-headlessui-state]:not([data-headlessui-state~=3D"open"])) .ui-=
not-open\:hover\:bg-white\/\[0\.08\]:hover:not([data-headlessui-state]) { b=
ackground-color: rgba(255, 255, 255, 0.08); }

.ui-active\:bg-uiBlue-600\/80[data-headlessui-state~=3D"active"] { backgrou=
nd-color: rgba(76, 82, 134, 0.8); }

:where([data-headlessui-state~=3D"active"]) .ui-active\:bg-uiBlue-600\/80 {=
 background-color: rgba(76, 82, 134, 0.8); }

:is(.dark .dark\:border-darkBlue-400) { --tw-border-opacity: 1; border-colo=
r: rgb(96 165 250 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-gray-600) { --tw-border-opacity: 1; border-color: r=
gb(71 85 105 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-gray-700) { --tw-border-opacity: 1; border-color: r=
gb(51 65 85 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-gray-800) { --tw-border-opacity: 1; border-color: r=
gb(30 41 59 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-gray-900) { --tw-border-opacity: 1; border-color: r=
gb(15 23 42 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-green-500\/20) { border-color: rgba(34, 197, 94, 0.=
2); }

:is(.dark .dark\:border-green-600) { --tw-border-opacity: 1; border-color: =
rgb(22 163 74 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-orange-500\/20) { border-color: rgba(249, 115, 22, =
0.2); }

:is(.dark .dark\:border-red-300) { --tw-border-opacity: 1; border-color: rg=
b(252 165 165 / var(--tw-border-opacity)); }

:is(.dark .dark\:border-red-500\/20) { border-color: rgba(239, 68, 68, 0.2)=
; }

:is(.dark .dark\:border-slate-800) { --tw-border-opacity: 1; border-color: =
rgb(30 41 59 / var(--tw-border-opacity)); }

:is(.dark .dark\:bg-black) { --tw-bg-opacity: 1; background-color: rgb(0 0 =
0 / var(--tw-bg-opacity)); }

:is(.dark .dark\:bg-blue-900) { --tw-bg-opacity: 1; background-color: rgb(4=
2 67 101 / var(--tw-bg-opacity)); }

:is(.dark .dark\:bg-darkBlue-500\/50) { background-color: rgba(26, 30, 45, =
0.5); }

:is(.dark .dark\:bg-darkBlue-900\/50) { background-color: rgba(8, 11, 22, 0=
.5); }

:is(.dark .dark\:bg-gray-800) { --tw-bg-opacity: 1; background-color: rgb(3=
0 41 59 / var(--tw-bg-opacity)); }

:is(.dark .dark\:bg-gray-900) { --tw-bg-opacity: 1; background-color: rgb(1=
5 23 42 / var(--tw-bg-opacity)); }

:is(.dark .dark\:bg-green-500\/20) { background-color: rgba(34, 197, 94, 0.=
2); }

:is(.dark .dark\:bg-orange-500\/20) { background-color: rgba(249, 115, 22, =
0.2); }

:is(.dark .dark\:bg-red-500\/20) { background-color: rgba(239, 68, 68, 0.2)=
; }

:is(.dark .dark\:bg-slate-900) { --tw-bg-opacity: 1; background-color: rgb(=
15 23 42 / var(--tw-bg-opacity)); }

:is(.dark .dark\:from-yellow-700\/5) { --tw-gradient-from: rgb(161 98 7 / .=
05) var(--tw-gradient-from-position); --tw-gradient-to: rgb(161 98 7 / 0) v=
ar(--tw-gradient-to-position); --tw-gradient-stops: var(--tw-gradient-from)=
, var(--tw-gradient-to); }

:is(.dark .dark\:text-blue-100) { --tw-text-opacity: 1; color: rgb(235 248 =
255 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-blue-300) { --tw-text-opacity: 1; color: rgb(147 197 =
253 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-blue-400) { --tw-text-opacity: 1; color: rgb(99 179 2=
37 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-blue-500) { --tw-text-opacity: 1; color: rgb(65 153 2=
25 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-darkBlue-400) { --tw-text-opacity: 1; color: rgb(96 1=
65 250 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-gray-100) { --tw-text-opacity: 1; color: rgb(241 245 =
249 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-gray-200) { --tw-text-opacity: 1; color: rgb(226 232 =
240 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-gray-300) { --tw-text-opacity: 1; color: rgb(203 213 =
225 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-gray-400) { --tw-text-opacity: 1; color: rgb(148 163 =
184 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-gray-500) { --tw-text-opacity: 1; color: rgb(100 116 =
139 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-green-200) { --tw-text-opacity: 1; color: rgb(187 247=
 208 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-green-400) { --tw-text-opacity: 1; color: rgb(74 222 =
128 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-orange-400) { --tw-text-opacity: 1; color: rgb(251 14=
6 60 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-red-300) { --tw-text-opacity: 1; color: rgb(252 165 1=
65 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-red-400) { --tw-text-opacity: 1; color: rgb(248 113 1=
13 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-slate-100) { --tw-text-opacity: 1; color: rgb(241 245=
 249 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-slate-100\/10) { color: rgba(241, 245, 249, 0.1); }

:is(.dark .dark\:text-slate-100\/20) { color: rgba(241, 245, 249, 0.2); }

:is(.dark .dark\:text-slate-100\/\[0\.07\]) { color: rgba(241, 245, 249, 0.=
07); }

:is(.dark .dark\:text-slate-300) { --tw-text-opacity: 1; color: rgb(203 213=
 225 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-slate-400) { --tw-text-opacity: 1; color: rgb(148 163=
 184 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-slate-500) { --tw-text-opacity: 1; color: rgb(100 116=
 139 / var(--tw-text-opacity)); }

:is(.dark .dark\:text-white) { --tw-text-opacity: 1; color: rgb(255 255 255=
 / var(--tw-text-opacity)); }

:is(.dark .dark\:placeholder-red-900)::-webkit-input-placeholder { --tw-pla=
ceholder-opacity: 1; color: rgb(127 29 29 / var(--tw-placeholder-opacity));=
 }

:is(.dark .dark\:placeholder-red-900)::placeholder { --tw-placeholder-opaci=
ty: 1; color: rgb(127 29 29 / var(--tw-placeholder-opacity)); }

:is(.dark .dark\:ring-slate-100\/10) { --tw-ring-color: rgb(241 245 249 / .=
1); }

:is(.dark .dark\:ring-white\/20) { --tw-ring-color: rgb(255 255 255 / .2); =
}

:is(.dark .dark\:hover\:border-blue-500:hover) { --tw-border-opacity: 1; bo=
rder-color: rgb(65 153 225 / var(--tw-border-opacity)); }

:is(.dark .dark\:hover\:border-gray-500:hover) { --tw-border-opacity: 1; bo=
rder-color: rgb(100 116 139 / var(--tw-border-opacity)); }

:is(.dark .hover\:dark\:border-red-400):hover { --tw-border-opacity: 1; bor=
der-color: rgb(248 113 113 / var(--tw-border-opacity)); }

:is(.dark .dark\:hover\:bg-gray-700:hover) { --tw-bg-opacity: 1; background=
-color: rgb(51 65 85 / var(--tw-bg-opacity)); }

:is(.dark .dark\:hover\:bg-gray-800:hover) { --tw-bg-opacity: 1; background=
-color: rgb(30 41 59 / var(--tw-bg-opacity)); }

:is(.dark .dark\:hover\:bg-gray-900:hover) { --tw-bg-opacity: 1; background=
-color: rgb(15 23 42 / var(--tw-bg-opacity)); }

:is(.dark .dark\:hover\:bg-slate-700:hover) { --tw-bg-opacity: 1; backgroun=
d-color: rgb(51 65 85 / var(--tw-bg-opacity)); }

:is(.dark .hover\:dark\:bg-blue-500\/5):hover { background-color: rgba(65, =
153, 225, 0.05); }

:is(.dark .dark\:hover\:text-blue-500:hover) { --tw-text-opacity: 1; color:=
 rgb(65 153 225 / var(--tw-text-opacity)); }

:is(.dark .dark\:hover\:text-gray-200:hover) { --tw-text-opacity: 1; color:=
 rgb(226 232 240 / var(--tw-text-opacity)); }

:is(.dark .dark\:hover\:text-slate-300:hover) { --tw-text-opacity: 1; color=
: rgb(203 213 225 / var(--tw-text-opacity)); }

:is(.dark .dark\:hover\:text-white:hover) { --tw-text-opacity: 1; color: rg=
b(255 255 255 / var(--tw-text-opacity)); }

:is(.dark .dark\:focus\:ring-uiBlue-600:focus) { --tw-ring-opacity: 1; --tw=
-ring-color: rgb(76 82 134 / var(--tw-ring-opacity)); }

:is(.dark .dark\:active\:bg-slate-800:active) { --tw-bg-opacity: 1; backgro=
und-color: rgb(30 41 59 / var(--tw-bg-opacity)); }

:is(.dark .dark\:active\:ring-uiBlue-600:active) { --tw-ring-opacity: 1; --=
tw-ring-color: rgb(76 82 134 / var(--tw-ring-opacity)); }

:is(.dark .group:hover .dark\:group-hover\:border-slate-700) { --tw-border-=
opacity: 1; border-color: rgb(51 65 85 / var(--tw-border-opacity)); }

:is(.dark .group:hover .dark\:group-hover\:text-blue-300) { --tw-text-opaci=
ty: 1; color: rgb(147 197 253 / var(--tw-text-opacity)); }

:is(.dark .group:hover .dark\:group-hover\:text-white) { --tw-text-opacity:=
 1; color: rgb(255 255 255 / var(--tw-text-opacity)); }

:is(.dark .ui-not-open\:dark\:hover\:text-white\/80:hover)[data-headlessui-=
state]:not([data-headlessui-state~=3D"open"]) { color: rgba(255, 255, 255, =
0.8); }

:where([data-headlessui-state]:not([data-headlessui-state~=3D"open"])) :is(=
.dark .ui-not-open\:dark\:hover\:text-white\/80:hover):not([data-headlessui=
-state]) { color: rgba(255, 255, 255, 0.8); }

@media not all and (min-width: 640px) {
  .max-sm\:max-h-11 { max-height: 2.75rem; }
  .max-sm\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
}

@media (min-width: 480px) {
  .xs\:flex-row { -webkit-box-orient: horizontal; -webkit-box-direction: no=
rmal; flex-direction: row; }
  .xs\:flex-nowrap { flex-wrap: nowrap; }
}

@media (min-width: 640px) {
  .sm\:sticky { position: sticky; }
  .sm\:-mx-8 { margin-left: -2rem; margin-right: -2rem; }
  .sm\:my-12 { margin-top: 3rem; margin-bottom: 3rem; }
  .sm\:my-8 { margin-top: 2rem; margin-bottom: 2rem; }
  .sm\:mb-16 { margin-bottom: 4rem; }
  .sm\:mt-4 { margin-top: 1rem; }
  .sm\:block { display: block; }
  .sm\:inline-block { display: inline-block; }
  .sm\:flex { display: flex; }
  .sm\:grid { display: grid; }
  .sm\:hidden { display: none; }
  .sm\:h-64 { height: 16rem; }
  .sm\:h-screen { height: 100vh; }
  .sm\:w-\[68px\] { width: 68px; }
  .sm\:w-auto { width: auto; }
  .sm\:max-w-lg { max-width: 32rem; }
  .sm\:max-w-md { max-width: 28rem; }
  .sm\:grow-0 { -webkit-box-flex: 0; flex-grow: 0; }
  .sm\:translate-x-0 { --tw-translate-x: 0px; transform: translate(var(--tw=
-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw=
-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw=
-scale-y)); }
  .sm\:translate-x-2 { --tw-translate-x: .5rem; transform: translate(var(--=
tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--=
tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--=
tw-scale-y)); }
  .sm\:translate-y-0 { --tw-translate-y: 0px; transform: translate(var(--tw=
-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw=
-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw=
-scale-y)); }
  .sm\:scale-100 { --tw-scale-x: 1; --tw-scale-y: 1; transform: translate(v=
ar(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(v=
ar(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(v=
ar(--tw-scale-y)); }
  .sm\:scale-95 { --tw-scale-x: .95; --tw-scale-y: .95; transform: translat=
e(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) ske=
w(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scale=
Y(var(--tw-scale-y)); }
  .sm\:flex-row { -webkit-box-orient: horizontal; -webkit-box-direction: no=
rmal; flex-direction: row; }
  .sm\:items-start { -webkit-box-align: start; align-items: flex-start; }
  .sm\:justify-start { -webkit-box-pack: start; justify-content: flex-start=
; }
  .sm\:justify-end { -webkit-box-pack: end; justify-content: flex-end; }
  .sm\:gap-12 { gap: 3rem; }
  .sm\:overflow-hidden { overflow: hidden; }
  .sm\:overflow-visible { overflow: visible; }
  .sm\:rounded-lg { border-radius: 0.5rem; }
  .sm\:rounded-md { border-radius: 0.375rem; }
  .sm\:rounded-xl { border-radius: 0.75rem; }
  .sm\:bg-opacity-50 { --tw-bg-opacity: .5; }
  .sm\:p-0 { padding: 0px; }
  .sm\:p-6 { padding: 1.5rem; }
  .sm\:p-8 { padding: 2rem; }
  .sm\:px-0 { padding-left: 0px; padding-right: 0px; }
  .sm\:px-10 { padding-left: 2.5rem; padding-right: 2.5rem; }
  .sm\:px-3 { padding-left: 0.75rem; padding-right: 0.75rem; }
  .sm\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .sm\:px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }
  .sm\:py-12 { padding-top: 3rem; padding-bottom: 3rem; }
  .sm\:py-16 { padding-top: 4rem; padding-bottom: 4rem; }
  .sm\:pb-6 { padding-bottom: 1.5rem; }
  .sm\:pt-2 { padding-top: 0.5rem; }
  .sm\:pt-4 { padding-top: 1rem; }
  .sm\:align-middle { vertical-align: middle; }
  .sm\:text-base { font-size: 1rem; line-height: 1.5rem; }
  .sm\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
  .sm\:text-xs { font-size: 0.75rem; line-height: 1rem; }
  .sm\:leading-5 { line-height: 1.25rem; }
  .sm\:leading-6 { line-height: 1.5rem; }
  .sm\:opacity-0 { opacity: 0; }
}

@media (min-width: 768px) {
  .md\:col-span-1 { grid-column: span 1 / span 1; }
  .md\:col-span-2 { grid-column: span 2 / span 2; }
  .md\:-mx-10 { margin-left: -2.5rem; margin-right: -2.5rem; }
  .md\:mb-0 { margin-bottom: 0px; }
  .md\:ml-16 { margin-left: 4rem; }
  .md\:mt-0 { margin-top: 0px; }
  .md\:grid { display: grid; }
  .md\:h-\[310px\] { height: 310px; }
  .md\:w-48 { width: 12rem; }
  .md\:w-56 { width: 14rem; }
  .md\:w-full { width: 100%; }
  .md\:max-w-md { max-width: 28rem; }
  .md\:grid-cols-3 { grid-template-columns: repeat(3, minmax(0px, 1fr)); }
  .md\:gap-24 { gap: 6rem; }
  .md\:gap-6 { gap: 1.5rem; }
  .md\:rounded-2xl { border-radius: 1rem; }
  .md\:rounded-full { border-radius: 9999px; }
  .md\:border-2 { border-width: 2px; }
  .md\:bg-darkBlue-900 { --tw-bg-opacity: 1; background-color: rgb(8 11 22 =
/ var(--tw-bg-opacity)); }
  .md\:p-1 { padding: 0.25rem; }
  .md\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .md\:px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }
  .md\:pb-20 { padding-bottom: 5rem; }
}

@media (min-width: 1024px) {
  .lg\:col-span-2 { grid-column: span 2 / span 2; }
  .lg\:my-16 { margin-top: 4rem; margin-bottom: 4rem; }
  .lg\:mt-0 { margin-top: 0px; }
  .lg\:flex { display: flex; }
  .lg\:grid { display: grid; }
  .lg\:w-1\/3 { width: 33.3333%; }
  .lg\:w-2\/3 { width: 66.6667%; }
  .lg\:w-\[480px\] { width: 480px; }
  .lg\:w-\[50vw\] { width: 50vw; }
  .lg\:min-w-\[700px\] { min-width: 700px; }
  .lg\:grid-cols-2 { grid-template-columns: repeat(2, minmax(0px, 1fr)); }
  .lg\:grid-cols-3 { grid-template-columns: repeat(3, minmax(0px, 1fr)); }
  .lg\:gap-8 { gap: 2rem; }
  .lg\:px-8 { padding-left: 2rem; padding-right: 2rem; }
  .lg\:py-24 { padding-top: 6rem; padding-bottom: 6rem; }
  .lg\:text-2xl { font-size: 1.5rem; line-height: 2rem; }
  .lg\:text-base { font-size: 1rem; line-height: 1.5rem; }
}

.\[\&\+\*\]\:mt-8 + * { margin-top: 2rem; }
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: image/png
Content-Transfer-Encoding: base64
Content-Location: https://lh3.googleusercontent.com/a/ACg8ocIyQ8gfzbWOmP23j5oBHampaJLnJs0EXI5gw38V-G9E0cdWXQ=s96-c

iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAAAAA3NCSVQICAjb4U/gAAAABmJLR0QA
UQAtAKgUqKNtAAAFE0lEQVR4nO2cXUxTVxzAz+29bS0C1SIfArbyVT4tyNxkTKKbE4OLRDNkWTLJ
Hra4t/mw5z0v2ZI9LVmWBRO3xC1hnUxHFiTi0CEzGAYdo/JVkQqUWFCkFLDQPbScey0f/0LLPU3z
/4WH87/lnP755Zz/Pb2ngTt74CeCrI+CdQKRDgoCQEEAKAgABQGgIAAUBICCAFAQAAoCQEEAKAgA
BQGgIAAUBICCAFAQAAoCQEEAKAgABQGgIAAUBICCAFAQAAoCQEEAKAgABQEI2zTuZ1+Vlx1Pl17x
esmlL7uargyEOPLn3x41HU4OuPjFxTudf46FOPKabNcMUvBcwA8vcG+c1Ic4rFanNpoSVg+uUHBh
SXs1si6xzPzdew1xoYxQ83FBTKwyXPkEg6yC1Br+zId5oYxQXJ4SrmSCRO4ibTqctOW+ZW+np4Y2
AbeA3IKS0mLfOpOxtb7Hz2ZuX61ZD7kFcRw5+o5ha31zixPCm0wwyCRodmaRtrOLErQ69WZH+OBT
U2y8ioYz0wvhyQxCJkEPup20rdkpnLtQuNkRSiv20rbnxbLNOh2ezCBkEtTbObngXqKhqSxwp7cx
JeUp+zK1NLRZn3q9YcttY2QSpFBwg71TNEw1xJVX7gu+e+W5LF4Qy/PdllFekCtzed5GtYNvaxoR
31XBbepeln8wkbadDvfVS1ZBGWWCVPyNhiGHfZZeMZqCvSXVXiiUFvXezklCiBB9M4gQ0tPhoFdi
41XnLxYH0/fQsVTaXlxYuv5jPyFEuuK2FZkEKZUKQoi5vm/e7aEXpTem9cgr2bPfuIuGNutTXy2L
tiUmKHlCiMPuGrCIpTo9I/7gEcDRqfdzpC7amx/5GtFWpJUq/xvduvaQ3qF5gausydq4Y36pWJ6f
TMxd+6Hf1xaibInRWdDaaJsYFUt1XsmeDXqdPm9MSNbQ0PL3JG1H2wySLpPuuxO0rdWpaz9Zd1f9
+glxr7Q4v/TbZSsNeT56Bf3y/X9ul1iqXzuWtmYXQ442M283DYf6pkcGntEw2u5i0hXhdLj7LeJH
M71Rm1+6xkI7XZfr2xz4uC3ZZ5LonkGEkNZGGy3VgqCoei9ndZeiQ+KjtcnHrj9+HpS+GnUziH/p
72n7fWR85DkNC15JDPj9EzVZSWk7aWi55wj4BdmenDE7F+tqF0u1LklTXZcrfbWiSjz/WHAvmeut
hBHMBDV81zs3+4KG0g/3Ccma7EIdDQd7p6TTTWaYCXo2tdDfI5bq/bm7DDn+Jz7vflSwI0Y80Wx7
uTzLDMuj5xbz8PKyv1ar1Hx1nf9EqFjyOM1hn73RMMQguRVYCmpvHh2TrJ2iV5MIIRWn9Cl68Wyn
uyOwPMsM4y8vdN0Zp+3E1JiTtdlvVmdwKzeo+TnPr/V9bDJbgbGgK9/865oRS/WRKr3xgPggbcDi
dNhdLPISYSxofs7zoOcJDQtKE2Pi/EfvXi+5dZ1lefbB/vtBLebh5SV/qeYku7+J0dnWRhubnCSw
F9TRYn/8cI1tzj9/ja++KD/sBRFC7rcFfvfJ7fKYWZdnHxEh6PLX3dKzaUJIv8XpdLhZ5SMlIgQR
QqxdYqn2esnNq8MMk5ESKYKaG4ZoqR4beX676RHbfCgc/ouujYmUGRSxoCAAFASAggBQEAAKAkBB
ACgIAAUBoCAAFASAggBQEAAKAkBBACgIAAUBoCAAFASAggBQEAAKAkBBACgIAAUBoCAAFASAggD+
BzRbOcnmvqKWAAAAAElFTkSuQmCC

------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: image/svg+xml
Content-Transfer-Encoding: quoted-printable
Content-Location: https://slickgpt.com/img/emoji/objects/pencil.svg

<svg xmlns=3D"http://www.w3.org/2000/svg" width=3D"64" height=3D"64"><path =
fill=3D"#F9C802" d=3D"M7.9 47.88l36.76-36.75 8.21 8.2L16.12 56.1z"/><radial=
Gradient id=3D"a" cx=3D"32.68" cy=3D"-31.93" r=3D"7.41" gradientTransform=
=3D"matrix(.9176 -.0824 -.0824 .9176 22.7 37.09)" gradientUnits=3D"userSpac=
eOnUse"><stop offset=3D"0" stop-color=3D"#ff709b"/><stop offset=3D".26" sto=
p-color=3D"#f96d97"/><stop offset=3D".61" stop-color=3D"#e8638b"/><stop off=
set=3D"1" stop-color=3D"#cc5478"/></radialGradient><path fill=3D"url(#a)" d=
=3D"M60.35 4.69l-1.04-1.04c-1.98-1.98-4.77-2.4-7.13-.03l-3.55 3.55 8.2 8.2 =
3.55-3.55c2.37-2.36 1.95-5.15-.03-7.13z"/><linearGradient id=3D"b" gradient=
Units=3D"userSpaceOnUse" x1=3D"82.51" y1=3D"31.43" x2=3D"74.44" y2=3D"23.14=
" gradientTransform=3D"translate(-28.02 -13.63)"><stop offset=3D"0" stop-co=
lor=3D"#6e787a"/><stop offset=3D".61" stop-color=3D"#d6dbde"/><stop offset=
=3D".69" stop-color=3D"#d2d8da"/><stop offset=3D".77" stop-color=3D"#c7cdd0=
"/><stop offset=3D".84" stop-color=3D"#b4bbbe"/><stop offset=3D".91" stop-c=
olor=3D"#9aa2a4"/><stop offset=3D".98" stop-color=3D"#788284"/><stop offset=
=3D"1" stop-color=3D"#6e787a"/></linearGradient><path fill=3D"url(#b)" d=3D=
"M56.83 15.37l-8.2-8.2-4.66 4.65 8.21 8.2z"/><linearGradient id=3D"c" gradi=
entUnits=3D"userSpaceOnUse" x1=3D"-160.43" y1=3D"224.21" x2=3D"-166.81" y2=
=3D"217.67" gradientTransform=3D"rotate(45 196.73 376.94)"><stop offset=3D"=
0" stop-color=3D"#6e787a"/><stop offset=3D".61" stop-color=3D"#d6dbde"/><st=
op offset=3D".69" stop-color=3D"#d2d8da"/><stop offset=3D".77" stop-color=
=3D"#c7cdd0"/><stop offset=3D".84" stop-color=3D"#b4bbbe"/><stop offset=3D"=
.91" stop-color=3D"#9aa2a4"/><stop offset=3D".98" stop-color=3D"#788284"/><=
stop offset=3D"1" stop-color=3D"#6e787a"/></linearGradient><path fill=3D"ur=
l(#c)" d=3D"M56.83 15.37l-8.2-8.2c-.36-.36-1.34.64-1 .99l8.21 8.2c.36.36 1.=
35-.63 1-.99z"/><linearGradient id=3D"d" gradientUnits=3D"userSpaceOnUse" x=
1=3D"-160.43" y1=3D"225.61" x2=3D"-166.81" y2=3D"219.07" gradientTransform=
=3D"rotate(45 196.73 376.94)"><stop offset=3D"0" stop-color=3D"#6e787a"/><s=
top offset=3D".61" stop-color=3D"#d6dbde"/><stop offset=3D".69" stop-color=
=3D"#d2d8da"/><stop offset=3D".77" stop-color=3D"#c7cdd0"/><stop offset=3D"=
.84" stop-color=3D"#b4bbbe"/><stop offset=3D".91" stop-color=3D"#9aa2a4"/><=
stop offset=3D".98" stop-color=3D"#788284"/><stop offset=3D"1" stop-color=
=3D"#6e787a"/></linearGradient><path fill=3D"url(#d)" d=3D"M55.84 16.36l-8.=
2-8.2c-.36-.36-1.34.63-1 .98l8.22 8.21c.35.35 1.34-.64.98-.99z"/><linearGra=
dient id=3D"e" gradientUnits=3D"userSpaceOnUse" x1=3D"-160.43" y1=3D"227.01=
" x2=3D"-166.81" y2=3D"220.46" gradientTransform=3D"rotate(45 196.73 376.94=
)"><stop offset=3D"0" stop-color=3D"#6e787a"/><stop offset=3D".61" stop-col=
or=3D"#d6dbde"/><stop offset=3D".69" stop-color=3D"#d2d8da"/><stop offset=
=3D".77" stop-color=3D"#c7cdd0"/><stop offset=3D".84" stop-color=3D"#b4bbbe=
"/><stop offset=3D".91" stop-color=3D"#9aa2a4"/><stop offset=3D".98" stop-c=
olor=3D"#788284"/><stop offset=3D"1" stop-color=3D"#6e787a"/></linearGradie=
nt><path fill=3D"url(#e)" d=3D"M54.85 17.35l-8.2-8.2c-.36-.36-1.35.63-1 .98=
l8.21 8.21c.36.35 1.35-.64 1-.99z"/><path fill=3D"#FFE463" d=3D"M43.97 11.8=
3l2.32 2.32L10.22 50.2 7.9 47.89z"/><path fill=3D"#EA8800" d=3D"M49.86 17.7=
1l2.33 2.33-36.07 36.04-2.33-2.33z"/><linearGradient id=3D"f" gradientUnits=
=3D"userSpaceOnUse" x1=3D"33.9" y1=3D"65.84" x2=3D"39.4" y2=3D"71.98" gradi=
entTransform=3D"translate(-28.02 -13.63)"><stop offset=3D"0" stop-color=3D"=
#fed0ac"/><stop offset=3D".25" stop-color=3D"#fccda8"/><stop offset=3D".5" =
stop-color=3D"#f5c39b"/><stop offset=3D".77" stop-color=3D"#ebb286"/><stop =
offset=3D"1" stop-color=3D"#de9e6d"/></linearGradient><path fill=3D"url(#f)=
" d=3D"M7.91 47.88l-4.8 10.56 2.44 2.46 10.57-4.81c.23-2.58-1.97-1.27-1.83-=
2.82.12-1.38-2.18-3.68-3.56-3.56-1.77.16-.22-2.06-2.82-1.83z"/><linearGradi=
ent id=3D"g" gradientUnits=3D"userSpaceOnUse" x1=3D"30.91" y1=3D"71.62" x2=
=3D"34.12" y2=3D"74.76" gradientTransform=3D"translate(-28.02 -13.63)"><sto=
p offset=3D"0" stop-color=3D"#4e5e67"/><stop offset=3D".37" stop-color=3D"#=
3f4450"/><stop offset=3D".74" stop-color=3D"#343241"/><stop offset=3D"1" st=
op-color=3D"#302c3b"/></linearGradient><path fill=3D"url(#g)" d=3D"M2.26 60=
.28c-.67 1.47 0 2.12 1.45 1.46l5.13-2.33-4.24-4.25-2.34 5.13z"/></svg>
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: image/svg+xml
Content-Transfer-Encoding: quoted-printable
Content-Location: https://slickgpt.com/img/slickgpt.svg

<svg xmlns=3D"http://www.w3.org/2000/svg" viewBox=3D"0 0 64 64">
  <path fill=3D"#50c18e" d=3D"M15 57c-2-10 6-22 16-24 5 9 3 33-9 31-3-1-6-3=
-7-7Z"/>
  <path fill=3D"#50c18e" d=3D"M1 42c0 9 14 9 13 0 1-9-13-9-13 0Z" opacity=
=3D".8"/>
  <path fill=3D"#f9bb49" d=3D"M7 15c10-2 22 6 24 16-9 5-33 3-31-9 1-3 3-6 7=
-7Z"/>
  <path fill=3D"#f9bb49" d=3D"M22 1c-9 0-9 14 0 13 9 1 9-13 0-13Z" opacity=
=3D".8"/>
  <path fill=3D"#e92e42" d=3D"M49 7c2 10-6 22-16 24-5-9-3-33 9-31 3 1 6 3 7=
 7Z"/>
  <path fill=3D"#e92e42" d=3D"M63 22c0-9-14-9-13 0-1 9 13 9 13 0Z" opacity=
=3D".8"/>
  <path fill=3D"#58caf7" d=3D"M57 49c-10 2-22-6-24-16 9-5 33-3 31 9-1 3-3 6=
-7 7Z"/>
  <path fill=3D"#58caf7" d=3D"M42 63c9 0 9-14 0-13-9-1-9 13 0 13Z" opacity=
=3D".8"/>
</svg>
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH----
Content-Type: image/svg+xml
Content-Transfer-Encoding: quoted-printable
Content-Location: https://slickgpt.com/img/emoji/symbols/repeat-button.svg

<svg xmlns=3D"http://www.w3.org/2000/svg" width=3D"64" height=3D"64"><linea=
rGradient id=3D"a" gradientUnits=3D"userSpaceOnUse" x1=3D"32" y1=3D"2" x2=
=3D"32" y2=3D"62"><stop offset=3D"0" stop-color=3D"#00abf1"/><stop offset=
=3D".23" stop-color=3D"#00a7ef"/><stop offset=3D".47" stop-color=3D"#009ae9=
"/><stop offset=3D".71" stop-color=3D"#0086e0"/><stop offset=3D".95" stop-c=
olor=3D"#0069d3"/><stop offset=3D"1" stop-color=3D"#0062d0"/></linearGradie=
nt><path fill=3D"url(#a)" d=3D"M62 54c0 4.4-3.6 8-8 8H10c-4.4 0-8-3.6-8-8V1=
0c0-4.4 3.6-8 8-8h44c4.4 0 8 3.6 8 8v44z"/><path fill=3D"#FFF" d=3D"M42 24.=
23H24c-.66 0-3.87.29-3.99 5.7L12.93 36a17.22 17.22 0 01-.93-5.77c0-10.27 7.=
18-14 12-14h18v-4l10 8-10 8v-4zM22 39.77h18c.66 0 3.87-.29 3.99-5.7L51.07 2=
8c.58 1.64.93 3.55.93 5.77 0 10.27-7.18 14-12 14H22v4l-10-8 10-8v4z"/></svg>
------MultipartBoundary--OoJfAV9FZhzZWjUztHGF5VXYsJWtK8zYCE3D5zLYtH------
