{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1984aecc-6be0-4b7b-a946-6f85f650645e",
   "metadata": {},
   "source": [
    "To load a pretrained ECAPA-TDNN model available for commercial use, download some sample audio files, and evaluate the model’s performance, you can follow these steps. For this example, we’ll use the SpeechBrain library, which provides pretrained models and tools for speaker verification.\n",
    "\n",
    "### Step 1: Install Dependencies\n",
    "If you haven’t already installed the necessary libraries, do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef177c86-c13f-4fab-abd6-d3da143f34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install speechbrain\n",
    "pip install torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d4f08-e7fd-4b28-8d54-7e424fff7f25",
   "metadata": {},
   "source": [
    "### Step 2: Load the Pretrained Model\n",
    "SpeechBrain provides a pretrained ECAPA-TDNN model that you can use directly. Here’s how to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd5599c-8968-4c22-814b-aafc58455a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "\n",
    "model_id = \"speechbrain/spkrec-ecapa-voxceleb\"\n",
    "\n",
    "# Load the pretrained ECAPA-TDNN model\n",
    "verification = SpeakerRecognition.from_hparams(source=model_id, savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb#compute-your-speaker-embeddings\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261ff31-fdd6-48a4-94db-c1d31c580d90",
   "metadata": {},
   "source": [
    "### Step 3: Download Sample Audio Files\n",
    "For demonstration purposes, you can download some sample audio files from online sources. Here, we use URLs to download a couple of sample audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc2fd6-5e40-4a5b-b759-5354907631a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_audio(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Sample audio URLs\n",
    "audio_urls = [\n",
    "    \"https://example.com/audio1.wav\",  # Replace with actual URLs\n",
    "    \"https://example.com/audio2.wav\"   # Replace with actual URLs\n",
    "]\n",
    "\n",
    "# Download audio samples\n",
    "audio_files = [\"audio1.wav\", \"audio2.wav\"]\n",
    "for url, filename in zip(audio_urls, audio_files):\n",
    "    download_audio(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01cc8c-6c9c-4abc-8469-4d816fc2cf95",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Model\n",
    "Evaluate the model by computing verification scores between pairs of audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7a838-c4d0-442e-9ac5-00b0a9b40210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load audio samples\n",
    "waveform1, sample_rate1 = torchaudio.load('samples/LibriSpeech/dev-other/116/288045/116-288045-0000.flac')#audio_files[0])\n",
    "waveform2, sample_rate2 = torchaudio.load('samples/LibriSpeech/dev-other/116/288045/116-288045-0001.flac')#audio_files[1])\n",
    "\n",
    "# Ensure the sample rates match\n",
    "assert sample_rate1 == sample_rate2, \"Sample rates do not match!\"\n",
    "\n",
    "# Perform speaker verification\n",
    "# score, prediction = verification.verify_batch(waveform1, waveform2)\n",
    "score, prediction = verification.verify_files(waveform1, waveform2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Verification score: {score.item()}\")\n",
    "print(f\"Prediction: {'Same speaker' if prediction else 'Different speakers'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25dc6a9d-0c74-4329-ab3a-2333ffe62b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification score: 0.7892520427703857\n",
      "Prediction: Same speaker\n",
      "Verification score: 0.08970315754413605\n",
      "Prediction: Different speakers\n"
     ]
    }
   ],
   "source": [
    "signal, fs =torchaudio.load('samples/LibriSpeech/dev-other/116/288045/116-288045-0000.flac')\n",
    "embeddings = classifier.encode_batch(signal)\n",
    "\n",
    "score, prediction = verification.verify_files('samples/LibriSpeech/dev-other/116/288045/116-288045-0000.flac', 'samples/LibriSpeech/dev-other/116/288045/116-288045-0001.flac') # Different Speakers\n",
    "\n",
    "# Output the results\n",
    "print(f\"Verification score: {score.item()}\")\n",
    "print(f\"Prediction: {'Same speaker' if prediction else 'Different speakers'}\")\n",
    "\n",
    "score, prediction = verification.verify_files('samples/LibriSpeech/dev-other/116/288045/116-288045-0000.flac', 'samples/LibriSpeech/dev-other/700/122866/700-122866-0000.flac') # Same Speaker\n",
    "\n",
    "# Output the results\n",
    "print(f\"Verification score: {score.item()}\")\n",
    "print(f\"Prediction: {'Same speaker' if prediction else 'Different speakers'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e66a2-3ed5-4148-9fcc-9c9d9cb415ab",
   "metadata": {},
   "source": [
    "### Complete Script\n",
    "Combining all the steps into a complete script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebd2ac-c68a-4dea-8382-25383e3dce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torchaudio\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "\n",
    "def download_audio(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Load the pretrained ECAPA-TDNN model\n",
    "model = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# Sample audio URLs (replace with actual URLs)\n",
    "audio_urls = [\n",
    "    \"https://example.com/audio1.wav\",\n",
    "    \"https://example.com/audio2.wav\"\n",
    "]\n",
    "\n",
    "# Download audio samples\n",
    "audio_files = [\"audio1.wav\", \"audio2.wav\"]\n",
    "for url, filename in zip(audio_urls, audio_files):\n",
    "    download_audio(url, filename)\n",
    "\n",
    "# Load audio samples\n",
    "waveform1, sample_rate1 = torchaudio.load(audio_files[0])\n",
    "waveform2, sample_rate2 = torchaudio.load(audio_files[1])\n",
    "\n",
    "# Ensure the sample rates match\n",
    "assert sample_rate1 == sample_rate2, \"Sample rates do not match!\"\n",
    "\n",
    "# Perform speaker verification\n",
    "score, prediction = model.verify_batch(waveform1, waveform2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Verification score: {score.item()}\")\n",
    "print(f\"Prediction: {'Same speaker' if prediction else 'Different speakers'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57282c-6601-4eb2-841d-180ec0435896",
   "metadata": {},
   "source": [
    "Replace the example audio URLs with actual URLs of audio files you want to test. This script will download the audio files, load the pretrained ECAPA-TDNN model, and evaluate the speaker verification performance between the two audio samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
