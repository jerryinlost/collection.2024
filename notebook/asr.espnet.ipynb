{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6027f4-753d-4cf6-b86f-55c042b7b0d4",
   "metadata": {},
   "source": [
    "ESPnet (End-to-End Speech Processing Toolkit) is a powerful toolkit for ASR and other speech processing tasks. Below, I’ll guide you through the process of using ESPnet to train a Korean ASR model using the Common Voice dataset and then converting that model to ONNX for deployment:\n",
    "\n",
    "### Step 1: Install ESPnet and Dependencies\n",
    "First, install ESPnet and its dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1a1c7-9fbc-4f13-b3a2-1af88f240b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/espnet/espnet\n",
    "cd espnet\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cfcb6-118c-43a0-9b73-3e44aceb8b01",
   "metadata": {},
   "source": [
    "### Step 2: Prepare the Common Voice Dataset\n",
    "ESPnet requires specific file formats and directories for datasets. Here’s how you can prepare the Common Voice dataset:\n",
    "\n",
    "1. Download the Dataset: Use the datasets library to download the Common Voice dataset.\n",
    "2. Convert and Organize: Convert the dataset into a format that ESPnet can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120a7cb-19d9-4d89-9562-2450d32bf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Common Voice dataset\n",
    "common_voice_train = load_dataset(\"mozilla-foundation/common_voice_8_0\", \"ko\", split=\"train\")\n",
    "common_voice_test = load_dataset(\"mozilla-foundation/common_voice_8_0\", \"ko\", split=\"test\")\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Save audio files and transcriptions\n",
    "def save_common_voice(dataset, save_dir):\n",
    "    with open(os.path.join(save_dir, \"wav.scp\"), \"w\") as wav_scp, \\\n",
    "         open(os.path.join(save_dir, \"text\"), \"w\") as text_f, \\\n",
    "         open(os.path.join(save_dir, \"utt2spk\"), \"w\") as utt2spk:\n",
    "        for i, sample in enumerate(dataset):\n",
    "            audio_path = os.path.join(save_dir, f\"{i}.wav\")\n",
    "            sample[\"audio\"][\"array\"].tofile(audio_path)\n",
    "            wav_scp.write(f\"{i} {audio_path}\\n\")\n",
    "            text_f.write(f\"{i} {sample['sentence']}\\n\")\n",
    "            utt2spk.write(f\"{i} {i}\\n\")  # dummy utt2spk\n",
    "\n",
    "save_common_voice(common_voice_train, train_dir)\n",
    "save_common_voice(common_voice_test, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a558dc7-8049-4ad2-879a-ab3513c495b9",
   "metadata": {},
   "source": [
    "### Step 3: Set Up ESPnet Configuration\n",
    "Prepare the configuration files for training. ESPnet uses YAML configuration files to define the training setup. Here’s an example configuration:\n",
    "\n",
    "Create a directory for your configuration and model files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556246d-9045-4535-a918-b723cd272e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p exp/whisper_asr/config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748a09e-233d-469d-be39-8b4ff64648ef",
   "metadata": {},
   "source": [
    "Create a config.yaml file inside exp/whisper_asr/config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816b166-40a4-49e8-9670-ad29fd643b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.yaml\n",
    "dataset:\n",
    "  train: \"data/train\"\n",
    "  valid: \"data/test\"\n",
    "\n",
    "model:\n",
    "  name: \"whisper_asr\"\n",
    "  frontend: \n",
    "    name: \"LogMelFilterBank\"\n",
    "    fs: 16000\n",
    "    n_mels: 80\n",
    "    n_fft: 400\n",
    "    hop_length: 160\n",
    "    fmin: 0\n",
    "    fmax: 8000\n",
    "\n",
    "  encoder:\n",
    "    name: \"Conformer\"\n",
    "    input_size: 80\n",
    "    output_size: 256\n",
    "    attention_heads: 4\n",
    "    linear_units: 2048\n",
    "    num_blocks: 12\n",
    "\n",
    "  decoder:\n",
    "    name: \"TransformerDecoder\"\n",
    "    vocab_size: 5000\n",
    "    attention_heads: 4\n",
    "    linear_units: 2048\n",
    "    num_blocks: 6\n",
    "\n",
    "training:\n",
    "  batch_size: 16\n",
    "  max_epochs: 50\n",
    "  learning_rate: 0.001\n",
    "  optimizer: \"adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8adbeb-0b35-4bbd-948a-ee0397cdbcff",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model\n",
    "Run the training process using ESPnet’s training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1c602-c3bc-4992-80d5-b81a3901bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd espnet/egs2/commonvoice/asr1\n",
    "./run.sh --stage 1 --stop_stage 5 --ngpu 1 --train_config exp/whisper_asr/config/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1542f-8508-42fd-8eac-46c154237f66",
   "metadata": {},
   "source": [
    "### Step 5: Convert the Model to ONNX\n",
    "After training, you can convert the model to ONNX format for deployment:\n",
    "\n",
    "1. Export the Model: Use ESPnet’s tools to export the trained model to ONNX.\n",
    "2. Verify the Export: Ensure the ONNX model runs correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ccead-2013-4268-b648-d9b7e719061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the directory with the trained model\n",
    "cd exp/whisper_asr/results\n",
    "\n",
    "# Export the model to ONNX\n",
    "python -m espnet2.bin.export_asr_model \\\n",
    "    --asr_train_config exp/whisper_asr/config/config.yaml \\\n",
    "    --asr_model_file exp/whisper_asr/results/model.pth \\\n",
    "    --output_file whisper_asr.onnx \\\n",
    "    --export_format onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5dad2-83e1-4136-b19f-fcaccd73542f",
   "metadata": {},
   "source": [
    "### Step 6: Verify the ONNX Model\n",
    "Load the ONNX model and run inference to ensure it works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18796beb-a8da-4e1a-b68d-5ac9021c8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = ort.InferenceSession(\"whisper_asr.onnx\")\n",
    "\n",
    "# Load an example audio file\n",
    "audio_path = \"path_to_audio_file.wav\"\n",
    "audio, rate = sf.read(audio_path)\n",
    "assert rate == 16000  # ensure the sample rate is 16000 Hz\n",
    "\n",
    "# Preprocess the audio\n",
    "audio = np.expand_dims(audio, axis=0)  # add batch dimension\n",
    "\n",
    "# Run inference\n",
    "onnx_inputs = {\"input\": audio}\n",
    "onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "\n",
    "# Decode the output if needed\n",
    "# This step depends on your model's output format\n",
    "print(\"ONNX model output:\", onnx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cd7b2-646d-493e-a844-311b6f30de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "This guide walks you through using ESPnet to train a Korean ASR model using the Common Voice dataset and converting it to ONNX for deployment. Adjust paths and parameters as needed for your specific use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
