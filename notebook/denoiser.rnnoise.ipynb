{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5bf6b5-5f4d-4959-9888-033694f43938",
   "metadata": {},
   "source": [
    "Hereâ€™s an all-in-one guide for using RNNoise, including loading pretrained models, preparing datasets, training, fine-tuning, evaluating, and deploying the model.\n",
    "\n",
    "#1. Loading Pretrained Models\n",
    "RNNoise comes with a pretrained model that you can use directly. Follow these steps to load and use it:\n",
    "\n",
    "Installation and Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154bb6a-cf78-4231-b9dc-dc07b7b8b463",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "git clone https://github.com/xiph/rnnoise.git\n",
    "cd rnnoise\n",
    "./autogen.sh\n",
    "./configure\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585864a-8921-4555-826b-6ccbd5403c7f",
   "metadata": {},
   "source": [
    "Using the Pretrained Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43c9f1-1b61-4f74-af8b-8b1badcfc786",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd examples\n",
    "./rnnoise_demo input.wav output.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb22629-0cf7-4c15-b3a5-7984c7376292",
   "metadata": {},
   "source": [
    "This command will denoise input.wav using the pretrained model and store the result in output.wav.\n",
    "\n",
    "#2. Preparing Datasets\n",
    "To train RNNoise on your own dataset, you need two types of audio files: clean speech and noisy speech.\n",
    "\n",
    "Dataset Preparation:\n",
    "\n",
    "Clean Speech: Collect recordings of clean speech.\n",
    "Noisy Speech: Mix clean speech with various background noises to create noisy speech samples.\n",
    "Example Python Script for Mixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b81c3-0fa1-4cbe-afe3-ffc49ec04380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def add_noise(clean_file, noise_file, snr_db):\n",
    "    clean, sr = sf.read(clean_file)\n",
    "    noise, _ = sf.read(noise_file)\n",
    "    if len(clean) > len(noise):\n",
    "        noise = np.tile(noise, int(np.ceil(len(clean) / len(noise))))\n",
    "    noise = noise[:len(clean)]\n",
    "    \n",
    "    clean_power = np.mean(clean**2)\n",
    "    noise_power = np.mean(noise**2)\n",
    "    desired_noise_power = clean_power / (10**(snr_db / 10))\n",
    "    scaling_factor = np.sqrt(desired_noise_power / noise_power)\n",
    "    noisy = clean + scaling_factor * noise\n",
    "\n",
    "    return noisy, sr\n",
    "\n",
    "clean_dir = 'clean_speech/'\n",
    "noise_dir = 'background_noises/'\n",
    "output_dir = 'noisy_speech/'\n",
    "\n",
    "snr_db = 10  # Signal-to-noise ratio\n",
    "\n",
    "for clean_file in os.listdir(clean_dir):\n",
    "    clean_path = os.path.join(clean_dir, clean_file)\n",
    "    noise_file = np.random.choice(os.listdir(noise_dir))\n",
    "    noise_path = os.path.join(noise_dir, noise_file)\n",
    "    \n",
    "    noisy, sr = add_noise(clean_path, noise_path, snr_db)\n",
    "    output_path = os.path.join(output_dir, clean_file)\n",
    "    sf.write(output_path, noisy, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5b86a-9731-4151-a9e6-ac9d3525e105",
   "metadata": {},
   "source": [
    "#3. Training the Model\n",
    "RNNoise uses a custom training script. The training process involves compiling the training code and running it.\n",
    "\n",
    "Compile the Training Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf0c2c-3c21-4076-bd5d-61ddf9f7f853",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd training\n",
    "gcc -o denoise_training rnn_train.c kiss_fft.c pitch.c celt_lpc.c -lm -I../src -I../include"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b4442-20eb-4b3b-a712-05cdf0c503ad",
   "metadata": {},
   "source": [
    "Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36d783-15e6-494b-b8b3-df09c38f5495",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "./denoise_training clean_speech/ noisy_speech/ model.rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b90d4-17bb-4b69-9829-9a96a2098b8d",
   "metadata": {},
   "source": [
    "This command will train a new model using the provided clean and noisy speech directories and save it as model.rnn.\n",
    "\n",
    "#4. Fine-Tuning the Model\n",
    "Fine-tuning involves continuing the training process with new data or a different dataset.\n",
    "\n",
    "Fine-Tuning Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f8913-ddf4-4bfc-ab92-a437119a4ed3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "./denoise_training clean_speech/ noisy_speech/ model.rnn --continue_from pretrained_model.rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0883e1-b9bb-480e-a1ee-41d650deaa95",
   "metadata": {},
   "source": [
    "5. Evaluation\n",
    "To evaluate the model, you can use the denoising demo with a test set and compare the results visually or using objective metrics like PESQ (Perceptual Evaluation of Speech Quality).\n",
    "\n",
    "Evaluation Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b2edf-fb43-4e4c-b674-b338f99ad6bd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "./rnnoise_demo test_noisy.wav test_denoised.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149aaf74-8be0-4972-9f4c-00a6775e8772",
   "metadata": {},
   "source": [
    "PESQ Evaluation (requires an external tool):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653ce54-46d3-49b5-aadf-5fced45ffc0a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pesq +16000 test_clean.wav test_denoised.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44059862-b11d-40f1-b195-6fb152b269a2",
   "metadata": {},
   "source": [
    "6. Deploying the Model\n",
    "To deploy the model on various platforms, you need to embed the RNNoise model into your application.\n",
    "\n",
    "Deploying on Mobile:\n",
    "\n",
    "Android: Use JNI (Java Native Interface) to call RNNoise functions from your Android application.\n",
    "iOS: Use Objective-C or Swift to call RNNoise functions.\n",
    "Example JNI Integration for Android:\n",
    "\n",
    "Create JNI Wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145e2d8-a3c8-49f8-8547-1115f22f21be",
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "outputs": [],
   "source": [
    "#include <jni.h>\n",
    "#include \"rnnoise.h\"\n",
    "\n",
    "JNIEXPORT void JNICALL Java_com_example_myapp_RNNoise_denoise(JNIEnv *env, jobject obj, jshortArray input, jshortArray output) {\n",
    "    jint length = (*env)->GetArrayLength(env, input);\n",
    "    jshort *input_buffer = (*env)->GetShortArrayElements(env, input, NULL);\n",
    "    jshort *output_buffer = (*env)->GetShortArrayElements(env, output, NULL);\n",
    "\n",
    "    DenoiseState *st = rnnoise_create(NULL);\n",
    "\n",
    "    for (int i = 0; i < length; i += FRAME_SIZE) {\n",
    "        rnnoise_process_frame(st, output_buffer + i, input_buffer + i);\n",
    "    }\n",
    "\n",
    "    rnnoise_destroy(st);\n",
    "\n",
    "    (*env)->ReleaseShortArrayElements(env, input, input_buffer, 0);\n",
    "    (*env)->ReleaseShortArrayElements(env, output, output_buffer, 0);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29721b-9076-45f0-8432-f11a4776dc76",
   "metadata": {},
   "source": [
    "Compile and Load the JNI Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3680c-6c3d-4514-8046-e22aeb0e6eb0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ndk-build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0dd33-a9a6-42d9-b956-84e15d46e508",
   "metadata": {},
   "source": [
    "Call from Java:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae9be9-26b2-4ee9-acf6-19c2fe95998b",
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [],
   "source": [
    "public class RNNoise {\n",
    "    static {\n",
    "        System.loadLibrary(\"rnnoise_jni\");\n",
    "    }\n",
    "\n",
    "    public native void denoise(short[] input, short[] output);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441bfaa-9a4a-4e5e-b684-a549551b57b8",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "This guide covers the essential steps to load, train, fine-tune, evaluate, and deploy RNNoise. Adjust the paths and parameters according to your specific needs and the environment you are working in. For more details and advanced usage, refer to the official RNNoise GitHub repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
