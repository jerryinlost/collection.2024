{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30588a67-291e-411e-a70a-54fd75fb6ba5",
   "metadata": {},
   "source": [
    "To create a domain-specific LLM chat model that focuses on science and technology, you need to ensure that your dataset is curated to include conversations relevant to these topics. Additionally, you should include examples where the model responds with “I don’t know” or “I’m not sure” for out-of-domain queries. Here’s a step-by-step guide on how to create and fine-tune such a model.\n",
    "\n",
    "### Sample Domain-Specific Chat Dataset\n",
    "Below is an example of a JSON dataset focused on science and technology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cbfb2-d114-4b3d-9444-3167bd6ff474",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"input_text\": \"Can you explain the theory of relativity?\",\n",
    "        \"response_text\": \"The theory of relativity, developed by Albert Einstein, includes both the special and the general theory of relativity. It revolutionized our understanding of space, time, and gravity.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What is quantum computing?\",\n",
    "        \"response_text\": \"Quantum computing is a type of computation that utilizes quantum bits or qubits, which can represent and store data in multiple states simultaneously.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What are black holes?\",\n",
    "        \"response_text\": \"Black holes are regions in space where the gravitational pull is so strong that even light cannot escape from them. They are formed when massive stars collapse at the end of their life cycles.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"Can you tell me about blockchain technology?\",\n",
    "        \"response_text\": \"Blockchain is a decentralized digital ledger that records transactions across many computers in such a way that the registered transactions cannot be altered retroactively.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"Who won the football match yesterday?\",\n",
    "        \"response_text\": \"I'm not sure about that. My knowledge is focused on science and technology.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What's the latest fashion trend?\",\n",
    "        \"response_text\": \"I don't know. I specialize in science and technology topics.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26900b2f-41aa-4006-a92a-1fa4938f373d",
   "metadata": {},
   "source": [
    "### Saving the Dataset\n",
    "Save the dataset to a file named domain_specific_chat_dataset.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b15b29-7f5c-4b2b-967b-9e30987dd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"input_text\": \"Can you explain the theory of relativity?\",\n",
    "        \"response_text\": \"The theory of relativity, developed by Albert Einstein, includes both the special and the general theory of relativity. It revolutionized our understanding of space, time, and gravity.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What is quantum computing?\",\n",
    "        \"response_text\": \"Quantum computing is a type of computation that utilizes quantum bits or qubits, which can represent and store data in multiple states simultaneously.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What are black holes?\",\n",
    "        \"response_text\": \"Black holes are regions in space where the gravitational pull is so strong that even light cannot escape from them. They are formed when massive stars collapse at the end of their life cycles.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"Can you tell me about blockchain technology?\",\n",
    "        \"response_text\": \"Blockchain is a decentralized digital ledger that records transactions across many computers in such a way that the registered transactions cannot be altered retroactively.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"Who won the football match yesterday?\",\n",
    "        \"response_text\": \"I'm not sure about that. My knowledge is focused on science and technology.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"What's the latest fashion trend?\",\n",
    "        \"response_text\": \"I don't know. I specialize in science and technology topics.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ec18a-4e31-489b-a7b9-dbd41592bdc0",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the Dataset\n",
    "Here’s how you can load and preprocess this dataset for fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c968144-1ace-48c4-9559-75bea7558dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import LLaMATokenizer, LLaMAForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('json', data_files={'train': 'path/to/domain_specific_chat_dataset.json'})\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"facebook/llama-3b\"\n",
    "tokenizer = LLaMATokenizer.from_pretrained(model_name)\n",
    "model = LLaMAForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    inputs = examples['input_text']\n",
    "    responses = examples['response_text']\n",
    "    inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    responses = tokenizer(responses, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    return {\n",
    "        'input_ids': inputs['input_ids'],\n",
    "        'attention_mask': inputs['attention_mask'],\n",
    "        'labels': responses['input_ids']\n",
    "    }\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_llama_chat')\n",
    "tokenizer.save_pretrained('./fine_tuned_llama_chat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654bf22-3a57-4a8a-bafa-7e4e16fd9219",
   "metadata": {},
   "source": [
    "### Inference with the Fine-tuned Chat Model\n",
    "Load your fine-tuned model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a02d2-6fe9-47e4-bbc1-40539e227e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = LLaMAForCausalLM.from_pretrained('./fine_tuned_llama_chat')\n",
    "tokenizer = LLaMATokenizer.from_pretrained('./fine_tuned_llama_chat')\n",
    "\n",
    "# Create a conversational pipeline\n",
    "chatbot = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate a response for an in-domain question\n",
    "prompt = \"What is quantum computing?\"\n",
    "generated_text = chatbot(prompt, max_length=50)\n",
    "print(generated_text)\n",
    "\n",
    "# Generate a response for an out-of-domain question\n",
    "prompt = \"What's the latest celebrity gossip?\"\n",
    "generated_text = chatbot(prompt, max_length=50)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4309a4-536c-4775-849c-e98f2b29cc3e",
   "metadata": {},
   "source": [
    "Notes\n",
    "1. Dataset Structure: Ensure your dataset includes both in-domain and out-of-domain examples, with appropriate responses for out-of-domain queries.\n",
    "2. Tokenization: Adjust the tokenization process as needed based on your specific tokenizer and model requirements.\n",
    "3. Special Tokens: You might want to add special tokens to signify the beginning and end of conversations, especially for more complex datasets.\n",
    "4. Evaluation: Regularly evaluate the model’s performance to ensure it correctly handles both in-domain and out-of-domain queries.\n",
    "This guide provides a framework for creating a domain-specific chat model that focuses on science and technology, with appropriate responses for out-of-domain topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
