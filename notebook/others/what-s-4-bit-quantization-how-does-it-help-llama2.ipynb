{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1e7a8b",
   "metadata": {
    "papermill": {
     "duration": 0.003413,
     "end_time": "2023-10-02T12:38:04.540972",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.537559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is 4-bit Quantization?\n",
    "\n",
    "Quantization in the context of deep learning is the process of constraining the number of bits that represent the weights and biases of the model. \n",
    "\n",
    "Weights and Biases numbers that we need in backpropagation. \n",
    "\n",
    "In 4-bit quantization, each weight or bias is represented using only 4 bits as opposed to the typical 32 bits used in single-precision floating-point format (float32).\n",
    "\n",
    "# Why does it use less GPU Memory?\n",
    "\n",
    "The primary advantage of using 4-bit quantization is the reduction in model size and memory usage. Here's a simple explanation:\n",
    "\n",
    "- A float32 number takes up 32 bits of memory.\n",
    "- A 4-bit quantized number takes up only 4 bits of memory.\n",
    "\n",
    "So, theoretically, you can fit 8 times more 4-bit quantized numbers into the same memory space as float32 numbers. This allows you to load larger models into the GPU memory or use smaller GPUs that might not have been able to handle the model otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda7416",
   "metadata": {
    "papermill": {
     "duration": 0.002346,
     "end_time": "2023-10-02T12:38:04.548431",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.546085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The amount of memory used by an integer in a computer system is directly related to the number of bits used to represent that integer.\n",
    "\n",
    "### Memory Usage for 4-bit Integer\n",
    "\n",
    "A 4-bit integer uses 4 bits of memory. \n",
    "\n",
    "### Memory Usage for 32-bit Integer\n",
    "\n",
    "A 32-bit integer uses 32 bits of memory.\n",
    "\n",
    "### Conversion to Bytes\n",
    "\n",
    "To convert these to bytes (since memory is often measured in bytes):\n",
    "\n",
    "- 1 byte = 8 bits\n",
    "- A 4-bit integer would use \\( 4/8 = 0.5 \\) bytes.\n",
    "- A 16-bit integer would use \\( 16/8 = 2 \\) bytes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee29c6b",
   "metadata": {
    "papermill": {
     "duration": 0.002141,
     "end_time": "2023-10-02T12:38:04.553172",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.551031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Llama 2 example\n",
    "\n",
    "For example, you may come across config like this in Llama 2 model:\n",
    "\n",
    "#### bnb_config = transformers.BitsAndBytesConfig(\n",
    "####    load_in_4bit=True,\n",
    "####    bnb_4bit_quant_type='nf4',\n",
    "####    bnb_4bit_use_double_quant=True,\n",
    "####    bnb_4bit_compute_dtype=bfloat16\n",
    "#### )\n",
    "\n",
    "\n",
    "* load_in_4bit=True: Enables 4-bit quantization.\n",
    "* bnb_4bit_quant_type='nf4': Specifies the type of 4-bit quantization.\n",
    "* bnb_4bit_use_double_quant=True: Enables double quantization for better accuracy.\n",
    "* bnb_4bit_compute_dtype=bfloat16: Specifies the data type for computation, which is bfloat16 here.\n",
    "\n",
    "By using 4-bit quantization, you can load the Llama 2 model with significantly less GPU memory, making it more accessible for devices with limited resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc84e8",
   "metadata": {
    "papermill": {
     "duration": 0.002118,
     "end_time": "2023-10-02T12:38:04.557690",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.555572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How much memory saved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bd6768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T12:38:04.564263Z",
     "iopub.status.busy": "2023-10-02T12:38:04.563908Z",
     "iopub.status.idle": "2023-10-02T12:38:04.574775Z",
     "shell.execute_reply": "2023-10-02T12:38:04.574138Z"
    },
    "papermill": {
     "duration": 0.020702,
     "end_time": "2023-10-02T12:38:04.580754",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.560052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saved by using 4-bit quantization: 3500.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Memory required for float32 weights\n",
    "\n",
    "float32_memory = 32  # in bits\n",
    "num_weights = 1000  # hypothetical number of weights\n",
    "\n",
    "float32_total_memory = float32_memory * num_weights  # in bits\n",
    "\n",
    "# Memory required for 4-bit quantized weights\n",
    "bit4_memory = 4  # in bits\n",
    "\n",
    "bit4_total_memory = bit4_memory * num_weights  # in bits\n",
    "\n",
    "# Memory saved\n",
    "memory_saved = float32_total_memory - bit4_total_memory  # in bits\n",
    "memory_saved_in_bytes = memory_saved / 8  # convert bits to bytes\n",
    "\n",
    "print(f\"Memory saved by using 4-bit quantization: {memory_saved_in_bytes} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85a21a",
   "metadata": {
    "papermill": {
     "duration": 0.002817,
     "end_time": "2023-10-02T12:38:04.588899",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.586082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Does reducing the bit-width from 32-bit to 4-bit quantization introduce the potential for a loss of accuracy in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757abaa",
   "metadata": {
    "papermill": {
     "duration": 0.002361,
     "end_time": "2023-10-02T12:38:04.593823",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.591462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a51835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T12:38:04.600975Z",
     "iopub.status.busy": "2023-10-02T12:38:04.600290Z",
     "iopub.status.idle": "2023-10-02T12:38:04.606516Z",
     "shell.execute_reply": "2023-10-02T12:38:04.605734Z"
    },
    "papermill": {
     "duration": 0.012005,
     "end_time": "2023-10-02T12:38:04.608359",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.596354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Quantization Error: 0.016702707617295285\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulate original float32 weights\n",
    "original_weights = np.random.rand(1000).astype(np.float32)\n",
    "\n",
    "# Simulate 4-bit quantized weights\n",
    "# First, normalize the weights to a range of 0 to 15 (since 4 bits can represent 16 values)\n",
    "quantized_weights = np.round(original_weights * 15).astype(np.uint8)\n",
    "\n",
    "# De-normalize to get the approximated original weights\n",
    "approximated_weights = quantized_weights / 15.0\n",
    "\n",
    "# Calculate the error\n",
    "error = np.abs(original_weights - approximated_weights).mean()\n",
    "\n",
    "print(f\"Average Quantization Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afacb78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T12:38:04.615823Z",
     "iopub.status.busy": "2023-10-02T12:38:04.615147Z",
     "iopub.status.idle": "2023-10-02T12:38:04.632155Z",
     "shell.execute_reply": "2023-10-02T12:38:04.630903Z"
    },
    "papermill": {
     "duration": 0.027666,
     "end_time": "2023-10-02T12:38:04.638886",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.611220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9247905 , 0.2848272 , 0.37645584, 0.5048465 , 0.6614357 ,\n",
       "       0.70491624, 0.1977602 , 0.6689422 , 0.66872555, 0.5624521 ,\n",
       "       0.6305628 , 0.3726736 , 0.35116363, 0.07541367, 0.45414782,\n",
       "       0.76398283, 0.05985678, 0.5913115 , 0.41074526, 0.13541609,\n",
       "       0.5910739 , 0.86276126, 0.06655507, 0.9818092 , 0.3161168 ,\n",
       "       0.3306428 , 0.39539385, 0.20723748, 0.9959016 , 0.30415216,\n",
       "       0.1939258 , 0.74822813, 0.27812615, 0.7735159 , 0.529855  ,\n",
       "       0.4883202 , 0.4443134 , 0.3167042 , 0.7455749 , 0.5094897 ,\n",
       "       0.8444225 , 0.29333502, 0.2650708 , 0.6700357 , 0.32049704,\n",
       "       0.41324535, 0.2554307 , 0.46257398, 0.5577883 , 0.07777528,\n",
       "       0.5722218 , 0.86186   , 0.4652247 , 0.39145812, 0.114711  ,\n",
       "       0.76122326, 0.5548202 , 0.44338274, 0.20434345, 0.68144834,\n",
       "       0.80105406, 0.21737652, 0.57614595, 0.79485035, 0.6377741 ,\n",
       "       0.01437411, 0.08599136, 0.903764  , 0.84312135, 0.31127113,\n",
       "       0.9599578 , 0.51527417, 0.6231499 , 0.5020487 , 0.63205826,\n",
       "       0.8093046 , 0.9670442 , 0.61998105, 0.3239916 , 0.1519587 ,\n",
       "       0.9992012 , 0.8641727 , 0.37833083, 0.9285793 , 0.59500235,\n",
       "       0.7526545 , 0.82951605, 0.9053931 , 0.44898385, 0.32977387,\n",
       "       0.05613903, 0.3861092 , 0.88941234, 0.8091628 , 0.32335544,\n",
       "       0.87015074, 0.8732235 , 0.37011796, 0.13631244, 0.35166827,\n",
       "       0.8674333 , 0.04825656, 0.9036351 , 0.13799779, 0.684421  ,\n",
       "       0.02148546, 0.6161236 , 0.9660635 , 0.03511966, 0.20038503,\n",
       "       0.81643647, 0.5247684 , 0.1134994 , 0.93596876, 0.6033687 ,\n",
       "       0.91222763, 0.36437628, 0.12638104, 0.00682061, 0.01755489,\n",
       "       0.12852022, 0.23988333, 0.33909032, 0.4915682 , 0.33492377,\n",
       "       0.17019396, 0.50235146, 0.7478315 , 0.12404448, 0.36378646,\n",
       "       0.70764726, 0.9002735 , 0.52397186, 0.78900677, 0.37160566,\n",
       "       0.7897496 , 0.78931963, 0.83007073, 0.9313968 , 0.40650165,\n",
       "       0.02085661, 0.40813735, 0.64172626, 0.12151229, 0.00399546,\n",
       "       0.49214867, 0.88705975, 0.7945594 , 0.5236582 , 0.11228065,\n",
       "       0.46125057, 0.15863311, 0.6206407 , 0.1254296 , 0.702884  ,\n",
       "       0.27337062, 0.94333553, 0.6122982 , 0.00867853, 0.4631799 ,\n",
       "       0.8349043 , 0.5687328 , 0.0337532 , 0.5978145 , 0.24709952,\n",
       "       0.27581465, 0.71458006, 0.9074249 , 0.24917446, 0.01321967,\n",
       "       0.72622067, 0.7317202 , 0.9460668 , 0.17175825, 0.52061826,\n",
       "       0.12912926, 0.26173362, 0.99134666, 0.16931483, 0.37991887,\n",
       "       0.9894757 , 0.398251  , 0.30836052, 0.39970383, 0.13175255,\n",
       "       0.46730444, 0.02427318, 0.03484402, 0.19438368, 0.49511686,\n",
       "       0.90122455, 0.27320004, 0.49255353, 0.9783599 , 0.63262385,\n",
       "       0.70927244, 0.8215986 , 0.04758386, 0.69964236, 0.22682844,\n",
       "       0.07726932, 0.7840542 , 0.85137475, 0.34351614, 0.94570094,\n",
       "       0.5904307 , 0.3468087 , 0.8439402 , 0.08711204, 0.00675822,\n",
       "       0.9135841 , 0.9381849 , 0.54306096, 0.37238097, 0.36070648,\n",
       "       0.13560945, 0.1421399 , 0.9235801 , 0.5506216 , 0.07477881,\n",
       "       0.62914824, 0.07239455, 0.3860086 , 0.6220938 , 0.60415006,\n",
       "       0.9202855 , 0.53279597, 0.254215  , 0.32387847, 0.9616438 ,\n",
       "       0.9031403 , 0.3243313 , 0.9708769 , 0.09148977, 0.20536418,\n",
       "       0.3032188 , 0.17976852, 0.40420958, 0.77856714, 0.53324544,\n",
       "       0.32758078, 0.5584226 , 0.9738276 , 0.42731893, 0.4088103 ,\n",
       "       0.9549212 , 0.8485227 , 0.3754357 , 0.03496957, 0.04705817,\n",
       "       0.6729662 , 0.78081745, 0.54638726, 0.62761277, 0.25494924,\n",
       "       0.33513072, 0.10644619, 0.34918892, 0.9391043 , 0.79571396,\n",
       "       0.5373918 , 0.2194457 , 0.5983357 , 0.6934405 , 0.39701807,\n",
       "       0.51229495, 0.63684946, 0.485857  , 0.20417246, 0.83522034,\n",
       "       0.02878025, 0.8577273 , 0.7188059 , 0.84552413, 0.17658049,\n",
       "       0.15435342, 0.70073724, 0.11626012, 0.05647076, 0.77965325,\n",
       "       0.54660654, 0.2869918 , 0.42399552, 0.07076759, 0.58312637,\n",
       "       0.6441227 , 0.472317  , 0.89559144, 0.47842032, 0.6088338 ,\n",
       "       0.10209738, 0.63835883, 0.66511667, 0.14001594, 0.50129664,\n",
       "       0.6989543 , 0.92579305, 0.6087187 , 0.98445004, 0.42757654,\n",
       "       0.2492896 , 0.9261909 , 0.3583853 , 0.54635626, 0.24734883,\n",
       "       0.16481586, 0.6537634 , 0.9298236 , 0.11292024, 0.03744415,\n",
       "       0.9682399 , 0.32909802, 0.84502566, 0.8146653 , 0.7789694 ,\n",
       "       0.78189373, 0.7011703 , 0.66325325, 0.21216182, 0.48020098,\n",
       "       0.3398132 , 0.9690847 , 0.8440292 , 0.0998117 , 0.17358793,\n",
       "       0.3876153 , 0.76487416, 0.40854642, 0.82727927, 0.9636029 ,\n",
       "       0.02524276, 0.2660796 , 0.29336682, 0.69673663, 0.4087555 ,\n",
       "       0.9027439 , 0.9010638 , 0.98143256, 0.54791445, 0.7346431 ,\n",
       "       0.09087659, 0.3680253 , 0.8383691 , 0.8983759 , 0.8886402 ,\n",
       "       0.97295547, 0.1598561 , 0.889189  , 0.34903973, 0.2088432 ,\n",
       "       0.9334321 , 0.6892805 , 0.17181328, 0.24951164, 0.8714563 ,\n",
       "       0.7707379 , 0.4348375 , 0.05445483, 0.26247665, 0.42056555,\n",
       "       0.6458762 , 0.994984  , 0.23023689, 0.49335098, 0.5749274 ,\n",
       "       0.03549622, 0.6614646 , 0.32604757, 0.8411492 , 0.6014299 ,\n",
       "       0.556614  , 0.22856033, 0.77451885, 0.44483408, 0.5764493 ,\n",
       "       0.7041714 , 0.6324034 , 0.87016445, 0.16718023, 0.8420739 ,\n",
       "       0.35930544, 0.39170244, 0.70718235, 0.19915745, 0.9062168 ,\n",
       "       0.4297453 , 0.42553732, 0.23632017, 0.8035896 , 0.44707108,\n",
       "       0.2634908 , 0.07211592, 0.75678754, 0.26730564, 0.9197045 ,\n",
       "       0.14062339, 0.20878962, 0.41099194, 0.82776505, 0.1350937 ,\n",
       "       0.09660045, 0.5967782 , 0.28064346, 0.28855392, 0.69421977,\n",
       "       0.1150708 , 0.2535367 , 0.18933596, 0.10883702, 0.5151214 ,\n",
       "       0.5814914 , 0.11903459, 0.1102537 , 0.06064845, 0.24295211,\n",
       "       0.32612   , 0.47081596, 0.11046283, 0.15193833, 0.9409744 ,\n",
       "       0.6639216 , 0.9518797 , 0.93844056, 0.3168064 , 0.81975293,\n",
       "       0.5008619 , 0.5870457 , 0.88896036, 0.75511855, 0.5931686 ,\n",
       "       0.00237831, 0.3235895 , 0.6829626 , 0.38505405, 0.5221913 ,\n",
       "       0.35351092, 0.99492854, 0.81255406, 0.44788668, 0.1932731 ,\n",
       "       0.58678806, 0.43516153, 0.2750339 , 0.19598378, 0.44029942,\n",
       "       0.10625894, 0.09594972, 0.80597174, 0.70611864, 0.59545755,\n",
       "       0.07859442, 0.30962664, 0.85321015, 0.6850654 , 0.8343945 ,\n",
       "       0.7362548 , 0.17506126, 0.873798  , 0.16578087, 0.03852344,\n",
       "       0.7377012 , 0.84202874, 0.29127777, 0.8712854 , 0.11898137,\n",
       "       0.39217603, 0.08139974, 0.92953   , 0.02139349, 0.8167306 ,\n",
       "       0.7695847 , 0.6169915 , 0.01396774, 0.5035795 , 0.12585635,\n",
       "       0.70370847, 0.5627265 , 0.16273457, 0.14108036, 0.34193364,\n",
       "       0.03578128, 0.59881014, 0.20798108, 0.9712396 , 0.14116302,\n",
       "       0.679537  , 0.21987464, 0.8213627 , 0.88243246, 0.9263737 ,\n",
       "       0.5457797 , 0.74583226, 0.39825797, 0.9166179 , 0.27164716,\n",
       "       0.6815221 , 0.1575049 , 0.28972745, 0.45303413, 0.7834206 ,\n",
       "       0.12626061, 0.85363847, 0.30206484, 0.85303587, 0.5161928 ,\n",
       "       0.29282957, 0.2970345 , 0.63957995, 0.8399543 , 0.15512358,\n",
       "       0.5591223 , 0.00718524, 0.4408278 , 0.51740354, 0.63400114,\n",
       "       0.06706423, 0.64879483, 0.11055975, 0.722854  , 0.887117  ,\n",
       "       0.26816857, 0.9191859 , 0.9759207 , 0.34943742, 0.8939429 ,\n",
       "       0.65951085, 0.26824597, 0.21520211, 0.07122353, 0.80425674,\n",
       "       0.03669934, 0.65794426, 0.6689174 , 0.25415918, 0.58718777,\n",
       "       0.8624597 , 0.9145581 , 0.9954449 , 0.6199358 , 0.26556706,\n",
       "       0.04554615, 0.23538649, 0.3051448 , 0.2695529 , 0.64597076,\n",
       "       0.45039552, 0.9113422 , 0.1634528 , 0.02414978, 0.8175326 ,\n",
       "       0.69809663, 0.627951  , 0.01265111, 0.7289182 , 0.02993375,\n",
       "       0.38501173, 0.44420227, 0.35471666, 0.58677566, 0.5321426 ,\n",
       "       0.82418686, 0.6509282 , 0.13947505, 0.9232024 , 0.796269  ,\n",
       "       0.63942415, 0.716607  , 0.06879786, 0.6066851 , 0.18956506,\n",
       "       0.10158851, 0.41540888, 0.06432672, 0.1510485 , 0.02225441,\n",
       "       0.42360908, 0.8147584 , 0.9396546 , 0.5693913 , 0.37650347,\n",
       "       0.54947805, 0.9824942 , 0.12219659, 0.30460802, 0.75611264,\n",
       "       0.15245968, 0.01130517, 0.18301788, 0.31748703, 0.82860994,\n",
       "       0.43663746, 0.8646656 , 0.03888908, 0.958702  , 0.8182062 ,\n",
       "       0.25769272, 0.94097537, 0.35181   , 0.7747592 , 0.25193575,\n",
       "       0.25160265, 0.2081006 , 0.65299267, 0.81088793, 0.48370168,\n",
       "       0.82599854, 0.69801617, 0.686502  , 0.8207503 , 0.24084303,\n",
       "       0.72583336, 0.65351313, 0.5514388 , 0.41470546, 0.4592439 ,\n",
       "       0.4708956 , 0.73645544, 0.30698046, 0.10926422, 0.5302246 ,\n",
       "       0.70843196, 0.91334283, 0.67921114, 0.20324607, 0.35329187,\n",
       "       0.7078961 , 0.74145246, 0.5544212 , 0.06273006, 0.6839426 ,\n",
       "       0.24386226, 0.5375901 , 0.19401796, 0.7166422 , 0.59213424,\n",
       "       0.00311711, 0.8373777 , 0.2957592 , 0.9734112 , 0.23776135,\n",
       "       0.16368793, 0.31064123, 0.72003603, 0.7738747 , 0.3167719 ,\n",
       "       0.85921836, 0.66165346, 0.6513837 , 0.4469418 , 0.04181121,\n",
       "       0.0010123 , 0.16929118, 0.8014613 , 0.1350485 , 0.74894416,\n",
       "       0.9735513 , 0.340272  , 0.7291188 , 0.65350044, 0.90936404,\n",
       "       0.9403724 , 0.6767839 , 0.39657232, 0.60243833, 0.345012  ,\n",
       "       0.01773605, 0.64229417, 0.82027775, 0.4460361 , 0.17851539,\n",
       "       0.9155594 , 0.02575994, 0.75934935, 0.584515  , 0.7468415 ,\n",
       "       0.7461439 , 0.32422084, 0.20158266, 0.9540315 , 0.8402835 ,\n",
       "       0.17900822, 0.4187348 , 0.73294395, 0.16009754, 0.5110371 ,\n",
       "       0.15395421, 0.6320243 , 0.4121941 , 0.04727651, 0.02316737,\n",
       "       0.71254414, 0.20368813, 0.08020285, 0.09003788, 0.7278732 ,\n",
       "       0.87937194, 0.9470563 , 0.86397463, 0.03085249, 0.88822687,\n",
       "       0.67225766, 0.5322629 , 0.69068605, 0.48644426, 0.6748323 ,\n",
       "       0.48571163, 0.24726811, 0.44275507, 0.02572296, 0.8730789 ,\n",
       "       0.69065857, 0.05243539, 0.02406849, 0.60570914, 0.17354877,\n",
       "       0.4967655 , 0.04563055, 0.9075684 , 0.3894639 , 0.6496719 ,\n",
       "       0.7969087 , 0.1961282 , 0.8699387 , 0.0030388 , 0.20986001,\n",
       "       0.27902544, 0.60832024, 0.8490522 , 0.2718885 , 0.7740278 ,\n",
       "       0.9028884 , 0.08648127, 0.06974612, 0.64579976, 0.50048137,\n",
       "       0.6335028 , 0.9803541 , 0.7275574 , 0.85641414, 0.7452934 ,\n",
       "       0.19004133, 0.67654204, 0.0841193 , 0.42817116, 0.4128771 ,\n",
       "       0.34311873, 0.5584111 , 0.44102967, 0.23675632, 0.24060997,\n",
       "       0.40507612, 0.6768407 , 0.53710806, 0.781898  , 0.9153345 ,\n",
       "       0.9060555 , 0.32104817, 0.54942244, 0.66818047, 0.7386264 ,\n",
       "       0.49324703, 0.66197807, 0.37620726, 0.2742072 , 0.5524879 ,\n",
       "       0.21175316, 0.6429537 , 0.53812283, 0.32635143, 0.9283183 ,\n",
       "       0.74310005, 0.5916253 , 0.6019287 , 0.24455564, 0.7165667 ,\n",
       "       0.28983173, 0.6528186 , 0.7662959 , 0.8404083 , 0.7120508 ,\n",
       "       0.99050635, 0.6067772 , 0.42324227, 0.10369828, 0.3639981 ,\n",
       "       0.07615286, 0.47292057, 0.6121598 , 0.4091666 , 0.6545358 ,\n",
       "       0.9626738 , 0.21135864, 0.05096659, 0.76674646, 0.97735375,\n",
       "       0.00406052, 0.35031906, 0.92677325, 0.65122104, 0.35406604,\n",
       "       0.9379824 , 0.8607681 , 0.20878793, 0.80759835, 0.5253145 ,\n",
       "       0.5263725 , 0.5131473 , 0.5541148 , 0.92705494, 0.4362372 ,\n",
       "       0.60734206, 0.22290686, 0.30826545, 0.20727628, 0.44096127,\n",
       "       0.05434992, 0.07472291, 0.97850716, 0.30620503, 0.68257225,\n",
       "       0.3075231 , 0.6825377 , 0.7780158 , 0.94146174, 0.15013908,\n",
       "       0.6435419 , 0.70537186, 0.87541825, 0.8780773 , 0.6595325 ,\n",
       "       0.43759757, 0.98713005, 0.16669329, 0.24653836, 0.28286126,\n",
       "       0.4383437 , 0.37021476, 0.8051173 , 0.47806275, 0.87244076,\n",
       "       0.83561593, 0.1617546 , 0.10761639, 0.652469  , 0.5231207 ,\n",
       "       0.9131601 , 0.6444807 , 0.3915194 , 0.05628731, 0.42349553,\n",
       "       0.02560674, 0.77987057, 0.557059  , 0.50296897, 0.10107689,\n",
       "       0.07212245, 0.4658627 , 0.3055381 , 0.02835651, 0.053854  ,\n",
       "       0.32439408, 0.12739515, 0.34960845, 0.8226265 , 0.8282228 ,\n",
       "       0.88230217, 0.70598114, 0.2303811 , 0.18453375, 0.32185498,\n",
       "       0.93852377, 0.7585628 , 0.11123346, 0.87183684, 0.44207102,\n",
       "       0.94450706, 0.14782925, 0.79240626, 0.7661786 , 0.8448196 ,\n",
       "       0.53027284, 0.09370613, 0.4080347 , 0.07996603, 0.9916289 ,\n",
       "       0.63828534, 0.4979778 , 0.64707637, 0.13178948, 0.36008406,\n",
       "       0.5286276 , 0.88213634, 0.13156182, 0.9488928 , 0.48292994,\n",
       "       0.71608603, 0.6097873 , 0.7531336 , 0.25398678, 0.15511946,\n",
       "       0.94247615, 0.89409524, 0.817239  , 0.15403579, 0.14143272,\n",
       "       0.87896496, 0.24080701, 0.05707967, 0.7832768 , 0.35203117,\n",
       "       0.62733924, 0.77011454, 0.14697972, 0.66290784, 0.9725747 ,\n",
       "       0.63516885, 0.7768082 , 0.07048567, 0.9277904 , 0.05721804,\n",
       "       0.25402203, 0.29742715, 0.16353625, 0.6382225 , 0.5457198 ,\n",
       "       0.73375046, 0.0123429 , 0.73885757, 0.8461134 , 0.6909568 ,\n",
       "       0.11277763, 0.32322925, 0.5448431 , 0.6929839 , 0.5547437 ,\n",
       "       0.8300751 , 0.7024793 , 0.7545807 , 0.7374399 , 0.10512897,\n",
       "       0.65766484, 0.00600639, 0.07618403, 0.308637  , 0.6971407 ,\n",
       "       0.7954833 , 0.23549378, 0.89026225, 0.82091475, 0.2651529 ,\n",
       "       0.44331703, 0.0765395 , 0.00240085, 0.00803138, 0.5045058 ,\n",
       "       0.86056703, 0.48642883, 0.57022697, 0.6168151 , 0.6309857 ,\n",
       "       0.43641293, 0.33521482, 0.6582913 , 0.61792433, 0.863003  ,\n",
       "       0.56756824, 0.43745187, 0.54027647, 0.9033196 , 0.09475409,\n",
       "       0.6409492 , 0.5522212 , 0.69792515, 0.18284811, 0.37593803,\n",
       "       0.33391082, 0.94864076, 0.91070706, 0.85463613, 0.5558129 ,\n",
       "       0.9574069 , 0.3159297 , 0.28988558, 0.6914914 , 0.7835678 ,\n",
       "       0.50695336, 0.04407465, 0.02818633, 0.8088833 , 0.19140139,\n",
       "       0.82159346, 0.3919144 , 0.76353943, 0.8506777 , 0.30010542,\n",
       "       0.12562837, 0.05173601, 0.3748851 , 0.92234635, 0.06064414],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e04222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T12:38:04.648587Z",
     "iopub.status.busy": "2023-10-02T12:38:04.647910Z",
     "iopub.status.idle": "2023-10-02T12:38:04.654928Z",
     "shell.execute_reply": "2023-10-02T12:38:04.654238Z"
    },
    "papermill": {
     "duration": 0.01408,
     "end_time": "2023-10-02T12:38:04.656641",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.642561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  4,  6,  8, 10, 11,  3, 10, 10,  8,  9,  6,  5,  1,  7, 11,  1,\n",
       "        9,  6,  2,  9, 13,  1, 15,  5,  5,  6,  3, 15,  5,  3, 11,  4, 12,\n",
       "        8,  7,  7,  5, 11,  8, 13,  4,  4, 10,  5,  6,  4,  7,  8,  1,  9,\n",
       "       13,  7,  6,  2, 11,  8,  7,  3, 10, 12,  3,  9, 12, 10,  0,  1, 14,\n",
       "       13,  5, 14,  8,  9,  8,  9, 12, 15,  9,  5,  2, 15, 13,  6, 14,  9,\n",
       "       11, 12, 14,  7,  5,  1,  6, 13, 12,  5, 13, 13,  6,  2,  5, 13,  1,\n",
       "       14,  2, 10,  0,  9, 14,  1,  3, 12,  8,  2, 14,  9, 14,  5,  2,  0,\n",
       "        0,  2,  4,  5,  7,  5,  3,  8, 11,  2,  5, 11, 14,  8, 12,  6, 12,\n",
       "       12, 12, 14,  6,  0,  6, 10,  2,  0,  7, 13, 12,  8,  2,  7,  2,  9,\n",
       "        2, 11,  4, 14,  9,  0,  7, 13,  9,  1,  9,  4,  4, 11, 14,  4,  0,\n",
       "       11, 11, 14,  3,  8,  2,  4, 15,  3,  6, 15,  6,  5,  6,  2,  7,  0,\n",
       "        1,  3,  7, 14,  4,  7, 15,  9, 11, 12,  1, 10,  3,  1, 12, 13,  5,\n",
       "       14,  9,  5, 13,  1,  0, 14, 14,  8,  6,  5,  2,  2, 14,  8,  1,  9,\n",
       "        1,  6,  9,  9, 14,  8,  4,  5, 14, 14,  5, 15,  1,  3,  5,  3,  6,\n",
       "       12,  8,  5,  8, 15,  6,  6, 14, 13,  6,  1,  1, 10, 12,  8,  9,  4,\n",
       "        5,  2,  5, 14, 12,  8,  3,  9, 10,  6,  8, 10,  7,  3, 13,  0, 13,\n",
       "       11, 13,  3,  2, 11,  2,  1, 12,  8,  4,  6,  1,  9, 10,  7, 13,  7,\n",
       "        9,  2, 10, 10,  2,  8, 10, 14,  9, 15,  6,  4, 14,  5,  8,  4,  2,\n",
       "       10, 14,  2,  1, 15,  5, 13, 12, 12, 12, 11, 10,  3,  7,  5, 15, 13,\n",
       "        1,  3,  6, 11,  6, 12, 14,  0,  4,  4, 10,  6, 14, 14, 15,  8, 11,\n",
       "        1,  6, 13, 13, 13, 15,  2, 13,  5,  3, 14, 10,  3,  4, 13, 12,  7,\n",
       "        1,  4,  6, 10, 15,  3,  7,  9,  1, 10,  5, 13,  9,  8,  3, 12,  7,\n",
       "        9, 11,  9, 13,  3, 13,  5,  6, 11,  3, 14,  6,  6,  4, 12,  7,  4,\n",
       "        1, 11,  4, 14,  2,  3,  6, 12,  2,  1,  9,  4,  4, 10,  2,  4,  3,\n",
       "        2,  8,  9,  2,  2,  1,  4,  5,  7,  2,  2, 14, 10, 14, 14,  5, 12,\n",
       "        8,  9, 13, 11,  9,  0,  5, 10,  6,  8,  5, 15, 12,  7,  3,  9,  7,\n",
       "        4,  3,  7,  2,  1, 12, 11,  9,  1,  5, 13, 10, 13, 11,  3, 13,  2,\n",
       "        1, 11, 13,  4, 13,  2,  6,  1, 14,  0, 12, 12,  9,  0,  8,  2, 11,\n",
       "        8,  2,  2,  5,  1,  9,  3, 15,  2, 10,  3, 12, 13, 14,  8, 11,  6,\n",
       "       14,  4, 10,  2,  4,  7, 12,  2, 13,  5, 13,  8,  4,  4, 10, 13,  2,\n",
       "        8,  0,  7,  8, 10,  1, 10,  2, 11, 13,  4, 14, 15,  5, 13, 10,  4,\n",
       "        3,  1, 12,  1, 10, 10,  4,  9, 13, 14, 15,  9,  4,  1,  4,  5,  4,\n",
       "       10,  7, 14,  2,  0, 12, 10,  9,  0, 11,  0,  6,  7,  5,  9,  8, 12,\n",
       "       10,  2, 14, 12, 10, 11,  1,  9,  3,  2,  6,  1,  2,  0,  6, 12, 14,\n",
       "        9,  6,  8, 15,  2,  5, 11,  2,  0,  3,  5, 12,  7, 13,  1, 14, 12,\n",
       "        4, 14,  5, 12,  4,  4,  3, 10, 12,  7, 12, 10, 10, 12,  4, 11, 10,\n",
       "        8,  6,  7,  7, 11,  5,  2,  8, 11, 14, 10,  3,  5, 11, 11,  8,  1,\n",
       "       10,  4,  8,  3, 11,  9,  0, 13,  4, 15,  4,  2,  5, 11, 12,  5, 13,\n",
       "       10, 10,  7,  1,  0,  3, 12,  2, 11, 15,  5, 11, 10, 14, 14, 10,  6,\n",
       "        9,  5,  0, 10, 12,  7,  3, 14,  0, 11,  9, 11, 11,  5,  3, 14, 13,\n",
       "        3,  6, 11,  2,  8,  2,  9,  6,  1,  0, 11,  3,  1,  1, 11, 13, 14,\n",
       "       13,  0, 13, 10,  8, 10,  7, 10,  7,  4,  7,  0, 13, 10,  1,  0,  9,\n",
       "        3,  7,  1, 14,  6, 10, 12,  3, 13,  0,  3,  4,  9, 13,  4, 12, 14,\n",
       "        1,  1, 10,  8, 10, 15, 11, 13, 11,  3, 10,  1,  6,  6,  5,  8,  7,\n",
       "        4,  4,  6, 10,  8, 12, 14, 14,  5,  8, 10, 11,  7, 10,  6,  4,  8,\n",
       "        3, 10,  8,  5, 14, 11,  9,  9,  4, 11,  4, 10, 11, 13, 11, 15,  9,\n",
       "        6,  2,  5,  1,  7,  9,  6, 10, 14,  3,  1, 12, 15,  0,  5, 14, 10,\n",
       "        5, 14, 13,  3, 12,  8,  8,  8,  8, 14,  7,  9,  3,  5,  3,  7,  1,\n",
       "        1, 15,  5, 10,  5, 10, 12, 14,  2, 10, 11, 13, 13, 10,  7, 15,  3,\n",
       "        4,  4,  7,  6, 12,  7, 13, 13,  2,  2, 10,  8, 14, 10,  6,  1,  6,\n",
       "        0, 12,  8,  8,  2,  1,  7,  5,  0,  1,  5,  2,  5, 12, 12, 13, 11,\n",
       "        3,  3,  5, 14, 11,  2, 13,  7, 14,  2, 12, 11, 13,  8,  1,  6,  1,\n",
       "       15, 10,  7, 10,  2,  5,  8, 13,  2, 14,  7, 11,  9, 11,  4,  2, 14,\n",
       "       13, 12,  2,  2, 13,  4,  1, 12,  5,  9, 12,  2, 10, 15, 10, 12,  1,\n",
       "       14,  1,  4,  4,  2, 10,  8, 11,  0, 11, 13, 10,  2,  5,  8, 10,  8,\n",
       "       12, 11, 11, 11,  2, 10,  0,  1,  5, 10, 12,  4, 13, 12,  4,  7,  1,\n",
       "        0,  0,  8, 13,  7,  9,  9,  9,  7,  5, 10,  9, 13,  9,  7,  8, 14,\n",
       "        1, 10,  8, 10,  3,  6,  5, 14, 14, 13,  8, 14,  5,  4, 10, 12,  8,\n",
       "        1,  0, 12,  3, 12,  6, 11, 13,  5,  2,  1,  6, 14,  1],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb2612",
   "metadata": {
    "papermill": {
     "duration": 0.003227,
     "end_time": "2023-10-02T12:38:04.663381",
     "exception": false,
     "start_time": "2023-10-02T12:38:04.660154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.847458,
   "end_time": "2023-10-02T12:38:05.087008",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-02T12:38:01.239550",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
