{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722a32ab-5ce7-4afb-940c-ac4ff570cbf5",
   "metadata": {},
   "source": [
    "Hereâ€™s an all-in-one guide for using DeepFilterNet, including loading pretrained models, preparing datasets, training, fine-tuning, evaluating, and deploying the model.\n",
    "\n",
    "#1. Loading Pretrained Models\n",
    "DeepFilterNet provides pretrained models which you can use directly. Follow these steps to load and use them:\n",
    "\n",
    "Installation and Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba422b2-0b68-4a9e-b504-fce46a465cb1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install cpu/cuda pytorch (>=1.9) dependency from pytorch.org, e.g.:\n",
    "pip install torch torchaudio -f https://download.pytorch.org/whl/cpu/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c048622-6cf2-4253-a724-212eaf35cfa2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install DeepFilterNet\n",
    "pip install deepfilternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e82449-f9f5-4b45-9db8-42150577624e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Or install DeepFilterNet including data loading functionality for training (Linux only)\n",
    "pip install deepfilternet[train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bee373-cc42-46fa-8a5d-59e756f65ede",
   "metadata": {},
   "source": [
    "Using the Pretrained Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed346eb0-64ed-413d-a2e4-2ee273610751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from deepfilter import DeepFilterNet\n",
    "\n",
    "# Load the pretrained model\n",
    "model = DeepFilterNet.from_pretrained('deepfilternet')\n",
    "\n",
    "# Denoise an audio file\n",
    "input_file = 'input.wav'\n",
    "output_file = 'output.wav'\n",
    "model.denoise_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ef11d-2c65-40ce-9753-71592b5f63c5",
   "metadata": {},
   "source": [
    "2. Preparing Datasets\n",
    "To train DeepFilterNet on your own dataset, you need clean speech and noisy speech recordings.\n",
    "\n",
    "Dataset Preparation:\n",
    "\n",
    "Clean Speech: Collect recordings of clean speech.\n",
    "Noisy Speech: Mix clean speech with various background noises to create noisy speech samples.\n",
    "Example Python Script for Mixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc9401-a6c4-4cf1-b880-29a949e6c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def add_noise(clean_file, noise_file, snr_db):\n",
    "    clean, sr = sf.read(clean_file)\n",
    "    noise, _ = sf.read(noise_file)\n",
    "    if len(clean) > len(noise):\n",
    "        noise = np.tile(noise, int(np.ceil(len(clean) / len(noise))))\n",
    "    noise = noise[:len(clean)]\n",
    "    \n",
    "    clean_power = np.mean(clean**2)\n",
    "    noise_power = np.mean(noise**2)\n",
    "    desired_noise_power = clean_power / (10**(snr_db / 10))\n",
    "    scaling_factor = np.sqrt(desired_noise_power / noise_power)\n",
    "    noisy = clean + scaling_factor * noise\n",
    "\n",
    "    return noisy, sr\n",
    "\n",
    "clean_dir = 'clean_speech/'\n",
    "noise_dir = 'background_noises/'\n",
    "output_dir = 'noisy_speech/'\n",
    "\n",
    "snr_db = 10  # Signal-to-noise ratio\n",
    "\n",
    "for clean_file in os.listdir(clean_dir):\n",
    "    clean_path = os.path.join(clean_dir, clean_file)\n",
    "    noise_file = np.random.choice(os.listdir(noise_dir))\n",
    "    noise_path = os.path.join(noise_dir, noise_file)\n",
    "    \n",
    "    noisy, sr = add_noise(clean_path, noise_path, snr_db)\n",
    "    output_path = os.path.join(output_dir, clean_file)\n",
    "    sf.write(output_path, noisy, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36a406-9a89-42f7-b506-bd7ef798bcfa",
   "metadata": {},
   "source": [
    "3. Training the Model\n",
    "DeepFilterNet uses a custom training script. The training process involves preparing your dataset and running the training script.\n",
    "\n",
    "Prepare Your Dataset:\n",
    "Place your clean and noisy speech files in appropriate directories.\n",
    "\n",
    "Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942ba5e-7e74-4fcc-b445-e368e3b94598",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --clean_dir clean_speech/ --noisy_dir noisy_speech/ --output_dir models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2afa9-1e26-440e-ae8c-1b35d2bdcca8",
   "metadata": {},
   "source": [
    "4. Fine-Tuning the Model\n",
    "Fine-tuning involves continuing the training process with new data or a different dataset.\n",
    "\n",
    "Fine-Tuning Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c312b7-fae9-4f78-8ab9-ec265458eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --clean_dir clean_speech/ --noisy_dir noisy_speech/ --output_dir models/ --pretrained_model models/pretrained_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd368a-90b2-464f-9a3a-40f02a5fbbcc",
   "metadata": {},
   "source": [
    "5. Evaluation\n",
    "To evaluate the model, you can test it on a separate validation set and compare the results.\n",
    "\n",
    "Evaluation Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305ce92-3c3d-4f51-a32e-931a27de8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepfilter import DeepFilterNet\n",
    "import soundfile as sf\n",
    "\n",
    "model = DeepFilterNet.from_pretrained('models/latest_model.pth')\n",
    "\n",
    "def evaluate(input_file, output_file):\n",
    "    model.denoise_file(input_file, output_file)\n",
    "    clean, _ = sf.read('clean_speech/' + os.path.basename(input_file))\n",
    "    denoised, _ = sf.read(output_file)\n",
    "    # Implement your evaluation metric here, e.g., PESQ, STOI\n",
    "    # pesq_score = calculate_pesq(clean, denoised)\n",
    "    # stoi_score = calculate_stoi(clean, denoised)\n",
    "\n",
    "test_files = os.listdir('test_noisy_speech/')\n",
    "for test_file in test_files:\n",
    "    evaluate('test_noisy_speech/' + test_file, 'test_denoised_speech/' + test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c965bf-fb98-4682-a36a-bd6cb0b0d536",
   "metadata": {},
   "source": [
    "6. Deploying the Model\n",
    "To deploy the model on various platforms, you need to embed the DeepFilterNet model into your application.\n",
    "\n",
    "Deploying on Mobile:\n",
    "\n",
    "#Android:\n",
    "Convert to ONNX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541eee54-049c-407b-b642-53cb95d575da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from deepfilter import DeepFilterNet\n",
    "\n",
    "model = DeepFilterNet.from_pretrained('models/latest_model.pth')\n",
    "dummy_input = torch.randn(1, 1, 16000)  # Adjust input size as needed\n",
    "torch.onnx.export(model, dummy_input, \"deepfilternet.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad76ccd-3f16-4a09-ab0c-9c940eebf113",
   "metadata": {},
   "source": [
    "Convert to TensorFlow Lite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84a31c-96b6-46a5-b1f1-8120ada822bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tf2onnx\n",
    "\n",
    "onnx_model = onnx.load(\"deepfilternet.onnx\")\n",
    "tf_rep = tf2onnx.tfonnx.process_tf_graph(tf.import_graph_def(onnx_model.graph), input_names=['input'], output_names=['output'])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(tf_rep.graph_def, ['input'], ['output'])\n",
    "tflite_model = converter.convert()\n",
    "with open(\"deepfilternet.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e4218-1034-4060-82f4-4f81f0d673a2",
   "metadata": {},
   "source": [
    "Integrate with Android App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e519b-f1f2-48dd-b535-4be2859ba830",
   "metadata": {},
   "outputs": [],
   "source": [
    "public class DeepFilterNet {\n",
    "    static {\n",
    "        System.loadLibrary(\"tensorflowlite_jni\");\n",
    "    }\n",
    "\n",
    "    public native void denoise(short[] input, short[] output);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c71a70-f61e-4001-9e41-841ab86f53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// JNI function implementation\n",
    "#include <jni.h>\n",
    "#include \"tensorflow/lite/interpreter.h\"\n",
    "#include \"tensorflow/lite/kernels/register.h\"\n",
    "#include \"tensorflow/lite/model.h\"\n",
    "\n",
    "JNIEXPORT void JNICALL Java_com_example_myapp_DeepFilterNet_denoise(JNIEnv *env, jobject obj, jshortArray input, jshortArray output) {\n",
    "    // Load the model and interpreter\n",
    "    const char *model_path = \"deepfilternet.tflite\";\n",
    "    std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(model_path);\n",
    "    tflite::ops::builtin::BuiltinOpResolver resolver;\n",
    "    std::unique_ptr<tflite::Interpreter> interpreter;\n",
    "    tflite::InterpreterBuilder(*model, resolver)(&interpreter);\n",
    "\n",
    "    // Set up input and output tensors\n",
    "    jint length = env->GetArrayLength(input);\n",
    "    jshort *input_buffer = env->GetShortArrayElements(input, NULL);\n",
    "    jshort *output_buffer = env->GetShortArrayElements(output, NULL);\n",
    "\n",
    "    float norm_input[length];\n",
    "    for (int i = 0; i < length; i++) {\n",
    "        norm_input[i] = input_buffer[i] / 32768.0f;\n",
    "    }\n",
    "\n",
    "    float *input_tensor = interpreter->typed_input_tensor<float>(0);\n",
    "    std::copy(norm_input, norm_input + length, input_tensor);\n",
    "\n",
    "    // Run inference\n",
    "    interpreter->Invoke();\n",
    "\n",
    "    float *output_tensor = interpreter->typed_output_tensor<float>(0);\n",
    "    for (int i = 0; i < length; i++) {\n",
    "        output_buffer[i] = output_tensor[i] * 32768;\n",
    "    }\n",
    "\n",
    "    env->ReleaseShortArrayElements(input, input_buffer, 0);\n",
    "    env->ReleaseShortArrayElements(output, output_buffer, 0);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aacb8cd-e523-4e21-a724-2a5c587b3e1a",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "This guide covers the essential steps to load, train, fine-tune, evaluate, and deploy DeepFilterNet. Adjust the paths and parameters according to your specific needs and environment. For more details and advanced usage, refer to the official DeepFilterNet GitHub repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
