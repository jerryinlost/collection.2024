{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cc3512-1834-4755-b110-8bce801850a6",
   "metadata": {},
   "source": [
    "SpeechBrain is an open-source toolkit for speech processing, which includes ASR. It provides flexibility and is suitable for creating lightweight models. Here’s how you can train a small ASR model using SpeechBrain with the Common Voice dataset:\n",
    "\n",
    "### Step 1: Install SpeechBrain and Dependencies\n",
    "First, install SpeechBrain and other necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1daee-da1d-4457-8ffa-b359575d794e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install speechbrain\n",
    "pip install torchaudio\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f057fa7-99e1-4db5-89c9-bc49d0bbaa42",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess the Common Voice Dataset\n",
    "Use the datasets library to load the Common Voice dataset and prepare it for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e4d9c-4fd6-48b6-ac1b-6da70e36d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "import speechbrain as sb\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "from speechbrain.dataio.batch import PaddedBatch\n",
    "\n",
    "# Load the Common Voice dataset\n",
    "common_voice_train = load_dataset(\"JaepaX/corean_dataset\", split=\"train\")\n",
    "common_voice_test = load_dataset(\"JaepaX/corean_dataset\", split=\"test\")\n",
    "\n",
    "# Define data preparation functions\n",
    "def prepare_common_voice(batch):\n",
    "    batch[\"speech\"] = read_audio(batch[\"path\"])\n",
    "    batch[\"target\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "\n",
    "common_voice_train = common_voice_train.map(prepare_common_voice)\n",
    "common_voice_test = common_voice_test.map(prepare_common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a323f55-260e-4483-b417-1d82c27f8c57",
   "metadata": {},
   "source": [
    "### Step 3: Define the ASR Model\n",
    "Define the model architecture using SpeechBrain’s Brain class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8b427-57e5-43ed-bb40-a96d0e7e6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "# Define the model\n",
    "class ASR(sb.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, wav_lens = batch.speech\n",
    "        outputs = self.modules.wav2vec2(wavs)\n",
    "        logits = self.modules.output(outputs)\n",
    "        return logits, wav_lens\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        logits, wav_lens = predictions\n",
    "        ids = batch.id\n",
    "        targets, target_lens = batch.target_encoded\n",
    "        loss = self.hparams.compute_cost(logits, targets, wav_lens, target_lens)\n",
    "        return loss\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        predictions = self.compute_forward(batch, stage)\n",
    "        loss = self.compute_objectives(predictions, batch, stage)\n",
    "        return loss.detach()\n",
    "\n",
    "# Load the hyperparameters file\n",
    "with open('hyperparams.yaml') as fin:\n",
    "    hparams = load_hyperpyyaml(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962fd931-424e-43f7-b1b6-aa02ea96f77a",
   "metadata": {},
   "source": [
    "### Step 4: Define Data Pipelines\n",
    "Set up data pipelines for loading and tokenizing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b71a58-9779-49c9-a5e0-14247a3db1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data pipeline\n",
    "def dataio_prep(hparams):\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"path\")\n",
    "    @sb.utils.data_pipeline.provides(\"speech\")\n",
    "    def audio_pipeline(path):\n",
    "        sig = read_audio(path)\n",
    "        yield sig\n",
    "\n",
    "    # Define text pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"sentence\")\n",
    "    @sb.utils.data_pipeline.provides(\"target\")\n",
    "    def text_pipeline(sentence):\n",
    "        yield sentence\n",
    "\n",
    "    data_pipeline = {\n",
    "        \"audio\": audio_pipeline,\n",
    "        \"text\": text_pipeline,\n",
    "    }\n",
    "\n",
    "    datasets = {\n",
    "        \"train\": sb.dataio.dataset.DynamicItemDataset.from_dataset(common_voice_train),\n",
    "        \"test\": sb.dataio.dataset.DynamicItemDataset.from_dataset(common_voice_test),\n",
    "    }\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets.values(), data_pipeline)\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        datasets.values(), [\"id\", \"speech\", \"target\"]\n",
    "    )\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ef144-f9f6-4f61-a1ab-ff1947b12432",
   "metadata": {},
   "source": [
    "### Step 5: Training Configuration\n",
    "Configure the training process in a hyperparams.yaml file:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40502605-f0c7-41ed-b71c-54fe2cdc0d94",
   "metadata": {},
   "source": [
    "# hyperparams.yaml\n",
    "output_folder: !ref ./results/\n",
    "\n",
    "# Training parameters\n",
    "lr: 1e-4\n",
    "batch_size: 16\n",
    "epochs: 10\n",
    "\n",
    "# Define the model\n",
    "modules:\n",
    "  wav2vec2: !new: speechbrain.lobes.models.huggingface_wav2vec2.Wav2Vec2ASR\n",
    "    source: facebook/wav2vec2-base\n",
    "  output: !new: torch.nn.Linear\n",
    "    in_features: 1024\n",
    "    out_features: 35\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer: !new: torch.optim.Adam\n",
    "  params: !ref <modules.parameters>\n",
    "  lr: !ref <lr>\n",
    "\n",
    "# Define the loss function\n",
    "compute_cost: !new: speechbrain.nnet.losses.ctc_loss\n",
    "    reduction: mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97e87b-6896-4088-8e7c-40f69bbc4ce3",
   "metadata": {},
   "source": [
    "### Step 6: Train the Model\n",
    "Finally, create a training script and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b965b-4494-4ffe-8512-99f8d5dc744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the hyperparameters\n",
    "with open(\"hyperparams.yaml\") as fin:\n",
    "    hparams = load_hyperpyyaml(fin)\n",
    "\n",
    "# Create the datasets\n",
    "datasets = dataio_prep(hparams)\n",
    "\n",
    "# Initialize the Brain object\n",
    "asr_brain = ASR(\n",
    "    modules=hparams[\"modules\"],\n",
    "    opt_class=hparams[\"optimizer\"],\n",
    "    hparams=hparams,\n",
    "    run_opts={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"},\n",
    "    checkpointer=sb.utils.checkpoints.Checkpointer(hparams[\"output_folder\"]),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "asr_brain.fit(\n",
    "    epoch_counter=sb.utils.epoch_loop.EpochCounter(max_epochs=hparams[\"epochs\"]),\n",
    "    train_set=datasets[\"train\"],\n",
    "    valid_set=datasets[\"test\"],\n",
    "    train_loader_kwargs={\"batch_size\": hparams[\"batch_size\"]},\n",
    "    valid_loader_kwargs={\"batch_size\": hparams[\"batch_size\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c2201-7dbf-4d61-9384-55a49e1fcb8c",
   "metadata": {},
   "source": [
    "This guide provides a basic setup for training a smaller ASR model using SpeechBrain and the Common Voice dataset. Adjust parameters, paths, and other configurations as needed for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a2516-4a97-44bb-a94e-007fbf0120f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
